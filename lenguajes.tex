% !TeX TS-program = 
\documentclass[tesis.tex]{subfiles}

%\newcommand{\ic}{independiente de contexto }
%\newcommand{\APND}{automáta de pila no determinístico }
%\newcommand{\APD}{automáta de pila determinístico }
%\newcommand{\gramatica}{{\cal G} = (V, \Sigma, P, S)}
%\newcommand{\deriva}{\overset{*}{\Rightarrow_{\cal G}}}
%\newcommand{\lengderivado}{L({\cal G})}
%\newcommand{\fg}{grupo finitamente generado }

\begin{document}
\chapter{Grupos independientes de contexto.}
Este capítulo sigue las ideas de los trabajos \cite{muller1983groups} y \cite{muller1985theory} completando muchos detalles que son omitidos por estos.



\section{Propiedades de los lenguajes independientes de contexto.}

En esta sección vamos a probar algunas propiedades que tienen los lenguajes independientes de contexto vistos como una clase de lenguajes.
La referencia de estos resultados es \cite{hopcraft-ullman}.

La clase de lenguajes independientes de contexto va a ser la siguiente:
\[
	\text{IC} = \{  L \mid \exists \Sigma, \ L \subseteq \Sigma^*, \ \ L \  \text{es independiente de contexto} \}.
\]
de manera similar podemos definir la clase de lenguajes regulares como
\[
	\text{REG} = \{  L \mid \exists \Sigma, \ L \subseteq \Sigma^*, \ \ L \  \text{es regular}  \}.
\]

La primera propiedad que vamos a ver de los lenguajes independiente de contexto es que son cerrados con respecto a la intersección con lenguajes regulares.

\begin{prop}\label{intersecciones-reg-ic}
	Sea $L \in \text{IC}$ y sea $R \in \text{REG}$ tales que existe $\Sigma$ de manera que $L,R \subseteq \Sigma^{*}$ entonces $L \cap R \in \text{IC}$.	
\end{prop}

\begin{proof}
	Sea $L$ un lenguaje \ic tal que $L \subset \Sigma^*$ y sea $R$ un lenguaje regular tal que $R \subset \Sigma^*$. 
	Queremos ver que el lenguaje $L \cap R$ es aceptado por un \APND.
	
	Si $L$ es aceptado por un \APND ${\cal M } = (Q, \Sigma, Z, \delta, q_0, F, Z_0)$ y R es aceptado por un autómata no determinístico ${\cal M' } = (Q', \Sigma, \delta', q_0', F',)$.
	
	Consideremos el siguiente \APND
	\[
		{\cal N } = (Q \times Q', \Sigma, Z, \delta \times \delta', (q_0,q_0'), F \times F', Z_0).
	\]	
	
	Queremos ver que $L({\cal N}) = L \cap R $.	
	Probemos primero la siguiente afirmación.
	\[
	((q_0,q_0'), w, Z_0) \vdash^*_{\cal N}  ((q_i,q_j), \lambda, z) \ \iff (q_0, w, Z_0) \vdash^*_{\cal M}  (q_i, \lambda, z) \ \text{y} \ (q_0', w) \vdash^*_{\cal M'} (q_j, \lambda)  	
	\]
	Para ver esto veremos las dos implicaciones a la vez haciendo inducción en la longitud de la palabra $w$.
	
	En el caso base $|w| = 1$ de manera que $w = a \in \Sigma$.
	Este caso tenemos la igualdad porque justamente la función de transición del \APND $\cal N$ es $\delta \times \delta'$.
	
	Para el paso inductivo consideremos que $|w|=n$ de manera que $w=ua$ con $|u|=n-1$ y $a \in \Sigma$.
	Luego tenemos que $((q_0,q_0'), u, Z_0) \vdash^*_{\cal N}  ((q_k,q_l), \lambda, z') \ \iff (q_0, u, Z_0) \vdash^*_{\cal M}  (q_k, \lambda, z') \ \text{y} \ (q_0', u) \vdash^*_{\cal M'} (q_l, \lambda)$.
	Nuevamente usamos nuestra definición de la función de transición $\delta \times \delta'$ para concluir que
	\[ 
	((q_i,q_j),\lambda, z) \in \delta \times \delta'((q_k,q_l), a, z') \iff  (q_i, a, z') \in \delta(q_k, a, z') \ \text{y} \ (q_j, a) \in \delta(q_l, a).
	\]	
	Con esto terminamos de probar la afirmación.
	
	Finalmente para ver que $L({\cal N})  =  L \cap R$ usamos que por nuestra afirmación si $w \in L \cap R$ entonces es aceptado por lo dos autómatas $\cal M$ y por $\cal M'$, esto es que $(q_0, w, Z_0) \vdash^* (q_F, \lambda, z)$ y que $(q_0', w) \vdash^* (q_F', \lambda)$ y equivalentemente $((q_0,q_0'),w,Z_0) \vdash^* ((q_F, q_F'),\lambda, z)$. 
	Dado que los estados finales del autómata $\cal N$ resultan ser $F \times F'$ obtenemos que $w \in L({\cal N}) \iff w \in L \cap R$.
	Concluimos así que el lenguaje $L \cap R$ resulta ser \ic tal como queríamos ver.		
\end{proof}

Otras propiedades que nos van a interesar tienen que ver con la relación que tienen con los morfismos de monoides.
Precisamente probaremos que los lenguajes \ic como clase son cerrados por imágenes de morfismos de monoides y por preimágenes de morfismos de monoides.
 

\begin{prop}\label{morfismos-monoides-ic}

		Sea $L \in \text{IC}$, $\Sigma$ tal que $L \subseteq \Sigma^{*}$ y $h:\Sigma^{*} \to \Delta^*$ un morfismo de monoides 
		 entonces $h(L) \in \text{IC}$.
		 
\end{prop}

\begin{proof}

		Consideramos $L$ lenguaje \ic sobre $\Sigma$.
		Esto nos dice que existe una gramática $\gramatica $ tal que $L(\cG) = L$.
		Si tenemos un morfismo de monoides $h: \Sigma^* \to \Delta^*$ queremos ver que existe una gramática $\cG'$ tal que $L(\cG') = h(L)$.
		Para eso consideramos $\cG  = (V, \Sigma, P', S)$ donde la única diferencia es que reemplazamos en cada producción $P \in \cG$ a cada letra $a \in \Sigma$ por $h(a) \in \Delta^*$.
		La gramática sigue siendo \ic, nos alcanza con ver que genera al lenguaje que queremos.
		
		Miramos las dos contenciones a la vez.		
		Si tomamos una palabra $w \in L$ luego tenemos que $h(w) \in h(L)$ por lo tanto tiene que haber una sucesión de producciones $S  \implies^* w  $ en la gramática $\cG$.
		Si tomamos esta derivación y cambiamos cada producción $A \to \alpha \in P$ por la correspondiente $A \to \beta \in P'$, donde $\beta = h(\alpha)$, en la gramática $\cG'$ ahora obtenemos la palabra $h(w)$.
		Volviendo para atrás obtenemos que $L(\cG') = h(L)$ tal como queríamos ver.

\end{proof}


\begin{prop}
	Sea $L \in \text{IC}$, $\Sigma$ tal que $L \subseteq \Sigma^{*}$ y $h:\Delta^{*} \to \Sigma^*$ un morfismo de monoides 
	entonces $h^{-1}(L) \in \text{IC}$.
\end{prop}

\begin{proof}
	Sea $L$ un lenguaje \ic sobre el alfabeto $\Sigma$ tal que es aceptado por un \APND ${\cal M } = (Q, \Sigma, Z, \delta, q_0, F, Z_0)$.
	Consideremos un morfismo de monoides $h: \Delta^* \to \Sigma^*$. 
	Queremos ver que el lenguaje $h^{-1}(L) \subset \Delta^*$ resulta ser \ic. 
	Primero introduzcamos la constante $ n = \max_{a \in \Delta} |h(a)|$.
	
	Ahora consideremos el siguiente \APND 
	\[
	{\cal M' } = (Q', \Delta, Z, \delta, q_0', F', Z_0)
	\]
	donde $Q' = Q \times \Sigma^{\le n}$, donde $\Sigma^{\le n} = \{ w \in \Sigma^* : |w| \le n  \}$.
	Los estados finales $F' = F \times \{ \lambda \}$.
	El estado inicial es $q_0' = (q_0, \lambda)$.
	Finalmente nuestra función de transición resulta ser 
	\[
	\delta'((q,v), a ,z) = 
	\begin{cases}
		\{(q,h(a), z )\}  \ &\text{si} \ v=\lambda, z \in Z \\
		\{(p,u),z' \} \ &\text{si} \ (p,z') \in \delta(q,y,z), v=yu \\  
		\emptyset \ &\text{caso contrario}.
	\end{cases}
	\]
	
	Probemos primero la siguiente afirmación.
	Para cada $w \in \Delta^*$ tenemos la siguiente equivalencia,
	\[
	(q_0',w,z) \vdash^*_{\cal M'} ((q,\lambda), \sigma) \iff (q_0,h(w), z) \vdash^*_{\cal M} (q, \sigma).
	\]
	
	Para probar esta equivalencia lo hacemos por inducción en la longitud de $|w|$.
	Para el caso base tenemos que $w = a \in \Delta$.
	En este caso tenemos que $(q_0', a, z) \vdash ((q,h(a)), z)$.
	Una vez en este estado por como definimos la función de transición tenemos que $ (q_0,h(a), z) \vdash (q, \sigma)  \iff ((q_0,h(a)), \lambda ,z) \vdash ((q,\lambda), \sigma)$.
	
	El caso general tenemos una palabra $w$ tal que $|w|=n$.
	Sabemos que la afirmación vale para cualquier palabra de longitud menor a $n$.
	En particular si $w=ua$ con $|u|=n-1$ y $a \in \Delta$, tenemos que por la hipótesis inductiva que 
	\[
	(q_0',u,z) \vdash^*_{\cal M'} ((q,\lambda), \sigma) \iff (q_0,h(u), z) \vdash^*_{\cal M} (q, \sigma)
	\]
	entonces de nuevo por el mismo razonamiento que hicimos para el caso base tenemos probada la afirmación.
	
	Para concluir la demostración notemos que por nuestra afirmación una palabra $w \in L(\cal M')$ si y solo si $h(w) \in L$. 
	Esto nos dice que el lenguaje aceptado por estado final de $\cal M'$ resulta ser $L' = \{ w \in \Delta^* : h(w) \in L \} = h^{-1}(L)$.
\end{proof}

Finalmente la herramienta principal que tenemos para ver que cierto lenguaje $L$ no es \ic es usar el siguiente lema.

\begin{lema}[Pumping] \label{pumping}
	Sea $L$ un lenguaje independiente de contexto entonces existe una constante $n \ge 0$ tal que para todas las palabras $w \in L$ de longitud al menos $n$ existe una factorización $w = uvxwy$ con $|vwx| \le n$ y $|vx| > 0$ tal que para todo $i \in \NN$ vale que $uv^iwx^iy \in L$.
\end{lema}

\begin{proof}
	Resultado estándar. Ver \cite{hopcraft-ullman}.
\end{proof}

\section{Autómatas de pila determinísticos.} 
\begin{deff}
	Un \emph{autómata de pila determinístico} es un automáta de pila 
	\[
	{\cal M } = (Q, \Sigma, \Gamma, \delta, q_0, F, Z_0)
	\]
	definido idénticamente a un \APND \ref{deff_apnd} con la salvedad que 
	\[
	|\delta(q,a, z)| \le 1 \ \ \ \forall z \in \Gamma, \ p \in Q, \ a \in \Sigma \cup \{ \lambda \}.
	\]
\end{deff}

\begin{obs}
	Todo \APD en particular es un autómata de pila no determinístico. 
\end{obs}

Esto nos dice que todas las definiciones que dimos para \APND siguen siendo válidas en este contexto.
Una diferencia importante es que si ${\cal M }$ es un \APD entonces dada una palabra $w \in \Sigma$ existe una única manera de consumir a la palabra $w$.
Notaremos $L(\cal M)$ al lenguaje aceptado por estado final y notaremos por $N(\cal M)$ al lenguaje aceptado por pila vacía entonces tenemos el siguiente resultado, que marca una diferencia con el caso de los lenguajes aceptados por autómatas de pila no determinísticos.

\begin{teo}
	Existen lenguajes $L, L' \in \text{IC}$ tales que:
	\begin{itemize}
		\item Existe $\cal M$ \APD de manera que $L = L(\cal M)$ pero no existe ningún $\cal N$ \APD tal que $L = N(\cal N)$.
		\item Existe $\cal M$ \APD de manera que $L' = N(\cal M)$ pero no existe ningún $\cal N$ \APD tal que $L' = L(\cal N)$.
	\end{itemize} 
\end{teo}
\begin{proof}
	\cite{sipser13}.
\end{proof}

Ahora probemos que no todo lenguaje aceptado por estado final por un \APND puede ser aceptado por estado final por un autómata de pila determinístico.
El mismo ejemplo del lenguaje de los palíndromos \ref{ej_ic_palindromos} nos sirve como contraejemplo.
\begin{ej}
	El lenguaje 
	\[
	L = \{ w \in \{ a,b \}^*  \ : \ w = w^r \}
	\]
	 no es aceptado por un \APD pero sí por uno no determinístico. 
	Supongamos que ${\cal {M}} = (Q, \{ a, b \}, \Gamma, \delta, q_0, F, Z_0)$ es un \APD que lo acepta. 

	
	Notemos que para cualquier palabra $w \in \{ a,b \}^*$ debe ser que
	\[
		(q_{0},w,Z_{0}) \overset{*}{\vdash} (q, \lambda, \gamma)
	\]
	donde $\gamma \in \Gamma^*$ es tal que $\gamma \neq \lambda$.
	Caso contrario tendríamos que $ww^r \notin L(\cal M)$ ya que la pila estaría vacía y no podríamos pasar de configuración.

	Fijamos una palabra arbitraria $w \in \{ a,b \}^*$ y consideramos $x_{w} \in \{ a, b\}^*$ de manera que si
	$(q_{0}, wx_{w}, Z_{0}) \overset{*}{\vdash} (q, \lambda, \gamma_{w})$ entonces $|\gamma_{w}|$ es minimal.
	

	Si consideramos palabras del estilo $wx_wz \in \{a,b\}^*$ sabemos que la longitud de lo que quede en la pila no puede disminuir, esto es que si $(q_{0}, wx_{w}z, Z_{0}) \overset{*}{\vdash} (q, \lambda, \gamma)$ entonces $|\gamma| \ge |\gamma_{w}|$.
	
	Nuestro \APD $\cal M$ tiene finitos estados y un alfabeto de pila finito por lo tanto existen finitos pares de estados y topes de pilas a los que puede llegar este \APD después de consumir una palabra.
	Esto nos dice que deben existir al menos dos palabras distintas $w, u \in \{ a, b\}^*$ tales que:
	\begin{align*}
		(q_{0}, wx_{w}, Z_{0}) & \overset{*}{\vdash} (q, \lambda, \gamma_{w}) \\
		(q_{0}, ux_{u}, Z_{0}) & \overset{*}{\vdash} (q, \lambda, \gamma_{u})
	\end{align*}
	que cumplan que caen en el mismo estado y tienen el mismo tope de pila, esto que existe $z \in \Gamma$ tal que $\gamma_{u} = z \gamma$ y $\gamma_{w} = z \gamma'$ para $\gamma, \gamma' \in \Gamma^{*}$.
	
	
	Vamos a elegir $v \in \{ a,b\}^*$ de manera que si $s = wx_{w}$ y $t = ux_{u}$ entonces $sv \in L \iff tv \notin L$ y viceversa.
	
	Procedemos separando en casos dependiendo de las longitudes de $s$ y de $t$.
	\begin{itemize}
		\item Si $|t|=|s|$ basta con tomar $v=s^r$. 
		Entonces $tv \in L({\cal M})$ pero $tv \notin L$.
		
		\item Si $|t|\neq |s|$ supongamos que $|s| < |t|$ y que $s$ no es prefijo de $t$ entonces  podemos tomar $v = s^r$ de manera que $sv \in L$ mientras que $tv \in L(\cal M)$ pero $tv \notin L$.
		
		\item Si $|t|\neq |s|$ y una es prefijo de la otra. 
		Sin pérdida de generalidad supongamos que $t=sy$ donde $y \in \{a,b\}^*$ tal que $|y| \ge 1$ y que $y = ay'$ con $y' \in \{a,b\}^*$ entonces $yb \notin L$.  
		De esta manera tenemos que si $v=bs^R$ entonces $sv \in L$ mientras que $tv \in L(\cal M)$ pero $tv \notin L$.		
	\end{itemize}
	
	Con esto probamos que no puede existir ningún autómata $\cal M$ tal que $L = L(\cal M)$ porque si $L \subseteq L(\cal M)$ entonces existen $w \in L(\cal M)$ tales que $w \notin L$.
	Por el ejemplo \label{ej_ic_palindromos} tenemos que $L$ es aceptado por un \APND y así vimos que no todo lenguaje que es aceptado por un \APND es aceptado por un autómata de pila determinístico.
	
\end{ej}

\subsection{Autómatas de pila determinísticos especiales.} 
Consideremos ahora un \APD tal que acepta tanto por estado final como por pila vacía. 

\begin{deff}
	Sea ${\cal {M}} = (Q,\Sigma, \Gamma, \delta, q_0, F, Z_0)$ un autómata de pila determinístico. 
	Diremos que $\cal M$ es un \emph{autómata de pila determinístico especial} si $w \in L({\cal M}) \iff w \in N(\cal M)$.
\end{deff}

La familia de lenguajes aceptados por los autómatas de pila determinísticos especiales es estrictamente menor a la familia de los que son aceptados por autómatas de pila determinísticos.
Veamos un contraejemplo.

\begin{ej}
	Sea el lenguaje $L = \{ a^m b^n  : m \ge n \ge 1 \}$ este no es un lenguaje independiente de contexto determinístico especial pero sí es determinístico. 
	
	Construyamos un \APD que acepte a $L$. 
	Sea $$M = (\{q_0,q_1,q_2\}, \{q_0\}, \{a,b\}, \{a,b,Z_0\}, Z_0, q_2) $$ un \APD 
	tal que si donde $Z \in \{a,b,Z_0\}$ es cualquier letra del alfabeto de la pila.
	Escribimos $b, a | \gamma$ para decir que $b$ es la letra de la palabra que estamos consumiendo que nos toca leer, $a$ es el tope de la pila y $\gamma$ es la palabra que reemplaza al tope de la pila, esto es que si estamos en un estado $q$ luego $\delta(q,b,a) = (p,\gamma)$ para $p$ otro estado.
	\todo{Terminar de escribir bien este ejemplo.}
	Entonces podemos representar graficamente al \APD de la siguiente manera:	
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,
		scale = 1,transform shape]
		
		\node[state,initial] (q_0) {$q_0$};
		\node[state] (q_1) [right of=q_0] {$q_1$};
		\node[state,accepting] (q_2) [right of=q_1] {$q_2$};
		
		\path (q_0) edge    [bend right]          node {$b, a | \lambda$ \ } (q_1)
		(q_0) edge    [loop above]          node {$a, Z | aZ$} (q_0)
		(q_1) edge      [bend right]      node {$\lambda, a | Z$}   (q_2)
		(q_1) edge    [loop above]           node {$b, a | \lambda$} (q_1);
		
		\end{tikzpicture}
	\end{center}
	
	
	
	
	El autómata en el estado inicial $q_0$ apila a todas las $a$ y cambia al estado $q_1$ cuando lee por primera vez una $b$ y en ese caso desapila la a que está en el tope de la pila. 
	En el estado $q_1$ sigue desapilando cada vez que ve una $b$. Finalmente va al estado $q_2$ cuando en la pila sigue quedando $a$ y ya leímos toda la palabra y en tal caso la acepta porque significa que vimos como máximo tantas $b$ como $a$ y este es el lenguaje que buscábamos generar.
	
	El lenguaje no es aceptado por un \APD por pila vacía dado que tiene la propiedad de los prefijos. 
	Es decir que existen palabras que están en el lenguaje tales que alguno de sus prefijos también están. 
	Por ejemplo consideremos
	 \[
	 	a^m b^i, \ a^m b^j \ \
	 	\text{para}  \
	 	m \ge 2,  \ i < j \le m
	 \] 
	Esto es porque si $M = (Q, \Sigma, Z, Z_0, \delta, q_0 , F)$ fuera un \APD que acepta por pila vacía a este lenguaje tendríamos que 
	\[
		(q_0,a^{m}b^{i},Z_0) \vdash^* (q,\lambda, \lambda)
	\]
	con $q$ un estado final pero como tiene la pila vacía no podemos continuar aceptando a la palabra $a^mb^j$ ya que por la definición que empleamos el autómata necesita leer algún elemento de la pila. 
	
	De esta manera vemos que este lenguaje no puede ser aceptado por pila vacía y estado final por un \APD concluyendo que los lenguajes determinísticos especiales forman un subfamilia propia de los independientes de contexto determinísticos.
	
%[Esto es con la otra definición de automáta de pila.]
%			Por el principio del palomar podemos ver que este lenguaje no es aceptado por \APD por pila vacía y estado final a la vez. Si así lo fuera supongamos que existe un automáta que lo acepta $M = (Q, \Sigma, Z, Z_0, \delta, q_0 , F)$. Debido a que tiene finitos estados podemos elegirnos $m$ suficientemente grande tal que existan palabras $a^mb^j, a^mb^i$ con $1 \le i < j < m$ y elegidas de manera que terminen en el mismo estado final $p$. Notemos que $(q_0,a^mb^ib^{m-j+1},Z_0) \vdash^* (q,\lambda, Z)$ donde $q$ es un estado final dado que $m-j+1+i \le m$. Por otro lado debe ser que $(q_0, a^mb^jb^{m-j+1}) \vdash^* (q,\lambda, Z) $ pero notemos que $a^mb^{m-1} \notin L$. Por lo tanto llegamos a una contradicción y de esta manera vemos que $L$ no es aceptado por un \APD especial tal como queríamos ver.
\end{ej}


\section{El problema de la palabra.}

Todo grupo $G$ lo podemos ver como un monoide. 
En particular si tenemos un grupo $G$ tal que es finitamente generado como grupo por algún conjunto finito $X$ entonces es finitamente generado como monoide por el conjunto simétrico de generadores $Y = X \cup X^{-1}$.
\todo{Def de monoide fg? Reescribir.}
Sea entonces $\Sigma$ conjunto finito de generadores como monoide de $G$
o lo que resulta equivalente, tenemos un epimorfismo de monoides desde el monoide libre $\pi: \Sigma^* \twoheadrightarrow  G$. 

El problema de la palabra es uno de los problemas de teoría de grupos más centrales al área. Explícitamente el problema consiste en encontrar un algoritmo que dada una palabra $\omega \in \Sigma^*$ decida si esta palabra es la identidad del grupo o no. 

\begin{deff}
El \emph{problema de la palabra de $G$ para los generadores $\Sigma$} es el siguiente lenguaje,	
\[ \text{WP} (G, \Sigma) = \{ \omega \in \Sigma^* \ | \ \omega \underset{G}= 1 \}\]
\end{deff}

Dado que este lenguaje depende del conjunto de generadores elegido nos gustaría ver qué condiciones tienen que cumplir los lenguajes o los grupos para que no exista esta dependencia en los generadores.


En el contexto del problema de la palabra nos van a interesar las familias de lenguajes que cumplen las siguientes propiedades.
\medskip
\begin{deff}
	Una familia de lenguajes $\CC$ es un \emph{cono} si para todo $L \in \CC$ resulta que:
	\begin{itemize}
		\item[\textbf{C1.}] Es cerrado por imágenes de morfismos de monoides. Sea $L \subset \Sigma^*$ luego si existe $\phi:\Sigma^* \to \Delta^*$ morfismo de monoides debe ser que $\phi(L) \in \CC$.
		\item[\textbf{C2.}] Es cerrado por preimagenes de morfismos de monoides. Sea $L \subset \Sigma^*$ luego si existe $\phi:\Sigma^* \to \Delta^*$ morfismo de monoides  debe ser que $\phi^{-1}(L) \in \CC$. 
		\item[\textbf{C3.}] Es cerrado por intersecciones con lenguajes regulares. Si $R$ es un lenguaje regular sobre $\Sigma^*$ entonces $L \cap R \in \CC$ también resulta serlo.
	\end{itemize}
\end{deff} 


Los conos de lenguajes cumplen la siguiente propiedad de gran importancia para el estudio del problema de la palabra.
\medskip
\begin{prop}\label{prop-cono-wp}
	Sea $WP(G, \Sigma)$ el lenguaje del problema de la palabra de cierto grupo $G$ para algunos generadores $\Sigma$ y $\CC$ cono de lenguajes. 
	Si $WP(G, \Sigma) \in \CC$ luego valen las siguientes afirmaciones:
	\begin{itemize}
		\item[\textbf{W1.}] $WP(G, \Delta) \in \CC$ para cualquier conjunto de generadores $\Delta$.
		\item[\textbf{W2.}] $WP(H) \in \CC$ para todo subgrupo $H$ \fg de $G$.
	\end{itemize} 
\end{prop}
\begin{proof}
		Para ver \textbf{W1} formamos el siguiente diagrama conmutativo,
		\begin{center}
			\begin{tikzcd}
				\Delta^* \arrow[r, "\delta"] \arrow[d,"f",swap] & G \\
				\Sigma^* \arrow[ru, "\pi",swap]    &  
			\end{tikzcd}
		\end{center}
		donde $f$ es algún morfismo de monoides y donde usamos la propiedad universal de los monoides libres.
		Notemos que $WP(G, \Delta) = \delta^{-1}(1)$ y como el diagrama conmuta tenemos que 
		\[
		f^{-1}(\delta^{-1}(1)) = f^{-1}(WP(G,\Sigma)) = WP(G, \Delta).
		\]
		Dado que esto es un cono obtenemos lo que queríamos ver puesto que es cerrado por preimágenes de morfismos de monoides.
		
		
		
		Veamos ahora que vale \textbf{W2}. 
		Sea $\Sigma'$ conjunto de generadores de $H$.
		Siempre podemos extenderlo a $\Sigma$ tal que $\Sigma$ genere a $G$. 
		De esta manera 
		\[
		WP(H, \Sigma') = WP(H, \Sigma) \cap \Sigma'^*
		\]
		y de vuelta como es un cono la intersección con lenguajes regulares nos da un lenguaje en el cono. 

\end{proof}


Esto nos dice que es interesante estudiar el problema de la palabra justamente sobre conos.

\section{Grupos independiente de contexto.}


\begin{ej}\label{ic-cono}
	Los lenguajes independiente de contexto forman un cono.
	Esto se puede ver a partir de las proposiciones  \ref{intersecciones-reg-ic} y \ref{morfismos-monoides-ic}.
\end{ej}

Esto nos dice que la siguiente definición no depende de los generadores que tomemos.

\begin{deff}
	Si $G$ es un grupo \fg tal que para ciertos generadores $\Sigma$ resulta que $WP(G, \Sigma)$ es independiente de contexto entonces diremos que $G$ es un \emph{grupo \ic }.
\end{deff}


\begin{ej} Consideremos los siguientes ejemplos.	
	\begin{enumerate}[E1.]
		\item 
		Dado $F$ grupo libre de rango finito supongamos generado por el conjunto finito $X$. 
		Sea  $Y = X \cup X^{-1}$ el conjunto de generadores simétrico de $X$. 
		Probemos que $\text{WP}(F,Y)$ es un lenguaje independiente de contexto.
		
		Consideremos el siguiente autómata de pila,
		\[
		M = (\{ 1 \}, Y, Y, \delta, 1, \{1\}).
		\]
		
		Por como lo definimos tiene un solo estado y el alfabeto tanto de entrada como el de la pila que usa es el conjunto de generadores $Y$.
		La función de transición $\delta$ está definida de la siguiente manera,
		\[
		\delta(1, y_i, u)=\left\{
		\begin{array}{ll}
		(1 , u )  &\ \text{si} \ a = 1  \\
		(1, y_i \cdot u') &\ \text{si} \  u = y_jw'  \\
		\end{array}
		\right.
		\]
		donde al apilar hacemos la multiplicación $y_i \cdot u$ en el grupo libre $F$.
		
		Consideremos el lenguaje aceptado por pila vacía, esto es
		
		\[
		{\cal L }(M) = \{  y \in Y^* \mid (y,1,1)   \vdash^*  (1, 1, 1)  \}.
		\]
		
		Notemos que ${\cal L }(M) = \text{WP}(F,Y)$ porque justamente en la pila apilamos lo que vamos leyendo de izquierda a derecha y desapilamos cuando leemos el inverso del generador que está en el tope de la pila.
		Esto es que desapilamos cuando un generador aparece después de su inverso en la palabra.

		
		\item 	$\ZZ \times \ZZ$ no es un grupo independiente de contexto.
		Si tomamos los siguientes generadores como monoide $\Sigma = \{ a,b,c \}$ tal que tenemos un morfismo de monoides $\pi: \Sigma^* \to \ZZ \times \ZZ$ dado por $\pi(a)=(1,0), \pi(b)=(0,1), \pi(c)=(-1,-1)$.
		Bajo esta presentación 
		\[
		WP(\ZZ \times \ZZ, \Sigma) = \{ w \in \Sigma^*  : \ \exists n \in \NN, \ |w|_a = |w|_b = |w|_c = n \}.
		\]
		Este lenguaje no es independiente de contexto.
		Para eso usemos el lema del pumping \ref{pumping} para probarlo por contradicción.
		Si fuera \ic debería existir una constante $n \ge 0$ tal que hace valer las hipotesis del lema.
		Consideremos la palabra $w = a^n b^n c^n \in WP(G, \Sigma)$.
		Si tenemos una factorización 
		\[
		uvwxy = a^nb^nc^n
		\]
		si $|vwx| \le n$ implica que no todas las letras aparecen en $vwx$.
		Supongamos que la letra que no aparece es $c$.
		Por otro lado como $|vx| \le 0$ esto nos dice que al menos una letra aparece en la subpalabra $vx$.
		Si tomamos $i=0$ notemos que la palabra $uwy \in WP(G,\Sigma)$ pero esto es una contradicción porque la cantidad de $c$ en esta palabra es mayor que de $a$ o $b$.
	\end{enumerate}
\end{ej}

\section{Grupos virtualmente libres.}


\begin{lema}\label{lema_int_normal}
	Sea $G$ grupo, sea $H$ subgrupo de $G$ luego el subgrupo $K = \bigcap_{g \in G} gHg^{-1}$ es un subgrupo normal de $G$.
\end{lema}


\begin{prop}\label{prop_vls}
	Para todo grupo $G$ \vl \ valen las siguientes propiedades.
	\begin{enumerate}
		\item Si $F$ es un subgrupo libre de índice finito entonces podemos tomarnos otro subgrupo $F'$ de manera que sea normal, libre y de índice finito.
		\item Si $H$ es un subgrupo de $G$ de índice finito entonces $H$ también resulta ser \vl.
	\end{enumerate}
\end{prop}

\begin{proof}
	Vamos a probar \textbf{1}.
	Si $G$ es virtualmente libre y $F$ es un subgrupo libre tenemos que la cantidad de conjugados de $F$ es finita por el lema \ref{lema_normalizador_conjugados}.
	Por el lema \ref{lema_int_normal} tenemos que el siguiente subgrupo de $G$ es normal
	\[
	F' = \bigcap_{g \in G} gFg^{-1}
	\]
	donde la cantidad de grupos que estamos intersecando es finita.
	Veamos que este subgrupo $F'$ nos sirve. 
	
	
	Como $F$ tiene índice finito y todos sus conjugados al ser isomorfos a $F$ también tienen índice finito entonces $F'$ tiene índice finito por el lema \ref{lema_indice_interseccion}.
	Como $G$ es finitamente generado por ser virtualmente libre entonces usando \ref{lema_subg_fg} obtenemos que $F'$ es finitamente generado.
	Finalmente notemos que es libre por el resultado \ref{coro_niels_sch} que nos dice que todo subgrupo de un grupo libre es libre, en particular al ser $F'$ subgrupo de $F$ que es libre obtenemos que $F'$ es libre tal como queríamos ver.
	
	Probemos \textbf{2}. 
	Por el lema \ref{lema_subg_fg} obtenemos directamente que $H$ es un grupo finitamente generado.
	Si $F$ es un libre de índice finito en $G$ podemos tomar $H \cap F$ que es libre por ser subgrupo de un libre de acuerdo al resultado \ref{coro_niels_sch}.
	El índice resulta ser finito puesto que 
	\[
	[H:F\cap H] \le [G:F] < \infty.
	\]
\end{proof}

\begin{obs}\label{obs_presentacion_vl}
	Dado $G$ \vl \ vamos a construirnos una presentación en particular.
	
	Como es un grupo \vl \ tenemos $F$ subgrupo libre que podemos tomarlo normal y $G/F$ grupo finito de manera que podemos escribir a $G$ como una extensión de estos dos grupos por medio de la siguiente forma
	\begin{center}
		\begin{tikzcd}
			1 \arrow[r] & F \arrow[r, "\iota"] & G \arrow[r, "\pi"] & G/F \arrow[r] & 1
		\end{tikzcd}
	\end{center}
	
	Consideremos que $F$ es libre generado por $Y = \{ y_1, \dots, y_n \}$.
	Por otro lado sea $G/F = \{ b_i : 1 \le i \le m \}$ todos los elementos de este conjunto finito.
	Elegimos un transversal a derecha $T = \{ t_1, \dots, t_m \}$ de manera que $\pi(t_i)= b_i$ y $t_1 = 1$.
	
	Dado que es un transversal tenemos que se deben cumplir las siguientes dos relaciones para $y_j \in Y$ y $t_i,t_j,t_k \in T$. 
	\begin{enumerate}
		\item $t_iy_jt_i^{-1} = u_{ij}$ donde $u_{ij} \in F$ usando que $F$ es normal.
		\item Si tenemos que $b_ib_j = b_k$ entonces $t_it_j = z_{ij}t_k$ donde $z_{ij} \in F$ usando que $(Ht_i)(Ht_j) = Ht_k$.
	\end{enumerate}
	
	Afirmamos que la siguiente es una presentación finita de $G$.
	\[
	\langle W \mid R \rangle =  \langle y_1, \dots, y_n, t_1, \dots, t_m \mid t_iy_jt_i^{-1} = u_{ij},  t_it_j = z_{ij}t_k \rangle.
	\]
	Sea el grupo que genera este presentación $H$ y sea $F'$ el grupo libre sobre sus generadores.
	
	Notemos que $W =Y \cup T$ genera a $G$ porque justamente $F$ es libre y generado por $Y$ y $T$ es un conjunto transversal finito porque $F$ tiene índice finito en $G$.
	Esto nos dice que tenemos un epimorfismo de grupos de $F'$ en el grupo $G$.
	
	Toda relación de $G'$ la cumple el grupo $G$ por la elección que tomamos, de esta manera tenemos un epimorfismo de grupos $\ol \varphi$ tal que hace conmutar al siguiente diagrama,
	
	\begin{center}
		\begin{tikzcd}
			F' \arrow[dd] \arrow[rr, "\varphi"]          &  & G \\
			&  &   \\
			H \arrow[rruu, "\overline \varphi"', dashed] &  &  
		\end{tikzcd}
	\end{center}
	
	El grupo  $G$ es tal que a toda palabra $w$ en sus generadores la podemos llevar a que sea de la pinta
	\[
	w = yt
	\]
	donde $y \in F$ reducida y $t \in T$ es alguno de los transversales. 
	Para llegar a esto hacemos el mismo procedimiento que hicimos en la demostración del lema \ref{lema_subg_fg}.
	
	De esta manera una palabra es trivial si y solamente si $y=1$ y $t=1$. 
	Esto nos dice que $\ol \varphi(w) = 1$ si y solamente si $w=1$. 
	Concluimos así que $\ol \varphi$ es un isomorfismo de grupos tal como queríamos ver y por lo tanto  $\langle W \mid R \rangle$ resultó ser una presentación de $G$.
	
\end{obs}
\medskip




\section{Teorema de Muller--Schupp.}


Una pregunta natural es intentar entender la relación entre la clasificación del lenguaje del problema de la palabra de un grupo dado y las distintas familias de grupos que le corresponden. 
La siguiente demostración generaliza la construcción del ejemplo del problema de la palabra de un grupo libre.


\begin{teo}\cite{muller1983groups}
	Todo grupo virtualmente libre es independiente de contexto.
\end{teo}


\begin{proof}
	Sea $G$ grupo \vl  \ y consideremos una presentación $\langle W  \mid  R \rangle$ como la que construimos en la observación \ref{obs_presentacion_vl}.
	Veamos de construir un autómata de pila de manera que acepte al lenguaje $\text{WP}(G,W)$.
	Antes de definirlo consideremos algunos conjuntos finitos que nos van a servir para definir al autómata.
	
	Si tenemos que $ t_j y_i = u_{ij} t_j $ y que $ t_it_j = z_{ijk}t_k $ luego consideremos la siguiente definición.
	El conjunto finito $U = \{ u_{ij}, \ z_{ijk} : 1 \le i,j,k \le n \}$.
	Consideremos $\text{Pre}(U) = \{ u' \in Y^* : u'v \in U  \}$ el conjunto de los prefijos de las palabras en $U$ que sabemos es finito también.	
	Sea entonces el conjunto finito $Q = T \times T \cup Y \times \text{Pre}(U) $.
	
	Con estas definiciones ahora nuestro autómata lo definimos así: 
	\[
	{\cal M }= (Q, W , Y, \delta, (1,1,1), \{(1,1,1)\})
	\]
	El conjunto $Q$ van a ser nuestros estados.
	El alfabeto de entrada es $W$ que es el conjunto de generadores del grupo.
	El alfabeto de la pila es $Y$ que es el conjunto de generadores del subgrupo libre $F$.
	Nuestro estado inicial que también es el final corresponde a $(1,1,1)$.
	
	Ahora podemos definir la función de transición. 
	Sea $w_i \in W$ algún generador del grupo luego tenemos que
	\begin{align*}
		\delta(y_iw',(t_j,1,1), v) &= (w', (t_j,y_i,1), v) \\
		\delta(t_iw',(t_j,1,1), v) &= (w', (t_k,t_i,1), v) \\
	\end{align*}
	de manera que si estamos en $T \times \{ 1 \} \times \{ 1 \}$ podemos pasar a la segunda coordenada correspondiente a la letra de $W$ que hayamos leído.	
	Ahora en esta instancia lo que vamos a hacer es la reducción del producto de $u_{ij} \cdot v$ o bien el de $z_{ijk} \cdot v$ respectivamente una letra a la vez.
	Para esto tenemos
	\begin{equation*}
		\delta(w',(t_j,w_i,u), v) = (w', (t_j,w_i,y_iu), y_i \cdot v) .
	\end{equation*}
	siempre y cuando $y_iu$ sea un prefijo de la palabra de $U$ correspondiente.
	Notemos que sigue siendo determinístico porque fijamos de antemano alguna escritura única en los generadores $Y$ para cada palabra $u \in U$.
	En la pila hacemos la reducción en el grupo libre de multiplicar por una letra.
	Finalmente la función de transición la definimos para que podamos volver una vez que ya reducimos toda la palabra $u \in U$.
	Para eso tenemos 
	\begin{equation*}
		\delta(w',(t_j,w_i,u), v) = (w', (t_j,1,1), v).		
	\end{equation*}
	en el caso que $u \in U$, es decir que ya hicimos toda la reducción.
	
	Una vez definido este autómata consideremos ahora el lenguaje aceptado por pila vacía y estado final a la vez,
	
	\[
	{\cal L }(M) = \{  w \in W^* \mid (w,1,1)   \vdash^*  (1, 1, 1)  \}
	\]
	Debemos ver que el autómata acepta justamente al lenguaje que queremos. 
	Esto es que $ {\cal L }(M) = \text{WP}(G,W) $ 
	
	
	Dada una palabra $w \in W^*$ por como es esta presentación sabemos que se puede escribir como $w = vt$ donde $v \in F$ reducida y $t \in  T$. 
	De esta manera $w \in \text{WP}(G,W)$ si y solo si $v=1, t=1$.
	Notemos que el autómata en toda transición no hace más que reescribir la cadena de izquierda a derecha tal como hicimos en la observación \ref{obs_presentacion_vl}.
	Esto es que cuando termina de consumir la cadena de entrada llegamos a la configuración $(1, t_i, v)$ es decir que $w = vt_i$.
	Por lo tanto como aceptamos por estado final y pila vacía esto nos dice que $w \in \text{WP}(G,W)$ si y solo sí $w \in {\cal L}(M)$.
	
	Con esto probamos que los grupos virtualmente libres son \ic usando la equivalencia \ref{teo_ic_apnd}.
	
\end{proof}
\begin{center}
	\missingfigure[figwidth=6cm]{Ejemplo de un grupo que sepa hacer?}
\end{center}
\todo[]{Agregar citas y uno o dos párrafos precisos sobre la complejidad computacional del problema.}




\end{document}

