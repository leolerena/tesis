\documentclass[tesis.tex]{subfiles}
\begin{document}

\chapter{Preliminares.}

En este capítulo introducimos resultados estándares de teoría de lenguajes y grupos que usaremos a través de esta tesis.

\section{Grupos virtualmente libres.}
\begin{deff}
	Un grupo $G$ finitamente generado es \emph{virtualmente libre} si existe un subgrupo libre $F$ tal que su índice en $G$ es finito.
\end{deff}

Veamos algunas propiedades elementales que cumplen todos los grupos \vl. 
Antes probemos algunos lemas sobre grupos.
\begin{deff}
	Sea $G$ un grupo y $H$ un subgrupo entonces el normalizador de $H$ en $G$ es el siguiente subgrupo
	\begin{equation*}
		N_G(H) = \{ g\in G : gHg^{-1} = H  \}
	\end{equation*}
\end{deff}

Denotaremos por $S= \{ g \in G :  gHg^{-1} \}$ al conjunto de conjugados del subgrupo $H$. 

\begin{lema}\label{lema_normalizador_conjugados}
	Si $G$ es un grupo \fg y $H$ es un subgrupo de índice finito entonces $N_G(H)$ tiene índice finito y más aún $[G:N_G(H)] = |S|$.
\end{lema}
\begin{proof}
	Para ver que tiene índice finito notemos que $H \le N_G(H)$ por lo tanto tenemos que 
	\[
	[G:N_G(H)] \le [G:H] < \infty.
	\]
	
	Para probar la otra afirmación definimos la siguiente función hacia los cosets a derecha del normalizador desde el conjunto $S$,
	\begin{align*}
		S  &\to  G/N_G(H) \\
		sHs^{-1} &\mapsto N_G(H)s
	\end{align*}
	Veamos que es biyectiva.
	
	Si $N_G(H)s = N_G(H)t$ entonces tenemos que esto sucede si y solo sí $st^{-1} \in N_G(H)$.
	Esto nos dice que por la definición del normalizador,
	\[
	st^{-1} H ts^{-1} = H \iff s^{-1}Hs = t^{-1}Ht
	\]
	y de esta manera obtenemos que la función está bien definida y es biyectiva.
\end{proof}

\begin{lema}\label{lema_indice_interseccion}
	Sea $G$ un grupo \fg \  y sean $K,H$ subgrupos de índice finito entonces $K \cap H$ es un subgrupo de índice finito.
\end{lema}
\begin{proof}
	Primero notemos que por el segundo teorema de isomorfismo para grupos tenemos que existe una biyección entre los siguientes conjuntos,
	\[
	KH / K \simeq K / K \cap H
	\]
	y en particular como $|KH / K| \le |G / K| < \infty$ por hipótesis obtenemos así que $|K / K \cap H| < \infty$.
	
	Finalmente por una propiedad de índices de subgrupos obtenemos lo siguiente
	\[
	[G:K\cap H] = [G:K][K: K \cap H]
	\]
	y como ambos índices de la derecha son finitos por lo visto obtenemos que $K \cap H$ es un subgrupo de índice finito también tal como queríamos ver.
\end{proof}

\begin{lema}\label{lema_subg_fg}
	Sea $G$ un \fg y sea $H$ subgrupo de índice finito entonces $H$ es un \fg.
\end{lema}
\begin{proof}
	Sea $A = \{g_1, \dots, g_n\}$ conjunto finito de generadores de $G$.
	Sea $T =\{t_1, \dots, t_m\}$ conjunto transversal a derecha de $H$, esto es que $Ht_1, \dots, Ht_k$ son todos los cosets a derecha de $H$ sobre $G$.
	Supongamos que $t_1=1$ dado que es el representante del coset $H$.
	
	Dado $g_j$ generador de $G$ debe existir $h_{ij} \in H$ tal que $h_{ij}t_{k} = t_ig_j$ para cierto $t_k$.
	También debe existir $h_i \in H$ de manera que $ h_i t_{k} = g_i$ para cierto $t_k$.
	Veamos que el conjunto finito 
	\[
	B = \{ h_{ ij}  \}_{1 \le i,j \le n } \cup \{ h_i \}_{1 \le i \le n}
	\]
	genera a $H$.
	
	Dado $h \in H$ tenemos que 
	\[
	h = g_{i_1}\dots g_{i_r}
	\]
	donde usamos el conjunto finito de generadores de $G$.
	
	Por lo visto anteriormente podemos escribir  $g_{i_1} = h_{i_1}t_{k_1}$ y entonces nos queda la siguiente escritura de $h$,
	\[
	h = h_{i_1}t_{k_1} g_{i_2}\dots g_{i_r}
	\]
	entonces usando que $h_{k_{1}i_{2}}t_{k_2} = t_{k_1}g_{i_2} $ llegamos a la siguiente escritura de $h$,
	\[
	h = h_{i_1}h_{k_{1}i_{2}}t_{k_2}\dots g_{i_r}.
	\]
	Repitiendo inductivamente este procedimiento llegamos a que $h =h_{i_1}h_{k_{1}i_{2}} \dots t_{k_r}$.
	Este $t_{k_r}$ tiene que ser $1$ porque justamente $h \in H$, por lo tanto tenemos $B$ es un conjunto finito de generadores de $H$.
\end{proof}


Con esto podemos probar estos resultados elementales de grupos \vl.

\begin{prop}\label{prop_vls}
	Para todo grupo $G$ \vl \ valen las siguientes propiedades.
	\begin{enumerate}
		\item Si $F$ es un subgrupo libre de índice finito entonces podemos tomarnos otro subgrupo $F'$ de manera que sea normal, libre y de índice finito.
		\item Si $H$ es un subgrupo de $G$ de índice finito entonces $H$ también resulta ser \vl.
	\end{enumerate}
\end{prop}

\begin{proof}
	\begin{enumerate}
		\item Si $G$ es virtualmente libre y $F$ es un subgrupo libre tenemos que la cantidad de conjugados de $F$ es finita por el lema \ref{lema_normalizador_conjugados}.
		Por lo tanto podemos considerar el siguiente subgrupo normal
		\[
		F' = \bigcap_{g \in G} gFg^{-1}
		\]
		donde la cantidad de grupos que estamos intersecando es finita y es normal por construcción.
		Veamos que $F'$ nos sirve. 
		Para ver que tiene índice finito nos alcanza con usar el lema \ref{lema_indice_interseccion} e inducción para que valga para una intersección finita arbitraria.
		Como tiene índice finito usando \ref{lema_subg_fg} sabemos entonces que es un \fg.
		Finalmente notemos que es libre por el resultado \ref{coro_niels_sch} que nos dice que todo subgrupo de un grupo libre es libre, en particular al ser $F'$ subgrupo de $F$ que es libre obtenemos que $F'$ es libre tal como queríamos ver.
		
		\item Por el lema \ref{lema_subg_fg} obtenemos directamente que $H$ es \fg.
		Si $F$ es un libre de índice finito en $G$ podemos tomar $H \cap F$ que es libre por ser subgrupo de un libre de acuerdo al resultado \ref{coro_niels_sch}.
		El índice resulta ser finito puesto que 
		\[
		[H:F\cap H] \le [G:F] < \infty.
		\]
	\end{enumerate}
\end{proof}

\begin{obs}\label{obs_presentacion_vl}
	Dado $G$ \vl \ vamos a construirnos una presentación en particular.
	
	Como es un grupo \vl \ tenemos $F$ subgrupo libre que podemos tomarlo normal y $G/F$ grupo finito de manera que podemos escribir a $G$ como una extensión de estos dos grupos por medio de la siguiente forma
	\begin{center}
		\begin{tikzcd}
			1 \arrow[r] & F \arrow[r, "\iota"] & G \arrow[r, "\pi"] & G/F \arrow[r] & 1
		\end{tikzcd}
	\end{center}
	
	Consideremos que $F$ es libre generado por $Y = \{ y_1, \dots, y_n \}$.
	Por otro lado sea $G/F = \{ b_i : 1 \le i \le m \}$ todos los elementos de este conjunto finito.
	Elegimos un transversal a derecha $T = \{ t_1, \dots, t_m \}$ de manera que $\pi(t_i)= b_i$ y $t_1 = 1$.
	
	Dado que es un transversal tenemos que se deben cumplir las siguientes dos relaciones para $y_j \in Y$ y $t_i,t_j,t_k \in T$. 
	\begin{enumerate}
		\item $t_iy_jt_i^{-1} = u_{ij}$ donde $u_{ij} \in F$ usando que $F$ es normal.
		\item Si tenemos que $b_ib_j = b_k$ entonces $t_it_j = z_{ij}t_k$ donde $z_{ij} \in F$ usando que $(Ht_i)(Ht_j) = Ht_k$.
	\end{enumerate}
	
	Afirmamos que la siguiente es una presentación finita de $G$.
	\[
	\langle W \mid R \rangle =  \langle y_1, \dots, y_n, t_1, \dots, t_m \mid t_iy_jt_i^{-1} = u_{ij},  t_it_j = z_{ij}t_k \rangle.
	\]
	Sea el grupo que genera este presentación $H$ y sea $F'$ el grupo libre sobre sus generadores.
	
	Notemos que $W =Y \cup T$ genera a $G$ porque justamente $F$ es libre y generado por $Y$ y $T$ es un conjunto transversal finito porque $F$ tiene índice finito en $G$.
	Esto nos dice que tenemos un epimorfismo de grupos de $F'$ en el grupo $G$.
	
	Toda relación de $G'$ la cumple el grupo $G$ por la elección que tomamos, de esta manera tenemos un epimorfismo de grupos $\ol \varphi$ tal que hace conmutar al siguiente diagrama,
	
	\begin{center}
		\begin{tikzcd}
			F' \arrow[dd] \arrow[rr, "\varphi"]          &  & G \\
			&  &   \\
			H \arrow[rruu, "\overline \varphi"', dashed] &  &  
		\end{tikzcd}
	\end{center}
	
	El grupo  $G$ es tal que a toda palabra $w$ en sus generadores la podemos llevar a que sea de la pinta
	\[
	w = yt
	\]
	donde $y \in F$ reducida y $t \in T$ es alguno de los transversales. 
	Para llegar a esto hacemos el mismo procedimiento que hicimos en la demostración del lema \ref{lema_subg_fg}.
	
	De esta manera una palabra es trivial si y solamente si $y=1$ y $t=1$. 
	Esto nos dice que $\ol \varphi(w) = 1$ si y solamente si $w=1$. 
	Concluimos así que $\ol \varphi$ es un isomorfismo de grupos tal como queríamos ver y por lo tanto  $\langle W \mid R \rangle$ resultó ser una presentación de $G$.
	
\end{obs}
\medskip

Veamos ahora unos ejemplos y contrajemplos de grupos \vl s.

\begin{ej}
	Veamos algunos ejemplos elementales de grupos que son de esta familia y algunos que no lo sean.

	\begin{enumerate}	
		\item 
		\todo[inline]{Escribir bien esta flia de ejemplo que son las extensiones.}
		Cualquier extensión de un grupo libre por un grupo finito es un grupo virtualmente libre,
		\[
		1 \to F \to G \to K \to 1
		\]
		donde $K$ es un grupo finito y $F$ es un grupo \fg libre.
		En particular esto nos da los casos más elementales de productos directos y semidirectos, esto es $G= F \times K$ o bien  $G = F \ltimes K$.
		En este capítulo veremos que todo grupo \vl \ podemos considerarlo como un subgrupo de una extensión de este tipo.
		
		\item El ejemplo más sencillo de un grupo que no es \vl \ es $\ZZ \times \ZZ$.
		La primera observación es que al ser abeliano si tiene un subgrupo libre necesariamente tiene que ser isomorfo a $\ZZ$.
		
		Nos alcanza con ver que no es virtualmente $\ZZ$.
		Sea $F$ un subgrupo que es isomorfo a $\ZZ$.
		Sea $(n,m) \in \ZZ \times \ZZ$ el generador de $F$.
		Probaremos que $\ZZ \times \ZZ / F$ tiene orden infinito.
		Para eso consideraremos $(p,q) \in \ZZ \times \ZZ$	tal que $p,q$ son primos distintos y ambos coprimos con $m,n$.
		Veamos que $[(p,q)] \in \ZZ \times \ZZ / F$ tiene orden infinito.
		Si no lo fuera deberían existir $\alpha, \beta \in \ZZ$ de manera que 
		\begin{align*}
			\alpha (p,q) = \beta(n,m) 
		\end{align*}
		
		como todos son coprimos entre sí esto nos dice que $p \mid \beta$ y similarmente que $q \mid \beta$, por lo que tenemos que $q \mid \alpha$ y $p \mid \alpha$.
		Esto nos dice que se pueden escribir de esta manera
		\begin{align*}
			\alpha = p^{r_1} q^{s_1} \gamma_1 \\
			\beta = p^{r_2} q^{s_2} \gamma_2
		\end{align*}
		con $r_i, s_i \ge 1$ para $i=1,2$.
		
		Finalmente como 
		\[ 
		\alpha p = \beta n
		\]
		tenemos que $r_1+ 1 = r_2$ pero por otro lado como
		\[
		\alpha q  = \beta m
		\]
		acá tenemos que al ser $m$ coprimo con $p$ luego la multiplicidad de $p$ en la descomposición en primos de lo que está a la izquierda es $r_2 - 1 $ mientras que lo que está a la derecha es $r_2$.
		
		Esto es una contradicción que vino de suponer que $[(p,q)] \in \ZZ \times \ZZ / F$ tenía orden finito por lo tanto tenemos que $\ZZ \times \ZZ$ no puede ser \vl.
		
	\end{enumerate}
\end{ej}
\section{Teoría de lenguajes.}	

Consideremos un conjunto no vacío $\Sigma$ que llamaremos en el contexto de los lenguajes un \emph{alfabeto}. 
Dado $k \in \NN$ denotaremos $\Sigma^k$ el conjunto de sucesiones finitas de elementos de $\Sigma$ de $k$ letras.
Hacemos énfasis especial en el caso que $k=0$ denotando $\Sigma^0 = \lambda$ a la \emph{palabra vacía}.
Dada una palabra $w= a_1 \dots a_k$ con  $a_i \in \Sigma$ diremos que su longitud es $k$ y lo denotaremos $|w| = k$. 
Similarmente denotaremos $|w|_{i}$ a la cantidad ocurrencias de $a_{i}$ en $w$.



\begin{deff}
	El \emph{monoide libre} sobre un alfabeto $\Sigma$ es el siguiente conjunto
	\begin{equation*}
		\Sigma^{*} = \bigcup_{k=0}^{\infty} \Sigma^k
	\end{equation*}
	con la operación $\cdot$ que es la concatenación de palabras. 
	Es decir dadas $w_1 \in \Sigma^{k}, w_2 \in \Sigma^{l}$ luego $w_1 \cdot w_2 \in \Sigma^{k+l} \subset \Sigma^*$. El elemento neutro es la palabra vacía que corresponde a la copia de $\Sigma^0$ que es la única palabra sin letras. 
\end{deff}
\begin{obs}
	El monoide es libre con la siguiente propiedad: si tenemos una función del alfabeto $f: \Sigma \to M$ donde $M$ es algún monoide entonces existe un único morfismo de monoides $\overline f: \Sigma^{*} \to M$ que hace conmutar al siguiente diagrama.	
	
	\begin{center}
		\begin{tikzcd}
			\Sigma \arrow[r, "f"] \arrow[d, hook] & M \\
			\Sigma^* \arrow[ru, "\overline f",dashed,swap]    &  
		\end{tikzcd}
	\end{center}
	
\end{obs}

Si $w$ es una palabra sobre el alfabeto $\Sigma$ luego una subpalabra $u$ de $w$ es una palabra $u \in \Sigma^*$ tal que $w = vuz$ para algunas $v, z \in \Sigma^*$. Si $w = vu$ entonces $v$ es un prefijo de $w$ y $u$ es un subfijo de $w$.


\begin{deff}
	Un \emph{lenguaje} $L$ sobre un alfabeto $\Sigma$ es un subconjunto de $\Sigma^*$.
\end{deff}




\subsection{Gramáticas.}

\begin{deff}
	Una \emph{gramática} es una tupla ${\cal G} = (V, \Sigma, P, S)$ donde:
	\begin{itemize}
		\item $V$ es un conjunto finito denominado las \emph{variables};
		\item $S \in V$ es el \emph{símbolo inicial};
		\item $\Sigma$ es un conjunto finito disjunto de $V$ que denominamos \emph{símbolos terminales};
		\item $P \subseteq (V \cup \Sigma)^*V(V \cup \Sigma)^* \times (V \cup \Sigma)^*$ es un conjunto finito de \emph{producciones}.
	\end{itemize}
\end{deff}

Dada una gramática ${\cal G} = (V, \Sigma, P, S)$ a cualquiera de sus producciones $(\gamma, \nu) \in P$, la vamos a denotar por medio de la siguiente notación $\gamma \to \nu$. 

A partir de una gramática $\cal G$ podemos definirnos una relación sobre las cadenas $(\Sigma \cup V)^*$. 
Dados $x,y \in (\Sigma \cup V)^*$ diremos que $x$ \emph{deriva} en $y$ si existen $u,v,w,z \in (\Sigma \cup V)^*$ tales que $x = uwv$ y tenemos una producción $w \to z \in P$ de manera que $y=uzv$.
La notación que usaremos es $x \Rightarrow_{\cal G} y$. 
Consideremos la clausura transitiva y reflexiva de esta relación que denotaremos por $\deriva$.

%Dados $uAv \in (\Sigma \cup V)^* V(\Sigma \cup V)^*$ y $w \in (\Sigma \cup V)^*$ si tenemos alguna producción $uAv \to w$ diremos que $uAv$ \emph{deriva} en $w$ y lo denotaremos $uAv \Rightarrow_{\cal G} uwv $. 
%Esto nos define una relación $\Rightarrow$ sobre $(\Sigma \cup V)^*$. 
%Tomamos la clausura transitiva, simétrica y reflexiva para así obtener una relación de equivalencia que denotaremos $\deriva$.


\begin{deff}
	Dada una gramática $\cG$ consideramos el \emph{lenguaje generado por la gramática} 
	\[
	L({\cal G}) = \{ w \in \Sigma^* \ | \ S \overset{*}{\Rightarrow_{\cal G}} w   \}.
	\]
\end{deff}

Este lenguaje está formado por las palabras en $\Sigma^*$ que se pueden derivar del símbolo inicial. 

\medskip
\begin{ej}\label{gramatica-regular}
	Consideremos la siguiente gramática ${\cal G} = (V, \Sigma, P, S)$ donde $V = \{ S, A \}, \Sigma = \{ a,b \}$ y tenemos las siguientes producciones,
	\begin{align*}
		S & \to Ab \\
		A & \to aA \mid \lambda 
	\end{align*}
	donde usamos $\mid$ para separar distintas producciones que tienen el mismo lado izquierdo.
	
	Veamos como podemos derivar la palabra $a^2b$ usando las producciones de esta gramática. 
	Esto es que $S \deriva a^2b$.
	Tomamos la siguiente sucesión:
	\begin{align*}
		S \to Ab \to aAb \to aaAb \to aab
	\end{align*} 
	y nos queda tal como queríamos ver.
	
	Más aún probemos que $L({\cal G}) = \{ a^{k}b : k \ge 0 \}$. 
	
	Si $w \in L(\cal G)$ entonces $S \deriva w$ por definición. 
	La única producción que la gramática tiene donde $S$ está a la izquierda es $S \to Ab$. 
	De esta manera cualquier palabra $w \in L(\cal G)$ va a tener una $b$ como postfijo de la palabra. 
	La variable $A$ vemos que solo puede derivar en $a^{k}A$ o $a^{k}$ para $k \ge 0$.
	Esto se debe a que podemos aplicar la producción $A \to aA$ tantas veces como querramos por lo tanto $A \deriva a^k$ para cualquier $k \ge 0$.
	Juntando con lo anterior vemos que $S \deriva a^{k}b$ así que terminamos de ver que la gramática genera al lenguaje $\{a^kb : k \ge 0\}$ tal como queríamos ver.
\end{ej}



Es posible clasificar los lenguajes a partir de las características de las gramáticas que los generan. 

\subsection{Lenguajes regulares.}

\begin{deff}
	Decimos que una gramática $\gramatica$ es \emph{regular} si las producciones son del estilo
	\begin{enumerate}
		\item $A \to \lambda$
		\item $A \to a$
		\item $A \to a B$
	\end{enumerate}
	donde $A, B \in V$, $a \in \Sigma$ y $\lambda$ es la palabra vacía. 
	Si $L=\lengderivado$ para alguna gramática regular $\cal G$ entonces diremos que $L$ es un \emph{lenguaje regular}. 
\end{deff}

En particular la gramática del ejemplo \ref{gramatica-regular} es regular. 
De esta manera $L= \{ a^k b : \ k \ge 0  \}$ resulta ser un lenguaje regular.


\begin{deff}
	Un \emph{autómata finito no determinístico} es una tupla ${\cal M} = (Q,\{q_0\},\Sigma,\delta,F)$ donde:
	\begin{itemize}
		\item $Q$ es un conjunto finito que denominamos \emph{estados}.
		\item $q_0 \in Q$ es el \emph{estado inicial}.
		\item $\Sigma$ es un conjunto finito que denominamos \emph{alfabeto}.
		\item $\delta:Q \times \Sigma \to {\cal P}(Q)$ es la \emph{función de transición}.
		\item $F \subseteq Q$ es un subconjunto de estados que llamaremos \emph{finales}.
	\end{itemize}
\end{deff}

Un par $(q,w) \in Q \times \Sigma^*$ lo llamaremos una configuración del automáta.
Consideremos que $w = aw'$ donde $a \in \Sigma$ y $w' \in \Sigma^*$ luego si tenemos que $p \in \delta(q,a) $ entonces denotaremos esto así $(q,w) \vdash (p,w')$.
Esto nos define una relación sobre $Q \times \Sigma^*$ tal que si tomamos la clausura transitiva y simétrica obtenemos una relación de equivalencia sobre este conjunto.


\begin{deff}
	El lenguaje generado por un autómata finito no determinístico $M$ es
	
	\[
	L({\cal M} ) = \{  w \in \Sigma^*, q_F \in F \mid (q_1,w) \vdash^* (q_F,\lambda)     \}
	\]
	
	
\end{deff}

\begin{obs}
	Al ser un autómata finito no determinístico existen posiblemente más de una manera de consumir alguna palabra en el autómata. 
	Es así que por la definición que dimos la palabra es aceptada por el autómata si al menos alguna de estas derivaciones la lleva a ser aceptada.
	No importa si existen algunas que no lo hagan mientras una sí lo haga. 
\end{obs}

%Como vimos en este ejemplo el lenguaje $L = \{ a^kb \ : \ k \ge 0  \}$ es aceptado por un automáta no determinístico finito y por lo que sabíamos del ejemplo \ref{gramatica-regular} es un lenguaje regular.
Vale que los lenguajes aceptados por automátas finitos no determinísticos son justamente los regulares.

\begin{teo}
	Un lenguaje $L$ es regular sii es aceptado por un autómata finito no determínistico.
\end{teo}

\begin{proof}
	Demostración estándar. Ver \cite{hopcraft-ullman}.
\end{proof}




%definición automáta finito
%definición de lenguaje regular por medio del automáta, las otras defs no son necesarias
% comentar que los regulares son cerrados para grupos? quizá pueda servir para después





\subsection{Lenguajes independientes de contexto.}
\begin{deff}
	Una gramática $\gramatica $ es \emph{independiente de contexto} si las producciones tienen la siguiente forma:
	\begin{equation*}
		A \to w
	\end{equation*}
	donde $A \in V, w \in (\Sigma \cup V)^*$.  
	Si $L=\lengderivado$ para alguna gramática independiente de contexto $\cal G$ entonces diremos que $L$ es un \emph{lenguaje independiente de contexto}.
\end{deff}

\begin{obs}
	Todo lenguaje regular en particular resulta ser un lenguaje \ic.
\end{obs}


\begin{ej}\label{leng_ej_gram_palindromos}
	Sea el alfabeto $\Sigma = \{ a,b \}$. Si $w=a_1 \dots a_k$ es una palabra sobre $\Sigma^*$ entonces podemos considerar a $w^r$ que es la palabra inversa dada por leerla de derecha a izquierda y tiene la siguiente pinta $w^r= a_k \dots a_1$. 
	Consideremos sobre $\Sigma$ el lenguaje 
	\[
	L = \{ w \in \Sigma^* \ | \ w = w^r  \}
	\]
	tal que este es el lenguaje de los palíndromos. 
	Construyamos una gramática independiente de contexto para este lenguaje.
	Sea $w$ una palabra en $L$ luego sabemos que si su longitud es mayor que uno entonces debe ser que $w = a u a$ o $w = b u b$ para cierta palabra $u \in L$ dado que $u$ necesariamente tiene que ser un palíndromo porque $w$ lo es. 
	Esto sucede para todas las palabras del lenguaje exceptuando las palabras de longitud uno que son justamente las letras del alfabeto. 
	De esta manera podemos considerar la siguiente gramática ${\cal G}  =  (\{S\}, \Sigma, P, S )$ donde las producciones $P$ están dadas por:
	\begin{equation*}
		S  \to \lambda \\ \mid a \\ S  \mid  b \\ \mid aSa \\ \mid bSb. \\
	\end{equation*}

	Para ver que esta gramática genera al lenguaje $L$ notemos que si tomamos una palabra en el lenguaje $w \in L$ luego si no es una letra al ser palíndromo sobre el alfabeto $\Sigma$ necesariamente debe comenzar con $a$ o con $b$ y de esta manera tenemos que la primer derivación es $S \to aSa$ o $S \to bSb$. 
	Dado que la subpalabra $w = aua$ que se obtiene de $w$ sin considerar la primera y última letra es un palíndromo (e incluso podría ser la palabra vacía) luego podemos repetir este proceso para llegar a $S \deriva w$ después de finitos pasos. 
	Por otro lado toda palabra generada por esta gramática es un palíndromo porque todas las reglas son tales que agregan una letra al principio y la misma al final o simplemente agregan letras que también son palíndromos.
\end{ej}

Toda gramática independiente de contexto la podemos tomar para que sea de una forma en particular.

\begin{deff}
	Una gramática $\gramatica$ independiente de contexto está en su \emph{forma normal de Chomsky} si las producciones son de este tipo:
	\begin{enumerate}
		\item[\textbf{CH1.}] $A \to BC$ donde $A\in V$ y $B,C \in V \setminus \{ S \}$.
		\item[\textbf{CH2.}] $A \to a$ donde $A \in V, a \in \Sigma$.
		\item[\textbf{CH3.}] $S \to \lambda$ 
	\end{enumerate}
\end{deff}



\begin{prop}
	Para toda gramática $\cal G$ independiente de contexto puede tomar otra $\cal G'$ tal que esté en forma normal de Chomsky y $\lengderivado = L(\cal G')$,
\end{prop}

\begin{proof}
	Demostración estándar. Ver \cite{hopcraft-ullman}.
\end{proof}

\subsection{Autómatas de pila.}

\begin{deff}
	Un \emph{autómata de pila finito no determinístico} es una tupla 
	\[
	{\cal M } = (Q, \Sigma, Z, \delta, q_0, F, Z_0)
	\]
	donde:
	\begin{itemize}
		\item $Q$ es un conjunto finito denominado los \emph{estados};
		\item $\Sigma$ es un conjunto finito que denominamos el \emph{alfabeto del lenguaje};
		\item $\Gamma$ es un conjunto finito que denominamos el \emph{alfabeto de la pila};
		\item $\delta$ es la \emph{función de transición} donde $\delta: Q  \times \Sigma \cup \{ \lambda \} \times \Gamma \cup \{ \lambda \} \to {\cal P}( Q  \times \Gamma)$;
		\item $F \subseteq Q$ es el conjunto de \emph{estados finales};
		\item $q_0 \in Q$ es el \emph{estado inicial};
	\end{itemize}
\end{deff}

\begin{obs}
	Bajo esta definición de un \APND notemos que no hay transición posible si en el tope de la pila está el símbolo inicial de la pila. 
\end{obs}


Una configuración de un autómata de pila no determinístico va a ser un triple $(q,w,\gamma) \in Q \times \Sigma^* \times Z^*$.
Sea $w = aw'$ con $a \in \Sigma$ y $w' \in \Sigma^*$ tal que $(p,\gamma') \in \delta (q,a,\gamma)$ luego denotaremos $(q,w,\gamma) \vdash_{\cal M} (p,w',\gamma')$ la transición de una configuración en otra en el \APND $\cal M$.
Esta operación nos define una relación sobre $Q \times \Sigma^* \times Z^*$.
Consideremos la relación de equivalencia generada por la clausura transitiva y simétrica de esta operación.
Así como en el caso de los autómatas finitos la denotaremos $\vdash^*_{\cal M}$.


\begin{deff}
	Dado $\cal M$ un autómata de pila no determinístico consideramos el lenguaje generado por estado final como
	\begin{equation*}
		L( {\cal M}) = \{ w \in \Sigma^* \ | \ (q_0,w,Z_0) \vdash^* (q, \lambda, \gamma), \ \ q \in F, \ \gamma \in \Gamma^*      \}
	\end{equation*}
\end{deff}


%\paragraph{Descripción instantánea del autómata.} Veamos ahora como describir formalmente el funcionamiento de un autómata a partir de lo que estamos haciendo en cierto instante. 
%Consideremos que estamos en el instante que nuestra subpalabra que nos queda por leer es $w$, estamos en un estado $q$ y en nuestra pila tenemos la palabra $\gamma$, entonces vamos a representar al instante por medio de esta tupla $(q,w,\gamma)$.
%Si ahora tenemos la posibilidad de movernos a otro estado $p$ tal que $(p,w',\alpha\beta) \in \delta (q,aw',x\beta)$ donde $aw' = w$ con $a$ alguna letra posiblemente vacía y similarmente $x \beta = \gamma$ con $x \in \Gamma^*$ una letra de $\Gamma$ posiblemente vacía. 
%Este movimiento lo denotamos como $(q,aw',x\beta) \vdash (p,w',\alpha \beta)$. 
%Podemos considerar la clausura transitiva de esta relación sobre los triples $Z \times Q \times \Sigma^*$ que denotaremos $\vdash^*$.


%\paragraph{Funcionamiento del autómata.}
%Un prefijo de $w$ será una subpalabra $\gamma$ tal que $w=\gamma w'$ visto con la concatenación de palabras en $\Sigma^*$.
%
%El autómata de pila finito funciona de la siguiente manera. 
%Dada una palabra $w \in \Sigma$ queremos saber si es aceptada por el autómata de pila o no. Para eso vamos a ir leyendo esta palabra de izquierda a derecha. 
%Al comenzar a leer esta palabra estamos en el estado $q_0$ que distinguimos como el estado inicial de nuestro autómata. 
%Nos fijamos en la función de transición que es una función parcial cuánto nos da evaluada  $\delta(\lambda,q_0,\gamma)$ para algún $\gamma$ prefijo de $w$ y donde estamos mirando a $\lambda \in Z^*$ el elemento neutro de este monoide. 
%Esto se corresponde a la idea de que al comenzar nuestra pila está vacía. 
%En tal caso nuestra función de transición nos da un resultado que es un par $(z,q)$ donde $z \in Z^{*}$ es lo que nos va a quedar en la pila y $q$ es el nuevo estado al cual nos movimos. 
%Notemos que nuestra función de transición no tiene porqué tener un $(z,q)$ tal que podamos movernos o podría ser bien que tenga más de uno. 
%En este caso diremos que nuestro autómata es \emph{no determinístico} dado que en algunos casos existe más de una opción.
%
%En general estamos en la siguiente situación en el proceso de aceptar la palabra $w$. 
%Tenemos algún $z \in Z$ en el tope de la pila que al ser una pila lo leeremos de derecha a izquierda, estamos en algún estado $q \in Q$ y nos quedará una subpalabra $\gamma$ de $w$ para leer. Una \emph{configuración} de nuestro autómata entonces es una manera de describir en que situación de aceptar o no aceptar una palabra y la denotamos $(z,q,\gamma)$. 
%
%Cuando hayamos visto toda la palabra o no tengamos manera de movernos de estado nos fijamos si el estado $p$ en el que estamos es final, es decir si $p \in F$. 
%En tal caso la palabra $w$ es aceptada por el autómata. Formalmente estaremos en alguna configuración $zq$ para $z \in Z^*$ y $q \in Q$ y no nos queda nada de la palabra $w$ porque ya la consumimos toda.
%\medskip
%\begin{obs}
%	Así como definimos el \APND para que al tener la pila vacía se detenga podríamos haberlo hecho de una manera distinta por ejemplo dejando que la pila sea vacía y así poder transicionar de una configuración a otra.	
%	Esta manera es equivalente porque...
%	Más en adelante nos va a resultar conceptualmente más útil para el caso que estemos viendo el problema de la palabra de un grupo mientras que para las demostraciones de esta sección usaremos esta otra definición.
%\end{obs}



%
%\paragraph{El lenguaje aceptado por un autómata de pila.} 
%Notemos que en particular el autómata de pila nos da un lenguaje que está formado por las palabras $w$ en el alfabeto de la entrada del autómata $\Sigma$ que son aceptadas. 
%En general diremos que un autómata acepta un lenguaje $L$ si su lenguaje aceptado es exactamente $L$. 
%Este lenguaje aceptado por el autómata $\cal M$ en algunas casos para hacer énfasis en el autómata 


\begin{ej}
	Sea nuestro alfabeto $\Sigma = \{ a, b\}$ y $L$ el lenguaje de los palíndromos sobre este alfabeto tal como lo definimos en el ejemplo \ref{leng_ej_gram_palindromos}.
	Consideremos el siguiente autómata de pila 
	\[
	M=(Q,\{a,b\}, \{a,b,\$\} , \delta, q_0, \{q_1\}, \$)
	\]
	donde nuestra pila tiene el mismo alfabeto que el de entrada con un símbolo adicional que va funcionar como nuestro símbolo inicial de la pila. 
	El autómata tiene dos estados, el inicial y el final. 
	Al automáta de pila lo representaremos de la siguiente manera:
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,
			scale = 1,transform shape]
			
			\node[state,initial] (q_0) {$q_0$};
			\node[state,accepting] (q_1) [right of=q_0] {$q_1$};
			
			\path (q_0) edge [bend right]             node {} (q_1);
			\path (q_1) edge [loop above] node {}    (   );
			\path (q_0) edge [loop above] node {}    (   );
		\end{tikzpicture}
	\end{center}
	
	La idea es que en el primer estado vamos apilando la palabra y en la segunda vamos desapilando la palabra anteriormente apilada. 
	Nuestra función de transición $\delta$ va a ser la siguiente,
	\begin{itemize}
		\item $\delta(q_0,a,Z) = (q_0,aZ)$ 
		\item $\delta(q_0,b,Z) = (q_0,ba)$ 
		\item $\delta(q_1,a,a) = (q_0,\lambda)$.
		\item $\delta(q_1,b,b) = (q_0,\lambda)$.
		\item $\delta (q_0, \lambda, Z) = (q_1,Z)$
		\item $\delta (q_0, X, Z) = (q_1, Z)$ 
	\end{itemize}
	donde $Z$ es decir cualquier elemento del alfabeto de la pila y $X$ cualquier elemento de nuestro alfabeto de entrada. 
	El autómata en el primer estado apila lo que sea que estemos leyendo sin importar lo que esté en el tope de pila. 
	En el segundo estado desapila cada vez que lo que estemos leyendo coincida con el tope de pila. 
	Finalmente para ir del estado inicial al final tenemos en cuenta dos casos. 
	Nos podemos mover por $\lambda$ es decir sin consumir ninguna letra de la palabra de la entrada o leyendo alguna de las letras de la palabra. 
	Estos casos se corresponden a que el palíndromo tenga longitud par o tenga longitud impar.	
\end{ej}

Este ejemplo nos da un indicio que los lenguajes aceptados por autómatas de pila también podrían ser \ic y esto efectivamente es cierto.

\medskip

\begin{teo}\label{teo_ic_apnd}
	Un lenguaje $L$ es independiente de contexto sii es aceptado por un autómata de pila no determinístico.
\end{teo}

\begin{proof}
	%Demo importante diría si bien es super estándar y conocidísimo el resultado.
	Ver \cite{hopcraft-ullman}.
\end{proof}



Hasta ahora definimos los autómatas de pila no determinísticos que aceptan por estado final. Otra definición posible de lenguaje aceptado podría ser que acepten por pila vacía. 
Es decir que una vez que consumimos la palabra $w$ de entrada llegamos a una configuración $(q, \lambda, \lambda)$ donde $\lambda$ es la palabra vacía de ambos alfabetos respectivamente. Formalmente dado un autómata de pila $\cal M$  notaremos al lenguaje aceptado por pila vacía de la siguiente manera,
\begin{equation*}
	N({\cal M}) = \{ w \in \Sigma^* \ | \ (q_0,w,Z_0) \vdash^* (q, \lambda, \lambda), \ q \in Q, u \in \Sigma^*    \}
\end{equation*}
donde arrancamos en el estado inicial y llegamos a algún estado $q$ cualesquiera sin importar que sea final o no.
La pila está vacía así como lo que nos queda por leer de la palabra. 
En este caso diremos que nuestro lenguaje es aceptado por un autómata de pila no determinístico por pila vacía.


El siguiente resultado nos dice que en el caso que nuestro autómata sea no determinístico es equivalente usar una u otra manera de definir a nuestro lenguaje.

\medskip
\begin{teo}
	Un lenguaje $L$ es aceptado por un autómata de pila no determinístico por estado final si y solo sí es aceptado por un autómata de pila no determinístico por pila vacía.
\end{teo}

\begin{proof}
	%Demo bastante fácil si se hacen los dibujitos. Quizá ni haga falta escribirla.
	Ver \cite{hopcraft-ullman}.
\end{proof}
















































\end{document}