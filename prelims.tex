\documentclass[tesis.tex]{subfiles}
\begin{document}

\chapter{Preliminares.}


En este capítulo introduciremos notación y varios resultados estándares que utilizaremos a lo largo de la tesis.

En la primera sección \ref{secc_tlen} introduciremos ágilmente resultados estándares de la teoría de lenguajes junto con algunos ejemplos para ilustrar todas estas definiciones.
En particular nos interesará especialmente para este trabajo la definición de los lenguajes \ic que introduciremos en la subsección \ref{subs_ic}. 


En la segunda sección \ref{secc_teo_grp} introduciremos notación y probaremos algunos resultados  sobre grupos finitamente generados. 


Finalmente en \ref{secc_graf_nd} introducimos la notación que usaremos para los grafos no dirigidos, daremos una definición de los grafos de Cayley de un grupo y probaremos un resultado \ref{lema_cayley_libre_arbol} sobre los grafos de Cayley de los grupos libres que nos servirá más en adelante para guiarnos en la caracterización de los grafos de Cayley de los grupos virtualmente libres.


\section{Teoría de lenguajes.}\label{secc_tlen}	


Consideremos un conjunto no vacío $\Sigma$ luego dado $k \in \NN$ denotaremos $\Sigma^k$ al conjunto de palabras en $\Sigma$ de exactamente $k$ elementos.
Hacemos énfasis especial en el caso que $k=0$ denotando $\Sigma^0 = \epsilon$ a la \emph{palabra vacía}.
Dada una palabra $w= a_1 \dots a_k \in \Sigma^k$ diremos que su longitud es $k$ y lo denotaremos $|w| = k$. 
Similarmente si $ \Sigma = \{ a_{i} \}_{i \in I} $ denotaremos $|w|_{i}$ a la cantidad ocurrencias de $a_{i}$ en $w$.



\begin{deff}
	Dado $\Sigma$ conjunto consideramos
	\begin{equation*}
		\Sigma^{*} = \bigcup_{k=0}^{\infty} \Sigma^k
	\end{equation*}
	y una operación binaria
	\[
		\cdot: \Sigma^{*} \times \Sigma^{*} \to \Sigma^{*}
	\]
	que llamaremos la \emph{concatenación de palabras} y que definimos de la siguiente manera: 
	dadas $w_1=a_{1}^1 \dots a_{k}^1 \in \Sigma^{*}, w_2 = a_{1}^{2} \dots a_{l}^{2} \in \Sigma^{*}$ luego $w_1 \cdot w_2 = a_{1}^1 \dots a_{k}^1 a_{1}^{2} \dots a_{l}^{2} $.
	Esta operación es asociativa y tiene como elemento neutro a $\epsilon$.
	De esta manera obtenemos que $(\Sigma^{*}, \cdot)$ es un monoide que llamaremos el \emph{monoide libre} sobre $\Sigma$.
\end{deff}

Este monoide también puede ser caracterizado salvo isomorfismo por una propiedad universal.

\begin{obs}
	El monoide es libre con la siguiente propiedad universal: si tenemos una función de conjuntos $f: \Sigma \to M$ donde $M$ es algún monoide entonces existe un único morfismo de monoides $\overline f: \Sigma^{*} \to M$ que hace conmutar al siguiente diagrama.	
	
	\begin{center}
		\begin{tikzcd}
			\Sigma \arrow[r, "f"] \arrow[d, hook] & M \\
			\Sigma^* \arrow[ru, "\overline f",dashed,swap]    &  
		\end{tikzcd}
	\end{center}
	
\end{obs}

Una \emph{palabra} sobre $\Sigma$ es un $w \in \Sigma^*$.
Si $w $ es una palabra sobre el alfabeto $\Sigma$ luego una \emph{subpalabra} $u$ de $w$ es una palabra $u \in \Sigma^*$ tal que $w = vuz$ para algunas $v, z \in \Sigma^*$. 
Si $w = vu$ entonces $v$ es un \emph{prefijo} de $w$ y $u$ es un \emph{subfijo} de $w$.


\begin{deff}
	Un \emph{lenguaje} $L$ sobre un alfabeto $\Sigma$ es un subconjunto de $\Sigma^*$.
\end{deff}

\begin{deff}
	Sea $\Sigma$ conjunto finito.
	Dados lenguajes $L_{1}, L_{2} \subseteq \Sigma^*$ definimos el \emph{cociente a derecha de $L_{1}$ por $L_{2}$} como el siguiente lenguajes
	\[
	L_{1}/L_{2} = \{ w \in \Sigma^* \mid \exists x \in L_{2}: wx \in L_{1}    \}
	\]
	Análogamente definimos el cociente a izquierda $L_{2} \backslash L_{1}$.
\end{deff}
Destacamos el caso particular que $L_{1} = \{w\}$ un lenguaje formado con una única palabra y que $L_{2} = \Sigma^*$.
En este caso tenemos que $L_{1}/\Sigma^* = \{  x \in \Sigma^*  \mid x \ \text{es prefijo de} \ w  \}$.
Usaremos para este caso especial la notación $ \text{Pre}(w) = \{w\}/\Sigma^*$.




\subsection{Gramáticas.}

\begin{deff}
	Una \emph{gramática} es una tupla ${\cal G} = (V, \Sigma, P, S)$ donde:
	\begin{itemize}
		\item $V$ es un conjunto finito denominado las \emph{variables};
		\item $S \in V$ es el \emph{símbolo inicial};
		\item $\Sigma$ es un conjunto finito disjunto de $V$ que denominamos \emph{símbolos terminales};
		\item $P \subseteq (V \cup \Sigma)^*V(V \cup \Sigma)^* \times (V \cup \Sigma)^*$ es un conjunto finito de \emph{producciones}.
	\end{itemize}
\end{deff}

Dada una gramática ${\cal G} = (V, \Sigma, P, S)$ a cualquiera de sus producciones $(\gamma, \nu) \in P$, la vamos a denotar por medio de la siguiente notación $\gamma \to \nu$. 

A partir de una gramática $\cGg$ vamos a definir una relación sobre $(\Sigma \cup V)^*$. 
Dados $x,y \in (\Sigma \cup V)^*$ diremos que $x$ \emph{deriva} en $y$ si existen $u,v,w,z \in (\Sigma \cup V)^*$ tales que $x = uwv$ e $y=uzv$ y tenemos una producción $w \to z \in P$.
La notación que usaremos es $x \Rightarrow_{\cal G} y$. 
Consideremos la clausura transitiva y reflexiva de esta relación que denotaremos por $\deriva$.

%Dados $uAv \in (\Sigma \cup V)^* V(\Sigma \cup V)^*$ y $w \in (\Sigma \cup V)^*$ si tenemos alguna producción $uAv \to w$ diremos que $uAv$ \emph{deriva} en $w$ y lo denotaremos $uAv \Rightarrow_{\cal G} uwv $. 
%Esto nos define una relación $\Rightarrow$ sobre $(\Sigma \cup V)^*$. 
%Tomamos la clausura transitiva, simétrica y reflexiva para así obtener una relación de equivalencia que denotaremos $\deriva$.


\begin{deff}
	Dada una gramática $\cGg$  definimos el \emph{lenguaje generado por la gramática} como
	\[
	L({\cal G}) = \{ w \in \Sigma^* \ | \ S \overset{*}{\Rightarrow_{\cal G}} w   \}.
	\]
\end{deff}

Este lenguaje está formado por las palabras en $\Sigma^*$ que se pueden derivar del símbolo inicial.
De esta manera una gramática la podemos pensar como un conjunto de reglas que nos permite generar un lenguaje. 
 

\medskip
\begin{ej}\label{gramatica-regular}
	Consideremos la siguiente gramática ${\cal G} = (V, \Sigma, P, S)$ donde $V = \{ S, A \}, \Sigma = \{ a,b \}$ y tenemos las siguientes producciones,
	\begin{align*}
		S & \to Ab \\
		A & \to aA \mid \epsilon 
	\end{align*}
	donde usamos $\mid$ para separar distintas producciones que tienen el mismo lado izquierdo.
	
	Veamos como podemos derivar la palabra $a^2b \in \Sigma^*$ usando las producciones de esta gramática. 
	Esto es que $S \deriva a^2b$.
	Tomamos la siguiente sucesión:
	\begin{align*}
		S \to Ab \to aAb \to aaAb \to aab
	\end{align*} 
	y nos queda tal como queríamos ver.
	
	Más aún probemos que $L({\cal G}) = \{ a^{k}b : k \ge 0 \}$. 
	
	Si $w \in L(\cal G)$ entonces $S \deriva w$ por definición. 
	La única producción que la gramática tiene donde $S$ está a la izquierda es $S \to Ab$. 
	De esta manera cualquier palabra $w \in L(\cal G)$ va a tener una $b$ como postfijo de la palabra. 
	La variable $A$ vemos que solo puede derivar en $a^{k}A$ o $a^{k}$ para $k \ge 0$.
	Esto se debe a que podemos aplicar la producción $A \to aA$ tantas veces como querramos por lo tanto $A \deriva a^k$ para cualquier $k \ge 0$.
	Juntando con lo anterior vemos que $S \deriva a^{k}b$ así que terminamos de ver que la gramática genera al lenguaje $\{a^kb : k \ge 0\}$ tal como queríamos ver.
\end{ej}



Es posible clasificar los lenguajes a partir de las características de las gramáticas que los generan. 

\subsection{Lenguajes regulares.}

\begin{deff}
	Decimos que una gramática $\gramatica$ es \emph{regular} si las producciones son del estilo
	\begin{enumerate}
		\item $A \to \epsilon$
		\item $A \to a$
		\item $A \to a B$
	\end{enumerate}
	donde $A, B \in V$, $a \in \Sigma$ y $\epsilon$ es la palabra vacía. 
	Si $L=\lengderivado$ para alguna gramática regular $\cal G$ entonces diremos que $L$ es un \emph{lenguaje regular}. 
\end{deff}

En particular la gramática del ejemplo \ref{gramatica-regular} es regular. 
De esta manera $L= \{ a^k b : \ k \ge 0  \}$ resulta ser un lenguaje regular.


\begin{deff}
	Un \emph{autómata finito no determinístico} es una tupla ${\cal M} = (Q,q_0,\Sigma,\delta,F)$ donde:
	\begin{itemize}
		\item $Q$ es un conjunto finito que denominamos \emph{estados}.
		\item $q_0 \in Q$ es el \emph{estado inicial}.
		\item $\Sigma$ es un conjunto finito que denominamos \emph{alfabeto}.
		\item $\delta:Q \times \Sigma \to {\cal P}(Q)$ es la \emph{función de transición}.
		\item $F \subseteq Q$ es un subconjunto de estados que llamaremos \emph{finales}.
	\end{itemize}
\end{deff}

Un par $(q,w) \in Q \times \Sigma^*$ lo llamaremos una \emph{configuración} del autómata.
Consideremos que $w = aw'$ donde $a \in \Sigma$ y $w' \in \Sigma^*$ luego si tenemos que $p \in \delta(q,a) $ entonces denotaremos esto así $(q,w) \vdash (p,w')$ y diremos que .
Esto nos define una relación sobre $Q \times \Sigma^*$ tal que su clausura transitiva y reflexiva 
la denotaremos $\vdash^*$.


\begin{deff}
	Dado un autómata finito no determinístico $\cal M$ el \emph{lenguaje generado} por $M$ es el siguiente
	
	\[
	L({\cal M} ) = \{  w \in \Sigma^*, q_F \in F \mid (q_0,w) \vdash^* (q_F,\epsilon)     \}.
	\]
\end{deff}
\medskip

Así como las gramáticas generan lenguajes pensamos que los autómatas aceptan lenguajes.
Más en particular dado ${\cal M} = (Q,\{q_0\},\Sigma,\delta,F)$ autómata finito no determinístico y $w \in \Sigma^*$ palabra diremos que $\cal M$ \emph{acepta} a $w$ si $w \in L(\cal M)$.
Una manera de \emph{consumir} la palabra $w$ es una sucesión $(q_0,w) \vdash (q_{i_{1}}, w_{i_{1}}) \vdash^{*} (q_{i_{n}}, \epsilon)$.

\medskip

\begin{obs}
	Decimos que estos autómatas son no determinísticos porque dada una configuración del autómata tenemos más de un estado al cual podemos acceder por medio de la función de transición.
	Esto nos dice que existen posiblemente más de una manera de consumir alguna palabra en el autómata. 
	Es así que por la definición que dimos la palabra es aceptada por el autómata si al menos alguna de estas maneras de consumirla la lleva a ser aceptada.
	Es importante notar que no importa si existen algunas que no lo hagan mientras que exista una que sí lo haga. 
\end{obs}

Vale que los lenguajes aceptados por automátas finitos no determinísticos son justamente los regulares.

\begin{teo}
	Un lenguaje $L$ es regular si y solo sí es aceptado por un autómata finito no determínistico.
\end{teo}

\begin{proof}
	Ver \cite{hopcraft-ullman}.
\end{proof}


\subsection{Lenguajes independientes de contexto.} \label{subs_ic}
\begin{deff}
	Una gramática $\gramatica $ es \emph{independiente de contexto} si las producciones tienen la siguiente forma:
	\begin{equation*}
		A \to w
	\end{equation*}
	donde $A \in V, w \in (\Sigma \cup V)^*$.  
	Si $L=\lengderivado$ para alguna gramática independiente de contexto $\cal G$ entonces diremos que $L$ es un \emph{lenguaje independiente de contexto}.
\end{deff}

\begin{obs}
	Todo lenguaje regular en particular resulta ser un lenguaje \ic.
\end{obs}


\begin{ej}\label{leng_ej_gram_palindromos}
	Sea el alfabeto $\Sigma = \{ a,b \}$. Si $w=a_1 \dots a_k$ es una palabra sobre $\Sigma^*$ entonces podemos considerar a $w^r$ que es la palabra inversa dada por leerla de derecha a izquierda y tiene la siguiente pinta $w^r= a_k \dots a_1$. 
	Consideremos sobre $\Sigma$ el lenguaje 
	\[
	L = \{ w \in \Sigma^* \ | \ w = w^r  \}
	\]
	tal que este es el lenguaje de los palíndromos. 
	Construyamos una gramática independiente de contexto para este lenguaje.
	Sea $w$ una palabra en $L$ luego sabemos que si $|w| > 1$ entonces debe ser que $w = a u a$ o $w = b u b$ para cierta palabra $u \in L$ que cumple que es un palíndromo porque $w$ lo es. 
	Esto sucede para todas las palabras del lenguaje exceptuando las palabras $w$ tales que $|w|=1$ que en nuestro caso en particular resultan ser dos palabras $w=a$ o bien $w = b$. 
	De esta manera podemos considerar la siguiente gramática ${\cal G}  =  (\{S\}, \Sigma, P, S )$ donde las producciones $P$ están dadas por:
	\begin{equation*}
		S  \to \epsilon \\ \mid a \\ S  \mid  b \\ \mid aSa \\ \mid bSb. \\
	\end{equation*}

	Para ver que esta gramática genera al $L$ notemos que si tomamos una palabra en el $w \in L$ tal que $|w| > 1$ entonces necesariamente debe comenzar con $a$ o con $b$ y de esta manera tenemos que la primer producción es $S \to aSa$ o $S \to bSb$. 
	Dado que la subpalabra $w = aua$ que se obtiene de $w$ sin considerar la primera y última letra es un palíndromo (e incluso podría ser la palabra vacía) luego podemos repetir este proceso para llegar a $S \deriva w$ después de finitos pasos. 
	Por otro lado toda palabra generada por esta gramática es un palíndromo porque todas las reglas son tales que agregan una letra al principio y la misma al final o simplemente agregan letras que también son palíndromos.
\end{ej}

Las gramáticas pueden ser modificadas de manera que sigan generando el mismo lenguaje, en el caso de las gramáticas independiente de contexto las podemos llevar a una forma normal.

\begin{deff}
	Una gramática $\gramatica$ independiente de contexto está en \emph{forma normal de Chomsky} si las producciones son de este tipo:
	\begin{enumerate}[i)]
		\item $A \to BC$ donde $A\in V$ y $B,C \in V \setminus \{ S \}$.
		\item $A \to a$ donde $A \in V, a \in \Sigma$.
		\item $S \to \epsilon$ 
	\end{enumerate}
\end{deff}

\begin{prop}\label{prop_fn_Chomsky}
	Dada una gramática $\cal G$ independiente de contexto podemos tomarnos otra gramática $\cal G'$ tal que esté en forma normal de Chomsky y $\lengderivado = L(\cal G')$,
\end{prop}

\begin{proof}
	Ver \cite{hopcraft-ullman}.
\end{proof}

\subsection{Autómatas de pila.}

\begin{deff}\label{deff_apnd}
	Un \emph{autómata de pila finito no determinístico} es una tupla 
	\[
	{\cal M } = (Q, \Sigma, \Gamma, \delta, q_0, F, Z_0)
	\]
	donde 
	\begin{itemize}
		\item $Q$ es un conjunto finito denominado los \emph{estados};
		\item $\Sigma$ es un conjunto finito que denominamos el \emph{alfabeto del lenguaje};
		\item $\Gamma$ es un conjunto finito que denominamos el \emph{alfabeto de la pila};
		\item $\delta$ es la \emph{función de transición} donde $\delta: Q  \times \Sigma \cup \{ \epsilon \} \times \Gamma \to {\cal P}( Q  \times \Gamma^*)$;
		\item $q_0 \in Q$ es el \emph{estado inicial};
		\item $F \subseteq Q$ es el conjunto de \emph{estados finales};
		\item $Z_{0} \in \Gamma$ es el \emph{símbolo inicial} de la pila
	\end{itemize}
\end{deff}

Una \emph{configuración} de un autómata de pila no determinístico va a ser un triple $(q,w,\gamma) \in Q \times \Sigma^* \times \Gamma^*$.
Dada una configuración de un autómata de pila no determinístico $(q,w, Z\gamma)$ diremos que $Z \in \Gamma$ es el \emph{tope de la pila}.
Intuitivamente es lo último que apilamos en nuestra pila.
La función de transición es tal que dada $(q,a,Z) \in Q  \times \Sigma \cup \{ \epsilon \} \times \Gamma $ nos devuelve un par $(p,\gamma)$ de manera que $\gamma \in \Gamma^{*}$ es la palabra que reemplaza al tope de la pila.
Vamos a tener las siguientes tres maneras de modificar el tope de la pila a través de la función de transición que lo haremos con la siguiente notación:

\begin{enumerate}
	\item Si $\delta(q,a,Z) = (p,\epsilon)$ luego eliminamos el tope de la pila.
	\item Si $\delta(q,a,Z) =  (p,Z)$ luego dejamos el mismo tope de pila.
	\item Si $\delta(q,a,Z) = (p, XZ)$ luego cambiamos el tope de pila por $X$ y dejamos a $Z$ apilada.
\end{enumerate}


Esto nos define una relación sobre el conjunto de todas las transiciones de un autómata de pila no determinístico.
Sea $(q,w,\gamma)$ una configuración entonces sean $w = aw'$ con $a \in \Sigma \cup \{ \epsilon \}$ y $w' \in \Sigma^*$  y sean $\gamma = Z\gamma'$ con $Z \in \Gamma$ y $\gamma' \in \Gamma^{*}$.
Si $(p,\theta) \in \delta (q,a,Z)$  luego denotaremos $(q,w,\gamma) \vdash_{\cal M} (p,w',\theta\gamma')$ la transición de una configuración en otra en el \APND $\cal M$,
donde $\theta \gamma'$ es la concatenación en el monoide libre $\Gamma^{*}$. 

Esta operación nos define una relación sobre $Q \times \Sigma^* \times \Gamma^*$.
Así como en el caso anterior de los autómatas finitos consideremos la relación generada por la clausura transitiva y reflexiva de esta operación tal que la denotaremos $\vdash^*_{\cal M}$.


\begin{deff}
	Dado $\cal M$ un autómata de pila no determinístico consideramos el \emph{lenguaje generado por estado final} como
	\begin{equation*}
		L( {\cal M}) = \{ w \in \Sigma^* \ | \ (q_0,w,Z_0) \vdash^* (q, \epsilon, \gamma), \ \ q \in F, \ \gamma \in \Gamma^*      \}
	\end{equation*}
\end{deff}



\begin{ej}\label{ej_ic_palindromos}
	Sea nuestro alfabeto $\Sigma = \{ a, b\}$ y $L$ el lenguaje de los palíndromos sobre este alfabeto tal como lo definimos en el ejemplo \ref{leng_ej_gram_palindromos}.
	Consideremos el siguiente autómata de pila 
	\[
	M=(Q,\{a,b\}, \{a,b,\$\} , \delta, q_0, \{q_1\}, \$)
	\]
	donde nuestra pila tiene el mismo alfabeto que el de entrada con un símbolo adicional que va funcionar como nuestro símbolo inicial de la pila. 
	El autómata tiene dos estados, el inicial y el final. 
	Al automáta de pila lo representaremos de la siguiente manera:
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,
			scale = 1,transform shape]
			
			\node[state,initial] (q_0) {$q_0$};
			\node[state,accepting] (q_1) [right of=q_0] {$q_1$};
			
			\path (q_0) edge [bend right]             node {} (q_1);
			\path (q_1) edge [loop above] node {}    (   );
			\path (q_0) edge [loop above] node {}    (   );
		\end{tikzpicture}
	\end{center}
	Donde dibujamos una flecha siempre y cuando la función de transición nos permita ir del estado del cual sale la flecha al estado al que llega.
	A los estados finales los distinguimos dibujandoles el borde dos veces.
	
	La idea intuitiva del funcionamiento de este autómata es la siguiente: en el primer estado vamos apilando la palabra de entrada y en el segundo estado vamos desapilando la palabra anteriormente apilada. 
	
	Sea $Z$ cualquier elemento del alfabeto de la pila y $X$ cualquier elemento de nuestro alfabeto de entrada e $Y = \{a,b, \epsilon\}$
	entonces dada una configuración $(q_{i}, Y, Z)$ nuestra función de transición $\delta$ va a ser la siguiente,
	\[
		\delta(q_{i}, Y, Z)  = 
		\begin{cases}
			(q_0,aZ)  		& \text{si} \ i=0, Y = a \\
			(q_0,bZ) 		&  \text{si} \ i=0, Y = b    \\
			(q_1,\epsilon) 	&  \text{si} \ i=1, Y = a, Z = a 	\\
			(q_1,\epsilon) 	&  \text{si} \ i=1, Y = b, Z = b \\
			(q_1,Z)			& \text{si} \ i=0, Y = \epsilon \\
			(q_1, Z)		& \text{si} \ i=0 \\
		\end{cases}
	\]

	
	Probemos que $L = L(\cal M)$.
	Primero vemos que $L \subseteq L(\cal M)$.
	Si $w \in L$ luego existe $u \in \Sigma^{*}$ de manera que $w = uu^r$ o bien existe $a \in \Sigma$ de manera que $w = uau^r$, dicho de otra forma distinguimos en el caso que $|w| \equiv 0 \mod (2)$ o en el caso que $|w| \equiv 1 \mod (2)$.
	En ambos casos podemos tomar sucesiones de movimientos similares.
	Veamos el caso que $|w|$ es par.
	Primero apilamos la subpalabra $u$ en la pila y consumimos $u$,
	\[
		(q_{0}, w, Z_{0}) \overset{*}{\vdash} (q_{0},u^r,u^rZ_{0})
	\]
	Si es par tenemos que $(q_{0},u^r,u^rZ_{0}) \vdash (q_{1},u^r,u^rZ_{0})$.
	Finalmente tenemos que 
	\[
		(q_{1},u^r,u^rZ_{0}) \overset{*}{\vdash} (q_{1},\epsilon,Z_{0}).
	\] 
	mientras que si es impar tenemos que 
	\[
		(q_{0}, w, Z_{0}) \overset{*}{\vdash} (q_{0},au^r,u^rZ_{0}) \vdash (q_{1},u^r,u^rZ_{0})\overset{*}{\vdash} (q_{1},\epsilon,Z_{0}).
	\] 	
	
	Probemos la otra contención.
	Para eso sea $w \in L(\cal M)$ luego tenemos que $(q_{0},w,Z_{0}) \overset{*}{\vdash} (q_{1},\epsilon,Z_{0})$ por definición de lenguaje aceptado por un autómata de pila no determinístico.
	Para esto notemos que tiene que existir alguna $u \in \Sigma^*$ y alguna $v \in \Sigma^{*}$ tal que $(q_{0}, w, Z_{0}) \overset{*}{\vdash} (q_{1},v,u^rZ_{0})$.
	Una vez que llegamos al estado $q_{1}$ la única manera de aceptar una palabra es que podamos consumir $v$ y esto ocurre si y solamente sí $v = u^r$.
	De esta manera obtenemos que $w$ tiene que ser un palíndromo, por lo tanto $w \in L$.
	
	
\end{ej}

Así como probamos en la subsección anterior la equivalencia de los lenguajes regulares con los lenguajes aceptados por autómatas finitos no determinísticos tenemos una equivalencia en el marco de los lenguajes independientes de contexto.

\medskip

\begin{teo}\label{teo_ic_apnd}
	Un lenguaje $L$ es independiente de contexto si y solo si es aceptado por un autómata de pila no determinístico.
\end{teo}

\begin{proof}
	%Demo importante diría si bien es super estándar y conocidísimo el resultado.
	Ver \cite{hopcraft-ullman}.
\end{proof}



Hasta ahora definimos los autómatas de pila no determinísticos que aceptan por estado final. Otra definición posible de lenguaje aceptado podría ser que acepten por pila vacía. 
Es decir que una vez que consumimos la palabra $w$ de entrada llegamos a una configuración $(q, \epsilon, \epsilon)$ donde $\epsilon$ es la palabra vacía de ambos alfabetos respectivamente. Formalmente dado un autómata de pila $\cal M$  notaremos al \emph{lenguaje aceptado por pila vacía} de la siguiente manera,
\begin{equation*}
	N({\cal M}) = \{ w \in \Sigma^* \ | \ (q_0,w,Z_0) \vdash^* (q, \epsilon, \epsilon), \ q \in Q, u \in \Sigma^*    \}
\end{equation*}
donde arrancamos en el estado inicial y llegamos a algún estado $q$ cualesquiera sin importar que sea final o no.
La pila está vacía así como lo que nos queda por leer de la palabra. 
En este caso diremos que nuestro lenguaje es aceptado por un autómata de pila no determinístico por pila vacía.


El siguiente resultado nos dice que en el caso que nuestro autómata sea no determinístico es equivalente usar una u otra manera de definir a nuestro lenguaje.

\medskip
\begin{teo}
	Un lenguaje $L$ es aceptado por un autómata de pila no determinístico por estado final si y solo sí es aceptado por un autómata de pila no determinístico por pila vacía.
\end{teo}

\begin{proof}
	%Demo bastante fácil si se hacen los dibujitos. Quizá ni haga falta escribirla.
	Ver \cite{hopcraft-ullman}.
\end{proof}

\subsection{Autómatas de pila determinísticos.} 
\begin{deff}
	Un \emph{autómata de pila determinístico} es un automáta de pila 
	\[
	{\cal M } = (Q, \Sigma, \Gamma, \delta, q_0, F, Z_0)
	\]
	definido idénticamente a un \APND \ref{deff_apnd} con la salvedad que 
	\[
	|\delta(q,a, z)| \le 1 \ \ \ \forall z \in \Gamma, \ p \in Q, \ a \in \Sigma \cup \{ \epsilon \}.
	\]
\end{deff}

\begin{obs}
	Todo \APD en particular es un autómata de pila no determinístico. 
\end{obs}

Esto nos dice que todas las definiciones que dimos para \APND siguen siendo válidas en este contexto.
Una diferencia importante es que si ${\cal M }$ es un \APD entonces dada una palabra $w \in \Sigma$ existe una única manera de consumir a la palabra $w$.
Notaremos $L(\cal M)$ al lenguaje aceptado por estado final y notaremos por $N(\cal M)$ al lenguaje aceptado por pila vacía entonces tenemos el siguiente resultado, que marca una diferencia con el caso de los lenguajes aceptados por autómatas de pila no determinísticos.

\begin{teo}
	Existen lenguajes $L, L' \in \text{IC}$ tales que:
	\begin{itemize}
		\item Existe $\cal M$ \APD de manera que $L = L(\cal M)$ pero no existe ningún $\cal N$ \APD tal que $L = N(\cal N)$.
		\item Existe $\cal M$ \APD de manera que $L' = N(\cal M)$ pero no existe ningún $\cal N$ \APD tal que $L' = L(\cal N)$.
	\end{itemize} 
\end{teo}
\begin{proof}
	\cite{sipser13}.
\end{proof}

Ahora probemos que no todo lenguaje aceptado por estado final por un \APND puede ser aceptado por estado final por un autómata de pila determinístico.
El mismo ejemplo del lenguaje de los palíndromos \ref{ej_ic_palindromos} nos sirve como contraejemplo.
\begin{ej}
	El lenguaje 
	\[
	L = \{ w \in \{ a,b \}^*  \ : \ w = w^r \}
	\]
	no es aceptado por un \APD pero sí por uno no determinístico. 
	Supongamos que ${\cal {M}} = (Q, \{ a, b \}, \Gamma, \delta, q_0, F, Z_0)$ es un \APD que lo acepta. 
	
	
	Notemos que para cualquier palabra $w \in \{ a,b \}^*$ debe ser que
	\[
	(q_{0},w,Z_{0}) \overset{*}{\vdash} (q, \epsilon, \gamma)
	\]
	donde $\gamma \in \Gamma^*$ es tal que $\gamma \neq \epsilon$.
	Caso contrario tendríamos que $ww^r \notin L(\cal M)$ ya que la pila estaría vacía y no podríamos pasar de configuración.
	
	Fijamos una palabra arbitraria $w \in \{ a,b \}^*$ y consideramos $x_{w} \in \{ a, b\}^*$ de manera que si
	$(q_{0}, wx_{w}, Z_{0}) \overset{*}{\vdash} (q, \epsilon, \gamma_{w})$ entonces $|\gamma_{w}|$ es minimal.
	
	
	Si consideramos palabras del estilo $wx_wz \in \{a,b\}^*$ sabemos que la longitud de lo que quede en la pila no puede disminuir, esto es que si $(q_{0}, wx_{w}z, Z_{0}) \overset{*}{\vdash} (q, \epsilon, \gamma)$ entonces $|\gamma| \ge |\gamma_{w}|$.
	
	Nuestro \APD $\cal M$ tiene finitos estados y un alfabeto de pila finito por lo tanto existen finitos pares de estados y topes de pilas a los que puede llegar este \APD después de consumir una palabra.
	Esto nos dice que deben existir al menos dos palabras distintas $w, u \in \{ a, b\}^*$ tales que:
	\begin{align*}
		(q_{0}, wx_{w}, Z_{0}) & \overset{*}{\vdash} (q, \epsilon, \gamma_{w}) \\
		(q_{0}, ux_{u}, Z_{0}) & \overset{*}{\vdash} (q, \epsilon, \gamma_{u})
	\end{align*}
	que cumplan que caen en el mismo estado y tienen el mismo tope de pila, esto que existe $z \in \Gamma$ tal que $\gamma_{u} = z \gamma$ y $\gamma_{w} = z \gamma'$ para $\gamma, \gamma' \in \Gamma^{*}$.
	
	
	Vamos a elegir $v \in \{ a,b\}^*$ de manera que si $s = wx_{w}$ y $t = ux_{u}$ entonces $sv \in L \iff tv \notin L$ y viceversa.
	
	Procedemos separando en casos dependiendo de las longitudes de $s$ y de $t$.
	\begin{itemize}
		\item Si $|t|=|s|$ basta con tomar $v=s^r$. 
		Entonces $tv \in L({\cal M})$ pero $tv \notin L$.
		
		\item Si $|t|\neq |s|$ supongamos que $|s| < |t|$ y que $s$ no es prefijo de $t$ entonces  podemos tomar $v = s^r$ de manera que $sv \in L$ mientras que $tv \in L(\cal M)$ pero $tv \notin L$.
		
		\item Si $|t|\neq |s|$ y una es prefijo de la otra. 
		Sin pérdida de generalidad supongamos que $t=sy$ donde $y \in \{a,b\}^*$ tal que $|y| \ge 1$ y que $y = ay'$ con $y' \in \{a,b\}^*$ entonces $yb \notin L$.  
		De esta manera tenemos que si $v=bs^r$ entonces $sv \in L$ mientras que $tv \in L(\cal M)$ pero $tv \notin L$.		
	\end{itemize}
	
	Con esto probamos que no puede existir ningún autómata $\cal M$ tal que $L = L(\cal M)$ porque si $L \subseteq L(\cal M)$ entonces existen $w \in L(\cal M)$ tales que $w \notin L$.
	Por el ejemplo \label{ej_ic_palindromos} tenemos que $L$ es aceptado por un \APND y así vimos que no todo lenguaje que es aceptado por un \APND es aceptado por un autómata de pila determinístico.
	
\end{ej}

\subsection{Autómatas de pila determinísticos especiales.} 
Consideremos ahora un \APD tal que acepta tanto por estado final como por pila vacía. 

\begin{deff}
	Sea ${\cal {M}} = (Q,\Sigma, \Gamma, \delta, q_0, F, Z_0)$ un autómata de pila determinístico. 
	Diremos que $\cal M$ es un \emph{autómata de pila determinístico especial} si $w \in L({\cal M}) \iff w \in N(\cal M)$.
\end{deff}

La familia de lenguajes aceptados por los autómatas de pila determinísticos especiales es estrictamente menor a la familia de los que son aceptados por autómatas de pila determinísticos.
Veamos un contraejemplo.

\begin{ej}
	Sea el lenguaje $L = \{ a^m b^n  : m \ge n \ge 1 \}$ este no es un lenguaje independiente de contexto determinístico especial pero sí es determinístico. 
	
	Construyamos un \APD que acepte a $L$. 
	Sea 
	\[
	{\cal M} = (\{q_0,q_1,q_2\}, \{q_0\}, \{a,b\}, \{a,b,Z_0\}, Z_0, q_2) 
	\]
	un \APD 
	Introducimos la siguiente notación estándar para representar la función de transición en un gráfico.
	Si tenemos una flecha de un estado $q \in Q$ a otro estado $p \in Q$ tal que tiene como etiqueta $b, a | \gamma$
	entonces esto quiere decir que $\delta(q,b,a) = (p,\gamma)$.
	
	Entonces podemos representar gráficamente al \APD de la siguiente manera, donde usamos que $Z \in \{a,b,Z_0\}$ es cualquier letra del alfabeto de la pila,	
	\begin{center}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,
			scale = 1,transform shape]
			
			\node[state,initial] (q_0) {$q_0$};
			\node[state] (q_1) [right of=q_0] {$q_1$};
			\node[state,accepting] (q_2) [right of=q_1] {$q_2$};
			
			\path (q_0) edge    [bend right]          node {$b, a | \epsilon$ \ } (q_1)
			(q_0) edge    [loop above]          node {$a, Z | aZ$} (q_0)
			(q_1) edge      [bend right]      node {$\epsilon, Z | Z$}   (q_2)
			(q_1) edge    [loop above]           node {$b, a | \epsilon$} (q_1);
			
		\end{tikzpicture}
	\end{center}
	Podemos ver de manera directa que $L = L(\cal M)$.
	Para esto notemos que si $w \in L(\cal M)$ entonces
	\[
	(q_{0},w,Z_{0}) \overset{*}{\vdash} (q_{0},bw',a^mZ_{0})
	\]
	donde $a^mbw' = w$ y $m \ge 1$.
	Entonces para pasar al estado $q_{1}$ necesitamos leer una $b$ por lo que
	\[
	(q_{0},bw',a^mZ_{0}) \vdash (q_{1},w',a^{m-1}Z_{0}) \overset{*}{\vdash} (q_{2},\epsilon, a^{m-1-n}Z_{0})
	\]
	donde $0 \le n \le m-1$.
	Similarmente usando las mismas configuraciones podemos ver que si $w \in L$ entonces $w \in L(\cal M)$.
	Con esto probamos que $L$ es aceptado por un autómata de pila determinístico.
	
	El lenguaje $L$ no es aceptado por un \APD por pila vacía y así no va a poder ser aceptado por un autómata de pila especial dado que tiene la \emph{propiedad de los prefijos}. 
	Es decir que existen palabras $w \in L$ tales que existe $u \in L$ y $w = uv$ donde $v \in \{ a, b\}^*$.
	Por ejemplo consideremos:
	\[
	u = a^m b^i, \ w = a^m b^j \ \
	\text{para}  \
	m \ge 2,  \ i < j \le m
	\] 
	entonces $u,w \in L$.
	Supongamos que $u,w \in N(\cal M)$ queremos llegar a una contradicción.
	Esto es porque si $M = (Q, \Sigma, Z, Z_0, \delta, q_0 , F)$ fuera un \APD que acepta por pila vacía a este lenguaje tendríamos que 
	\[
	(q_0,u,Z_0) \vdash^* (q,\epsilon, \epsilon)
	\]
	con $q \in F$ pero como tiene la pila vacía no podemos continuar aceptando a la palabra $w$ ya que por la definición que empleamos el autómata necesita leer algún elemento de la pila. 
	
	De esta manera vemos que este lenguaje no puede ser aceptado por pila vacía y estado final por un \APD concluyendo que los lenguajes determinísticos especiales forman un subfamilia propia de los independientes de contexto determinísticos.
\end{ej}


\section{Teoría de grupos.}\label{secc_teo_grp}



\begin{deff}
	Dado $H$ subgrupo de $G$ podemos definir la \emph{acción por multiplicación a izquierda} sobre $G$ como $\alpha: H \to S(G)$ definida por $\alpha(h)(g) = hg$.
	En este caso el cociente por esta acción lo vamos a denotar $H \backslash G $.
	
	Análogamente podemos definir una \emph{acción por multiplicación a derecha} $\beta:H \to S(G)$ definida como $\beta(h)(g) = gh$.
	Al cociente de esta acción lo vamos a denotar $G/H$.
\end{deff}

A los elementos de $G/H$ los llamaremos \emph{cosets a izquierda} y los denotaremos $gH$ mientras que a los de $H \backslash G$ los llamaremos \emph{cosets a derecha} y los denotaremos $Hg$.

\begin{deff}
	Dado $G$ grupo y $H$ subgrupo el \emph{índice} de $H$ en $G$ es el número de cosets a izquierda de $H$ en $G$ y lo denotaremos $[G:H]$.
\end{deff}


\begin{lema}\label{lema_ind_prod_inter}
	Si $G$ es un grupo, $H$ un subgrupo de $G$ y $K$ un subgrupo de $H$ entonces
	\[
	[G:K] = [G:H][H:K].
	\]
\end{lema}

Por la definición de cosets que dimos tenemos que $[G:H] = |G/H|$.
Equivalentemente tenemos que podemos definir al índice como $[G:H] = |H \backslash G|$, ver \cite{}.

\begin{deff}
	Dado un conjunto $A$ podemos definir a $F_{A}$ el \emph{grupo libre} generado por los elementos de $A$ como un grupo que tiene una función inyectiva $\iota: A \to F_{A}$ que denominamos la inclusión de los generadores en el grupo libre y que está definido por la siguiente propiedad universal: 
	dado $H$ grupo y $f:A \to H$ función entonces existe un único morfismo de grupos $\ol f: F_{A} \to H$ tal que $\ol f \circ \iota (a) = f(a)$ para todo $a \in A$.
	Equivalentemente el siguiente diagrama conmuta,
	\begin{center}
		\begin{tikzcd}
			F_{A}  \arrow[rr, "\ol f", dashed]          &  & H \\
			&  &   \\
			A \arrow[uu, "\iota"] \arrow[rruu, "f", swap] &  &  
		\end{tikzcd}
	\end{center}
	
\end{deff}

\begin{obs}
	Una observación que se desprende de la definición de un grupo libre es que si tenemos dos conjuntos $A, A'$ tales que $|A| = |A'|$ luego $F_{A} \simeq F_{A'}$.
En particular si $|A|=k < \infty$ tenemos que $F_{A} \simeq F_{ \{1, \dots, k \} }$.
Introduciremos la notación $F_{k}$ para referirnos a un grupo libre generado por algún conjunto $A$ tal que $|A| = k$.
\end{obs}

Todo grupo en particular es un monoide.
En el caso que $F_{A}$ es un grupo libre si miramos el conjunto simétrico de generadores $B = A \cup A^{-1}$ donde $A^{-1} = \{ a^{-1} : a \in A \}$ luego tenemos que el grupo libre $F_{A}$ es un cociente del monoide libre $B^*$.
Esto es porque $F_{A} \simeq B^{*} / \{ aa^{-1} : a \in A \}$.
Sea $\pi: B^{*} \to F_{A}$ este epimorfismo de monoides.
Dada una palabra $w \in B^{*}$ notaremos $w \underset{G}{=} g$ si $\pi(w) = g$.
	

	

\begin{deff}
	Dado un grupo libre $F_{A}$ luego si consideramos el conjunto $B = A \cup A^{-1}$. 
	Una \emph{palabra reducida} es una palabra $w = a_{0} \dots a_{n} \in B^{*}$ tal que no existe ningún $0 \le i < n$ de manera que $a_{i+1}=a_{i}^{-1}$.
\end{deff}


\begin{obs}\label{obs_libres_pal_red}
	Dado un grupo $F_{A}$ libre entonces una palabra reducida y no vacía $w \in B^*$  es tal que $w \underset{G}{\neq} 1$.
\end{obs}


\begin{deff}
	Un grupo $G$ es \emph{finitamente generado} si existe un conjunto finito $A$ junto con un epimorfismo de grupos $\pi: F_{A} \twoheadrightarrow G$.
	En este caso al conjunto $A$ lo llamaremos los \emph{generadores} de $G$.
\end{deff}


\begin{deff}
	Sea $G$ un grupo y $H$ un subgrupo entonces el \emph{normalizador} de $H$ en $G$ es el siguiente subgrupo
	\begin{equation*}
		N_G(H) = \{ g\in G : gHg^{-1} = H  \}
	\end{equation*}
\end{deff}

Denotaremos por $S= \{ g \in G :  gHg^{-1} \}$ al conjunto de conjugados del subgrupo $H$. 

\begin{lema}\label{lema_normalizador_conjugados}
	Si $G$ es un grupo finitamente generado y $H$ es un subgrupo de índice finito entonces $N_G(H)$ tiene índice finito y más aún $[G:N_G(H)] = |S|$.
\end{lema}
\begin{proof}
	Para ver que tiene índice finito notemos que $H \le N_G(H)$ por lo tanto tenemos que 
	\[
	[G:N_G(H)] \le [G:H] < \infty.
	\]
	
	Para probar la otra afirmación definimos la siguiente función hacia los cosets a izquierda del normalizador desde el conjunto $S$,
	\begin{align*}
		S  &\to  G/N_G(H)  \\
		sHs^{-1} &\mapsto sN_G(H)
	\end{align*}
	Veamos que es biyectiva viendo que es inyectiva ya que $G/N_{G}(H)$ es un conjunto finito.
	
	Si $sN_G(H) = tN_G(H)$ entonces tenemos que esto sucede si y solo sí $t^{-1}s \in N_G(H)$.
	Esto nos dice que por la definición del normalizador,
	\[
	t^{-1}s H s^{-1}t = H \iff sHs^{-1} = tHt^{-1}
	\]
	y de esta manera obtenemos que la función está bien definida y es inyectiva y por lo tanto biyectiva.
	
\end{proof}


\begin{lema}\label{lema_indice_interseccion}
	Sea $G$ grupo y $K_1, \dots, K_n$ subgrupos tales que $K_{i}$ tiene índice finito para todo $ 1 \le i \le n $ entonces $\bigcap_{i=1}^{n} K_{i}$ es un subgrupo de índice finito.
\end{lema}
\begin{proof}
	Lo probaremos por inducción en la cantidad de subgrupos de índice finito que estamos intersecando.
	En el caso base tenemos dos subgrupos $H,K$ de índice finito.
	Primero notemos que por el segundo teorema de isomorfismo para grupos tenemos que existe una biyección entre los siguientes conjuntos de cosets $ KH / H \simeq K / K \cap H $ (en principio ningún subgrupo es normal así que no podemos hablar de grupos sino de conjuntos).
	Como  $|KH / H| \le |G / H| < \infty$ dado que $H$ tiene índice finito obtenemos así que $|K / K \cap H| < \infty$.
	
	Por \ref{lema_ind_prod_inter} obtenemos lo siguiente
	\[
	[G:K\cap H] = [G:K][K: K \cap H]
	\]
	y como ambos índices de la derecha son finitos por lo visto obtenemos que $K \cap H$ es un subgrupo de índice finito también tal como queríamos ver.
	
	Para la demostración del paso inductivo debemos ver que si tenemos $n$ subgrupos de índice finito $K_{1}, \dots, K_{n}$ entonces $\bigcap_{i=1}^{n} K_{i}$ también tiene índice finito.
	La demostración se reduce a la del caso base si tomamos $H = \bigcap_{i=1}^{n-1} K_{i}$ (que por hipótesis inductiva tiene índice finito) y $K = K_{n}$.
\end{proof}


\begin{lema}\label{lema_subg_fg}
	Sea $G$ un \fg y sea $H$ subgrupo de índice finito entonces $H$ es un \fg.
\end{lema}
\begin{proof}
	Sea $A = \{g_1, \dots, g_n\}$ conjunto finito de generadores de $G$.
	Sea $T =\{t_1, \dots, t_m\}$ conjunto transversal a derecha de $H$ tal que $t_1=1$.
	
	Dado $g_j$ generador de $G$ debe existir $h_{ij} \in H$ tal que $h_{ij}t_{k} = t_ig_j$ para cierto $t_k$.
	También debe existir $h_i \in H$ de manera que $ h_i t_{k} = g_i$ para cierto $t_k$.
	Veamos que el conjunto finito 
	\[
	B = \{ \ h_{ ij}  \mid {1 \le i,j \le n } \} \cup \{ \ h_i \mid {1 \le i \le n} \}
	\]
	genera a $H$.
	
	Dado $h \in H$ veamos que se puede escribir como una palabra en $B$. 
	Tenemos que 
	\[
	h = g_{i_1}\dots g_{i_r}
	\]
	donde usamos el conjunto finito de generadores de $G$.
	
	Por lo visto anteriormente podemos escribir  $g_{i_1} = h_{i_1}t_{k_1}$ para cierto y entonces nos queda la siguiente escritura de $h$,
	\[
	h = h_{i_1}t_{k_1} g_{i_2}\dots g_{i_r}
	\]
	entonces usando que $h_{k_{1}i_{2}}t_{k_2} = t_{k_1}g_{i_2} $ llegamos a la siguiente escritura de $h$,
	\[
	h = h_{i_1}h_{k_{1}i_{2}}t_{k_2}\dots g_{i_r}.
	\]
	Repitiendo inductivamente este procedimiento llegamos a que $h =h_{i_1}h_{k_{1}i_{2}} \dots t_{k_r}$.
	Necesariamente $t_{k_r} = 1$ porque $T$ es un conjunto de transversales de $H$ y $h \in H$.
	Concluimos que $B$ es un conjunto finito de generadores de $H$.
	
\end{proof}

\begin{deff}
	Un grupo finitamente generado $G$ es \emph{virtualmente libre} si tiene un subgrupo libre $F$ tal que $(G:F) < \infty$.
\end{deff}





\begin{ej}
	Veamos algunos ejemplos elementales de grupos que son de esta familia y algunos que no lo sean.
	
	\begin{enumerate}	
		\item 
		Cualquier extensión de un grupo libre por un grupo finito es un grupo virtualmente libre,
		\[
		1 \to F \to G \to K \to 1
		\]
		donde $K$ es un grupo finito y $F$ es un grupo libre finitamente generado.
		En particular esta familia de ejemplos incluye los productos directos $G= F \times K$ y semidirectos $G = F \rtimes K$.
		
		
		\item Uno de los ejemplos más elementales de un grupo que no es \vl \ es $\ZZ \times \ZZ$.
		La primera observación es que al ser abeliano si tiene un subgrupo libre necesariamente tiene que ser isomorfo a $\ZZ$ porque este es el único grupo libre abeliano.
		
		Nos alcanza con ver que no es virtualmente $\ZZ$.
		Vamos a probarlo por reducción al absurdo. 
		Sea entonces $F$ un subgrupo que es isomorfo a $\ZZ$.
		Sea $(n,m) \in \ZZ \times \ZZ$ el generador de $F$.
		Probaremos que $\ZZ \times \ZZ / F$ tiene orden infinito.
		Para eso consideraremos $(p,q) \in \ZZ \times \ZZ$	tal que $p,q$ son primos distintos y ambos coprimos con $m$ y con $n$.
		Veamos que $[(p,q)] \in \ZZ \times \ZZ / F$ tiene orden infinito.
		Si no lo fuera deberían existir $\alpha, \beta \in \ZZ$ de manera que 
		\begin{align*}
			\alpha (p,q) = \beta(n,m) 
		\end{align*}
		
		como todos son coprimos entre sí esto nos dice que $p \mid \beta$ y similarmente que $q \mid \beta$, por lo que tenemos que $q \mid \alpha$ y $p \mid \alpha$.
		Esto nos dice que se pueden escribir de esta manera
		\begin{align*}
			\alpha = p^{r_1} q^{s_1} \gamma_1 \\
			\beta = p^{r_2} q^{s_2} \gamma_2
		\end{align*}
		con $r_i, s_i \ge 1$ para $i=1,2$.
		
		Finalmente como 
		\[ 
		\alpha p = \beta n
		\]
		tenemos que $r_1+ 1 = r_2$ pero por otro lado como
		\[
		\alpha q  = \beta m
		\]
		acá tenemos que al ser $m$ coprimo con $p$ luego la multiplicidad de $p$ en la descomposición en primos de lo que está a la izquierda es $r_2 - 1 $ mientras que lo que está a la derecha es $r_2$.
		
		Esto es una contradicción que vino de suponer que $[(p,q)] \in \ZZ \times \ZZ / F$ tenía orden finito por lo tanto tenemos que $\ZZ \times \ZZ$ no puede ser \vl.
		
	\end{enumerate}
\end{ej}




\section{Grafos no dirigidos.}\label{secc_graf_nd}

Sea $V$ un conjunto entonces introducimos la siguiente notación:
\[
	[V]^k = \{ \{ v_1, v_2, \dots, v_{k} \} \mid v_{i} \in V, \ 1 \le i \le k \}
\]

\begin{deff}
	Un \emph{grafo no dirigido} $\Gamma$ va a ser un par $(V,E)$ de conjuntos disjuntos que satisfacen que
	$E \subseteq [V]^2$.
	Los elementos de $V$ serán denominados \emph{vértices} mientras que los elementos de $E$ serán denominados \emph{aristas}.
	El conjunto de vértices de un grafo $\Gamma$ se escribe $V(\Gamma)$ y el de aristas se escribe $E(\Gamma)$.
\end{deff}


Diremos que $\Gamma$ es un \emph{grafo infinito} si $|V| = \infty$ caso contrario diremos que es un grafo finito.

Un vértice $v \in V$ diremos que es \emph{incidente} con una arista $e \in E$ si $v \in e$.
Si la arista $e \in E$ es incidente con $v \in V$ y con $w \in V$ luego escribiremos $e = vw$ mientras diremos que los vértices $v,w$ son \emph{adyacentes} en este caso.
Definimos el conjunto $E(v) = \{  e \in E : v \ \text{es incidente en } \ e \}$.
Al valor $|E(v)|$ lo llamaremos el \emph{grado} de $v$.


\begin{deff}
	Un grafo $\Gamma$ es \emph{localmente finito} si para todo $v \in V$ vale que
	\[
		| E(v) | < \infty
	\]
	Un grafo $\Gamma$ tiene \emph{el grado acotado uniformemente} si existe $k \in \NN$ tal que para todo $v \in V$ vale que 
	\[
		|E(v)| \le k.
	\]
\end{deff}
\begin{obs}
	Todo grafo $\Gamma$ tal que tiene grado acotado uniformemente es un grafo localmente finito.
\end{obs}

Un \emph{camino} $c$ en un grafo no dirigido es una sucesión de vértices $c=(v_{0}, \dots, v_{n})$ de manera tal que $v_{i}$ es adyacente con $v_{i+1}$ para todo $1 \le i < n$.
Dado un camino $c = (v_{0}, \dots, v_{n})$ denotaremos por su \emph{longitud} al número entero positivo $|c|= n$.
Un grafo es \emph{conexo} si para todo par de vértices $(v,w) \in V \times V$ existe un camino $c = (v_{0}, \dots, v_{n})$ tal que $v_{0} = v$ y $w=v_{n}$.
Diremos que el camino $c$ \emph{une los vértices} $v$ y $w$.
Un \emph{ciclo} es un camino $c = (v_{0}, \dots, v_{n}, v_{0})$ en el cual el primer vértice y el último son idénticos y todas las aristas $\{ v_{i}, v_{i+1} \}$ que aparecen en el camino son distintas.
Un grafo conexo y sin ciclos es un \emph{árbol}.



\begin{deff}
	Dados grafos no dirigidos $\Gamma, \Gamma'$ un \emph{morfismo de grafos no dirigidos} es una función $\varphi:V(\Gamma) \to V(\Gamma')$ tal que para toda arista $\{ v,w \} \in E(\Gamma)$ vale que $\{  \varphi(v), \varphi(w) \} \in E(\Gamma')$.
	Un \emph{automorfismo} va a ser un morfismo de grafos biyectivo $\varphi:V(\Gamma) \to V(\Gamma)$.
	Equivalentemente $\varphi: V(\Gamma) \to V(\Gamma)$ es un automorfismo si
	$\{ v,w \} \in E(\Gamma) \iff \{ \varphi(v), \varphi(w) \} \in E(\Gamma)$. 
\end{deff}

Dado un grafo $\Gamma$ sus automorfismos forman un grupo con la composición.
Esto es que si $\text{Aut}(\Gamma) = \{ \varphi: \Gamma \to \Gamma  \mid \varphi \ \text{es un automorfismo} \  \}$ luego $(\text{Aut}(\Gamma), \circ)$ es un grupo.

Una vez que tenemos definido el grupo de automorfismos de un grafo podemos hablar de acciones de grupos.

\begin{deff}
	Una \emph{acción} de un grupo $G$ sobre un grafo no dirigido $\Gamma$ es un morfismo $\psi:G \to \text{Aut}(\Gamma)$.
	En el caso que exista una acción diremos que $G$ actúa sobre $\Gamma$.
\end{deff}




Definimos ahora el tipo de grafos que nos van a interesar mayoritariamente en este trabajo.
Estos grafos nos van a unir la teoría de grupos con la teoría de grafos no dirigidos.

Primero una definición útil en este contexto.


\begin{deff}
	Sea $G$ un grupo y $A$ un conjunto de generadores tal que $1 \notin A$.
	Definimos el \emph{grafo de Cayley} $\Gamma = \text{Cay}(G,A)$ como el grafo que tiene como vértices $V(\Gamma) = G$ y aristas $\{g,h\} \in E(\Gamma)$ si y solo sí $h=ga$ para ciertos $g,h \in G$ y $a \in B$. 
	Para una arista $e = \{g,ga\}$ llamaremos la \emph{etiqueta} de $e$ al generador $a \in A$.
\end{deff}


En particular el grupo $G$ tiene una acción bastante natural sobre sus grafos de Cayley tal que es una acción libre.


\begin{lema}\label{lema_grp_acc_libre_cayley}
	Sea $G$ grupo finitamente generado por $A$ y $\Gamma = \text{Cay}(G,A)$ su grafo de Cayley entonces $G$ actúa libremente sobre $\Gamma$.
\end{lema}

\begin{proof}
	Vamos a definir una acción de $G$ sobre $\Gamma$ y probar que es libre.
	
	Una acción de $G$ en $\Gamma$ es un morfismo de grupos $\psi: G \to \text{Aut}(\Gamma)$.
	Dado $g \in G$ definimos $\psi(g)$ como $\psi(g)(h) = gh$ donde usamos que los vértices del grafo de Cayley son los elementos del grupo por lo tanto podemos multiplicarlos en el grupo $G$ y mirar el vértice correspondiente.
	Por como lo definimos es claro que $\psi(g)$ es un morfismo de grafos. 
	Para ver que es un automorfismo basta con tomar $\psi(g^{-1})$ tal que es la inversa de $\psi(g)$.
	Por la definición también es claro que $\psi$ es un morfismo de grupos.
	
	Probemos ahora que la acción que conseguimos es libre.
	Para eso si $h \in V(\Gamma)$ notemos que si $\psi(g)(h) = h$ luego esto nos dice que $gh = h$ lo que implica que $g = 1$ por lo tanto la acción es libre.
	
\end{proof}

Veamos ahora que características necesariamente tiene que cumplir un grafo no dirigido para ser un grafo de Cayley.

\begin{lema}\label{lema_cayley_conexo_grado}
	Si $G$ es un grupo finitamente generado por un conjunto simétrico $A$ luego $\Gamma = \text{Cay}(G,A)$ es un grafo conexo y de grado acotado uniformemente.
\end{lema}
\begin{proof}
	Para ver que es conexo,	probaremos que para todo $g \in V(\Gamma)$ existe un camino $c$ tal que une $1 \in V(\Gamma)$ con $g$.
	Para eso usamos que $A$ es un conjunto de generadores por lo tanto $g = a_{1} \dots a_{k}$ para $a_{i} \in A$ para todo $1 \le i \le k$.
	Esto nos dice que el camino $c = (1, a_{1}, a_{1}a_{2}, \dots, a_{1} \dots a_{k})$ une $1$ con $g$ y así vemos que el grafo $\Gamma$ es conexo. 
	
	Para ver que tiene grado acotado uniformemente consideramos algún vértice $g \in V(\Gamma)$ luego $E(g) = \{  h \in V(\Gamma) : \{g,h\} \in E \}$ tal que por como definimos al grafo de Cayley tenemos que $|E(g)| \le |A| < \infty$ usando que $A$ es un conjunto finito.
\end{proof}

Si $G$ es un grupo finitamente generado por $A$ tomaremos $B = A \cup A^{-1}$ otro conjunto finito de generadores que llamaremos el \emph{simétrico} de $A$.
Otra manera equivalente de pensar esto es que $B$ es un conjunto finito de generadores de $G$ no como grupo sino como monoide.

\begin{obs}\label{obs_grafo_Cayley_palabras}
	
En el caso de los grafos de Cayley vamos a identificar los caminos con palabras en los generadores del grupo.
Más específicamente si $G$ es un grupo finitamente generado por $A$ conjunto simétrico de generadores y $\Gamma = \text{Cay}(G,A)$ el grafo de Cayley entonces dado un camino $c = (g_{0}, \dots, g_{n})$ sobre $\Gamma$ vamos a considerar la siguiente palabra $c \in A^{*}$ en el monoide libre sobre los generadores de $G$, definida como:
si $g_{i}g_{i+1} \in E(\Gamma)$ tiene etiqueta $a_{i}$ luego $c = a_{0}\dots a_{n}$ es la palabra asociada al camino $c$.
Bajo esta interpretación de caminos como palabras notemos que si $c$ es un camino tal que empieza y termina en el mismo vértice luego su palabra asociada resulta ser $c \in A^*$ tal que $c \underset{G}{=} 1$.
En el caso particular de un ciclo tenemos que la palabra asociada está reducida.
\end{obs}

Ahora vamos a ver que en el caso particular que el grupo sea libre entonces su grafo de Cayley para ciertos generadores se puede tomar para que sea un árbol.

\begin{lema}\label{lema_cayley_libre_arbol}
	Si $G = F_{A}$ para un conjunto finito $A$ luego si $B$ es el simétrico de $A$ tenemos que $\Gamma = \text{Cay}(G,B)$ es un árbol.
\end{lema}

\begin{proof}
	Todo grafo de Cayley es conexo por \ref{lema_cayley_conexo_grado}.
	Debemos ver que no tiene ciclos.
	Para eso si $c$ es un ciclo en $\Gamma$ entonces por la observación \ref{obs_grafo_Cayley_palabras} obtenemos una palabra $c$ en $B^*$ tal que es {reducida} y tal que $c \underset{G}{=} 1$.
	Por \ref{obs_libres_pal_red} si una palabra reducida es la identidad del grupo entonces esta palabra es la palabra vacía.
	Concluimos así que no hay ciclos en el grafo de Cayley de este grupo libre.
	
\end{proof}


Todo grafo lo podemos ver como un espacio métrico discreto si consideramos como conjunto base a sus vértices. 
Dado $\Gamma$ un grafo no dirigido conexo el espacio métrico asociado es 
$ (V(\Gamma), d )$ con $d$ la distancia definida como 
\[
	d(v,w) = \inf \{ \  |\gamma|  \mid \gamma \subseteq \Gamma \land \gamma \ \text{es un camino y} \ 
	\gamma=(v,\dots, w)  \}
\] 
a los caminos $\gamma$ tales que realizan la distancia las llamaremos \emph{geodésicas}.

Utilizaremos en varias ocasiones las siguientes dos observaciones:

\begin{enumerate}[1-]
	\item Si $\alpha = (v_{0}, \dots, v_{n})$ es una geodésica entonces para todo $0 \le i,j \le n$ vale que  $d(v_{i}, v_{j}) = |j-i|$.
	\item Si $T$ es un árbol entonces es \emph{únicamente geodésico}.
	Esto es que para todo par de vértices $t,s \in V(T)$ existe una única geodésica $\alpha$ que comienza en $s$ y termina en $t$.
\end{enumerate}



\end{document}