\documentclass[tesis.tex]{subfiles}

\newcommand{\APND}{automáta de pila no determinístico }
\newcommand{\APD}{automáta de pila determinístico }
\newcommand{\fg}{grupo finitamente generado }
\newcommand{\fp}{grupo finitamente presentado }
\newcommand{\WP}{\text{WP}(G, \Sigma)}
\newcommand{\deriva}{\overset{*}{\Rightarrow_{\cal G}}}

\begin{document}
	
\chapter{Grupos virtualmente libres.}

Un grupo $G$ es virtualmente libre si existe un subgrupo $F$ libre tal que el índice es finito.





\section{El problema de la palabra de los grupos virtualmente libres.}
Una pregunta natural es intentar entender la relación entre la clasificación del lenguaje del problema de la palabra de un grupo dado y las distintas familias de grupos que le corresponden. Los grupos que su lenguaje del problema de la palabra sea independiente de contexto los llamaremos directamente independientes de contexto. 

Dado que tenemos una equivalencia con ser aceptado por un automáta de pila no determinístico veamos qué clase de grupos se corresponden a tener un lenguaje independiente de contexto.

\begin{ej}[Automáta para grupos libres.]
	Dado un grupo libre $F_\Sigma$ veamos cómo construir un automáta $\cal M$ tal que acepta su problema de la palabra. Pensemos un \APND que tenga dos estados. Uno inicial que también va a ser final para poder aceptar la palabra vacía que corresponde al elemento 1 de nuestro grupo y otro estado para las palabras que no están en el problema de la palabra.
	Para eso la idea es tener en la pila lo que fuimos leyendo de nuestra palabra hasta el momento visto como un elemento en el grupo. Esto es, cada vez que leemos una letra de la palabra ver de multiplicarla como un elemento en el grupo con lo que tenemos en el tope de la pila. Eventualmente cuando hayamos recorrido la palabra entera debería quedarnos una palabra en la pila que queremos que sea exactamente $1$ y esto es lo mismo que pedir que sea aceptada por pila vacía. Entonces este automáta lo podemos representar de la siguiente manera,
	
	
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm,
	scale = 1.15,transform shape]
	
	\node[state,accepting,initial] (1') {$1'$};
	\node[state] (1) [right of=1'] {$1$};
	
	\path (1') edge[bend left]              node {} (1)
	(1) edge[bend left]              node {} (1');
	\end{tikzpicture}
	
	Donde las transiciones del estado 1' a 1 son todas las transiciones en las cuales la letra que estamos por leer no es la inversa de lo que esté al tope de la pila. Por otro lado las transiciones del estado 1 al estado 1' son todas las que lo que leemos es justamente el inverso de lo que está al tope de la pila.
	
	% No sé bien si anotar todas las representaciones o no! Creo que al ser un ejemplo es un poco excesivo y así se entiende mejor pero no me queda claro.
\end{ej}

Esta idea que usamos para los grupos libres se puede extender más en general para grupos virtualmente libres con algunas modificaciones. Esta es la primera de las equivalencias que vamos a ver.

\begin{teo}
	Todo grupo virtualmente libre es tal que su problema de la palabra es aceptado por un automáta determinístico especial de pila finito.
\end{teo}

\begin{proof}
	Para demostrar este teorema necesitamos construirnos al automáta para una presentación fijada de un grupo virtualmente libre.
	
	Fijemos entonces el subgrupo libre de índice finito $F_\Sigma$. 
	Sea $R$ representantes de coclases a derecha de $G/F_\Sigma$ que sabemos son finitos. 
	De esta manera podemos considerar al conjunto  $\Delta = \Sigma \cup \Sigma^{-1} \cup R$ de generadores de nuestro grupo tal que nos da una presentación.
	
	Recordemos por \ref{} que para todo grupo virtualmente libre tenemos un sistema de reescritura convergente dado por 
	\[
	S = \{ ab \to w(a,b)r  \}
	\] 
	donde $w(a,b) \in F_\Sigma$ es una palabra reducida y $r \in R$ tal que $ab = w(a,b)r$. Vamos a usar este sistema para construirnos la función de transición de nuestro automáta. 
	
	Nuestro automáta lo definimos así 
	\[
	{\cal M }= (Q,\Delta, Z, \delta, q_0, F)
	\]
	donde los estados $Q$ se corresponden a $R \cup R'$ siendo $R'$ una copia de $R$. 
	Para el alfabeto de la pila consideramos solamente el alfabeto del subgrupo libre y otra vez agregamos otras copias de manera que nuestro alfabeto para la pila es $Z = \Sigma \cup \Sigma^{-1} \cup (\Sigma \cup \Sigma^{-1})^{'}$. 
	Nuestro estado inicial es $q_0 = 1' \in R'$ es decir el $1$ de la copia. Nuestro conjunto de estados finales contiene solamente al estado inicial $F=q_0$. 
	Notemos a su vez a $m = \max {|w(r,a)|}$ para $r \in R, a \in \Delta$ que es finito porque es el máximo de longitudes de finitas palabras. 
	Cuando tengamos una ecuación en término de las copias la vamos a considerar como el elemento que representa en el grupo. 
	La utilidad radica en poder tener un automáta más declarativo en cuanto a los nombres de los estados. 
	Nuestra función de transición entonces funciona de la siguiente manera si no tenemos nada en la pila
	
	\begin{align*}
		(r'a,w(r'a)s) \in \delta  \ \ \ \text{para} \ \  s \in R \ \ \text{tal que} \ r'a=w(r',a)s \ \ \text{y} \ \ w(r',a) \neq 1  \\
		(r'a,s') \in \delta  \ \ \text{para} \ \  s \in R \ \ \text{tal que} \ r'a=s.  \\ 
	\end{align*}
	
Si la palabra reducida $w(r',a)$ es distinta de la identidad entonces pasamos a los estados que le corresponden a $R$ mientras que en el otro caso nos quedamos en los estados de la copia $R'$. 
En particular como el estado inicial es $1' \in R'$ luego siempre que tengamos la pila no vacía vamos a estar en algún estado $r \in R$. 
Repliquemos esta idea también para el caso que que tengamos algo en la pila,
	
	\begin{align*}
	(xra,ys) \in \delta \ \ \text{para} \ \  s \in R, x,y \in (\Sigma \cup \Sigma^{-1})^m & \ \  \text{tal que} \ ra=w(r,a)s  \\ & \ \ \text{e} \ \ y \ \text{es la forma reducida de} \ \ xw(r,a)  \\
	(xra,s') \in \delta\ \ \text{para} \ \  s' \in R', x,y \in (\Sigma \cup \Sigma^{-1})^m & \ \  \text{tal que} \ ra=w(r,a)s'  \\ & \ \ \text{e}  \ \ xw(r,a)  \ \text{se reduce a 1}. \ \  \\ 
	\end{align*}
	En este caso la función de transición cuando tenemos algo en la pila lo que va haciendo es lo mismo que antes y solo pasa a los estados que corresponden a $R'$ cuando la palabra que nos queda la pila vacía. 
	
	De esta manera notemos que en particular es un automáta especial determinístico considerando que la transición es determinística porque el sistema de reescritura es convergente por lo que hay una única palabra reducida. 
	Por otro lado como el único estado que acepta es el estado inicial y la única manera de llegar a cualquier estado en $R'$ es con la pila vacía luego el automáta acepta por pila vacía y estado final a la vez.
\end{proof}

\begin{obs}
	En particular esto nos dice que todo grupo virtualmente libre es tal que su problema de la palabra es un lenguaje independiente de contexto determinístico. 
	Como tal tiene las siguientes buenas propiedades algorítmicas \ref{}...
\end{obs}

\newpage

\section{Grafos de Cayley.}

\begin{deff}
	Sea $G$ un \fg y $\Sigma$ un conjunto de generadores como monoide. 
	Supongamos que $1 \notin \Sigma$.
	Definimos el \blue{grafo de Cayley} $\Gamma = Cay(G,\Sigma)$ como el grafo que tiene como vértices $V(\Gamma) = G$ y $E(\Gamma) = G \times (\Sigma \cup \Sigma^{-1})$. 
\end{deff}

Para una arista $(g,a)$ llamaremos la \emph{etiqueta} al generador $a$.
Extendemos esta definición a caminos sobre el grafo para obtener una palabra en el monoide $\Sigma^*$.
Este grafo por como lo definimos no tiene aristas múltiples ni tampoco tiene bucles.
Dado que $\Sigma$ genera tenemos que el grafo $\Gamma$ es conexo.

El grafo de Cayley lo podemos ver como un espacio métrico justamente si hacemos que todas las aristas sean isométricas a $[0,1]$. 
Esto es que $d(g,ga) = 1$ para todo $g \in G, a \in \Sigma^*$. 
Un camino $\alpha = g_0 \dots g_n$ es una \emph{geodésica} si $d(g_i,g_j) = j-i$ para todo $i,j \in [0,n]$.

\begin{ej}
	Sea $\Bbb F_2$ el grupo libre en dos generadores $a,b$. Su grafo de Cayley para estos generadores tiene la siguiente pinta,
	\bigskip
	
	\begin{tikzpicture}
	\draw l-system [l-system={cayley, axiom=[A] [+A] [-A] [++A], step=2.35cm, order=3}];
	\end{tikzpicture}
	
	 Notemos que este grafo resulta ser un árbol y esto es algo que vale en general para todos los grupos libres cuando miramos respecto a sus generadores canónicos.
\end{ej}

Como todo grupo libre es tal que sus grafos de Cayley resultan ser árboles por un resultado clásico de Serre, ver \cite{}.
Es razonable pensar que todo grupo virtualmente libre es tal que su grafo de Cayley se parezca a un árbol. 
La primera noción que podemos tomar para modelizar esto es el de tener un treewidth finito.

\begin{deff}\label{desc-arbol}
	 Una \blue{descomposición en un árbol} de un grafo $X$ es un árbol $T$ y un mapa $q:t \in V(T) \mapsto X_t \in {\cal P}(V(X))$ (llamaremos a $X_t$ bolsones) que cumple las siguientes condiciones:
	\begin{enumerate}
		\item Dado cualquier vértice $v \in V(X)$ existe $t \in V(T)$ tal que $x \in X_t$. 
		\item Si hay una arista $e$ entre dos vértices $v,w \in V(X)$ luego existe $t \in V(T)$ tal que $v,w \in X_t$.
		\item Si $v \in V(X)$ es tal que $v \in X_t \cap X_s$ luego $v \in X_r$ para todo $r$ en la geodésica que va desde $s$ a $t$ dentro de $T$. En otras palabras esto es que $\{ t \in V(T) :  v \in X_t \}$ forma un subárbol. 
	\end{enumerate} 
\end{deff}
\smallskip

La idea de la descomposición es que los \emph{bolsones} $X_t \in {\cal P}(V(T))$ no tengan muchos vértices si es que queremos modelizar que el grafo se parezca a un árbol. Esto nos conduce a la siguiente definición.

\begin{deff}
El \blue{bagsize} de una descomposición en un árbol $T$ de un grafo $X$ es el siguiente valor:
	\begin{equation*}
		bs(X,T) = \{ \sup |X_t|, \ t \in V(T) : T \ \text{descomposición de} \ X  \} - 1
	\end{equation*}
Un grafo $X$ tiene \blue{treewidth finito} si existe una descomposición en un árbol de bagsize finito.	
\end{deff}
\begin{obs}
 En particular si el grafo $X$ es un árbol notemos que tiene treewidth exactamente igual a 1.
 Una manera de probarlo es tomar $T$ la subdivisión baricéntrica de $X$. 
 Este es el siguiente árbol que tiene como vértices a 
 \[
 V(T) = \{ \{ x \} \ | \ x \in V(X)  \} \cup \{ \{ x,y \} \ | \ xy \in E(X) \}.
 \]
 Tomamos todos los vértices de $x$ y los agregamos a los de $T$ y agregamos un vértice por cada arista del grafo $X$.
 Finalmente las aristas están formadas por 
 \[
 E(T) = \{  ts \ | \ t \subset s \ \lor s \subset t \}
 \]
 agregamos una arista entre cada vértice de $T$ que se corresponde con un vértice de $X$ con los que se corresponden con una arista que lo contiene en $X$. 
%Por cada arista del grafo $e \in E(X)$ donde $e=xy$ con $x,y \in V(X)$ agregamos un vértice $v_e \in V(T)$ tal que definimos para que $xv_e, v_ey \in E(T)$.
 
 
 La descomposición que tomamos entonces es la siguiente. 
 Por cada $t \in V(T)$ tenemos ya armados los bolsones por la construcción que hicimos. 
 Esto es que:
 \begin{itemize}
 	\item Si $t$ es un vértice que ya estaba en $V(X)$ entonces $X_t = \{ t \}$. 
 	\item Si $t$ lo agregamos por una arista $xy \in E(X)$ entonces $X_t = \{ x,y  \}$.
 \end{itemize}
Por como los definimos es evidente que $|X_t| \le 2$ para todo $t \in V(T)$, de esta manera si vemos que se trata de una descomposición en un árbol tendremos probado que $bs(X,T) = 1$ tal como queríamos ver.

Finalmente veamos que se trata de una descomposición. Corroboremos que cumple las tres condiciones necesarias.
\begin{enumerate}
	\item Todo vértice $v \in V(X)$ lo podemos ver como uno en $T$. Su bolsón asociado $X_v$ lo tiene como único elemento por la construcción de esta descomposición.
	\item Si $xy \in E(X)$ entonces tenemos un vértice $t\in V(T)$ tal que $X_{t} = \{ x,y \}$. 
	\item Sea $x \in X_t \cap X_s$. 
	Por como armamos los bolsones, si estos son distintos no queda más que al menos uno de los dos, por ejemplo $X_t$ tenga esta pinta, $X_t = \{ x,y\}$ para cierto vértice $y \in V(X)$ tal que junto con $x$ forman una arista $xy \in E(X)$.
	
	El primer caso es que $X_s = \{ x \}$.
	La geodésica que podemos tomar entonces es $st$ puesto que $s$ se corresponde con el vértice $x$ y sabemos que existe una arista $st \in E(T)$ porque justamente $t$ se corresponde con una arista en $X$ que contiene a $x$.
	
	En el caso que $s \in V(T)$ sea tal que el bolsón $X_s$ se corresponda con los vértices que aparecen en una arista debería ser del tipo $X_s = \{x,z\}$ para cierto $z \in V(X)$. 
	Es decir que la arista debe incluir a $x$ necesariamente y como vimos los bolsones solo tienen a lo sumo dos elementos.
	Si miramos la geodésica sobre $T$ entre ambos vértices no es más que el siguiente camino $tvs$ donde $v \in V(T)$ es el vértice que está tanto en el árbol original $X$ como en la subdivisión baricéntrica $T$.
	Esto es que $X_v = \{ x \}$.
	De esta manera $x$ está en todos los bolsones correspondientes a la geodésica sobre $T$ tal como queríamos ver.	
\end{enumerate}
\end{obs}


\begin{comment} [Creo que está bastante mal esto. Si lo tengo que usar más en adelante repensarlo bien.]
	\begin{obs}
	Si un grafo $\Gamma$ tiene treewidth finito podemos tomarnos otra descomposición tal que siga siendo de treewidth finito pero los bolsones de la descomposición sean conexos. 
	Si algún bolsón no es conexo agregamos todos los vértices del grafo que estén en la geodésica que une las componentes conexas. 
	Haciendo esto la descomposición sigue siendo finita aunque el tamaño de los bolsones puede aumentar considerablemente.
	\end{obs}
\end{comment}

\begin{deff}
	Dado un grafo $X$, el \blue{borde} de un conjunto de vértices $C \subseteq V(X)$ se define como
	\[
	\beta C = \{ u \in V(X) : \exists v \in V(X), \ uv \in E(X), \  \ \ (u \in C \wedge v \in \overline C) \ \ \lor  (u \in \overline C \wedge v \in  C)   \}.
	\] 
\end{deff}

\begin{ej}\label{desc-grafo-cayley}%[Descomposición válida para todo grupo finitamente generado].
	
	Construyamos una descomposición en un árbol que podemos hacer en general para todos los grafos de Cayley de grupos finitamente generados. 
	Consideremos el grafo $\Gamma = Cay(G,\Sigma)$ para cierto conjunto de generadores $\Sigma$ finito.
	
	Sea $V_n = \Gamma \setminus B_n(1) $ tal que $V_0 = \Gamma \setminus \{1\}$. 
	El árbol que vamos a considerar va a tener como vértices a conjuntos de vértices del grafo $\Gamma$ de manera que resultará evidente los bolsones que vamos a tomar para la descomposición. 
	Los vértices del árbol $T$ van a estar dados por los siguientes conjuntos,
	\[
	V(T) = \{  \beta C : C \subseteq V_n \ \text{componente conexa}   \}
	\]
	esto es todas las fronteras de las componentes conexas que nos quedan cuando consideramos algún $V_n$. 
	Las aristas entonces van a estar dadas por lo siguiente,
	\[
	E(T) = \{ \beta C \beta D : C \subseteq D \subseteq V_n, \ C \subset V_{n+1}   \}
	\]
	esto es que $C$ es una componente conexa del grafo que queda de sacarla la bola de radio un número mayor que el que está $D$.
	
	Notemos en particular que por como definimos este grafo $T$ resulta que si $C$ es una componente conexa de $V_n$ entonces solo existe una única arista $(\beta C, \beta D)$ tal que $D \subseteq V_{n-1}$. 
	Esto se debe a que al ser $C$ conexo entonces como $V_{n-1} \subseteq V_{n}$ en particular $C \subseteq V_{n}$ y debe estar contenida en una sola componente conexa $D \subseteq V_{n-1}.$
	
	%Quizá estaría bueno poner algún dibujito acá.
	
	Podemos ver que así como lo construimos tenemos que el grafo $T$ resulta ser un árbol tal que su raíz es $B_1(\Gamma)$. 
	
	Para ver que es un árbol veamos primero que es conexo. Dado un vértice $\beta C \in V(T)$ vamos a armar un camino que lo conecte con la raíz del árbol $B_1(\Gamma)$. 
	Usemos inducción en el $n$ tal que $C$ es una componente conexa de $V_n$. 
	El caso base es algún $C$ tal que es una componente conexa de $V_2$ y queremos armarnos un camino que lo una con $B_1(\Gamma)$. 
	Dado que $V_2 \subseteq V_1$ en particular tenemos que $C \subseteq V_1$. De esta manera por la definición tenemos que existe una arista $(\beta C, B_1(0))$ tal como queríamos ver.
	
	Para el paso inductivo supongamos que tenemos que para cualquier borde de una componente conexa de $V_{n-1}$ tenemos un camino que lo une con la raíz $B_1(\Gamma)$ y veamos de construirnos un camino con cualquier borde de una componente conexa $C \subseteq V_n$.
	De esta manera debe existir $D$ componente conexa de $V_{n-1}$ tal que $C \subseteq D$. Esto es porque $V_{n-1} \subseteq V_{n}$ y al ser $C$ un conexo si interseca alguna de las componentes conexas de $V_{n-1}$ debe estar contenida en ella. 
	Necesariamente debe intersecar a alguna de estas componentes conexas porque particionan al espacio.
	Así vimos que existe una arista $(\beta C, \beta D)$ y ahora usando la hipótesis inductiva obtenemos un camino de $B_1(\Gamma)$ con $\beta C$.
	Concluimos que el grafo $T$ es conexo.   
	
	% Otra manera que se me ocurrió es tomar un ciclo de longitud mínimo y llegar a un absurdo achicandolo. Creo que es más corto pero no me convence.
	Para terminar de ver que es un árbol veamos que es acíclico. 
	Dado un camino cerrado $\sigma$ en $T$ probemos que necesariamente tiene que repetirse algún vértice por lo tanto ningún camino cerrado puede ser un ciclo. Vamos a probarlo usando inducción en el máximo $n \in \NN$ tal que $C \in V_n$ y $\beta C$ es uno de los vértices en el camino. 
	%Notemos que está bien definido porque los caminos cerrados son compactos.
	Para el caso base notemos que si $\sigma$ es un camino cerrado tal que el máximo $n$ que aparece es $n=1$ entonces necesariamente $\sigma$ es idéntico al camino constante fijo en $B_1(0)$.
	%reescribir esto!
	Para el paso inductivo supongamos que para todo camino cerrado con máximo $m \in \NN$ tal que algún vértice que aparece en este camino es una componente conexa de $V_m$ resulta ser $n-1$ entonces este camino no es un ciclo. Veamos que si $m=n$ entonces este camino cerrado también resulta ser un ciclo.
	
	Partamos de un camino tal que pasa por $\beta C$ con $C \subseteq V_n$. 
	Como no existe $(\beta C, \beta C') \in E(T)$ tal que $C,C'$ sean componentes conexas de un mismo $V_n$ por la definición que dimos de las aristas. Necesariamente tiene que haber una arista con alguna componente conexa $D \in V_{n-1}$ dado que $n$ es máximo en este camino cerrado.   
	Como vimos anteriormente solamente hay una única arista que una a $\beta C$ con alguna $\beta D$ con $D \subseteq V_{n-1}$. 
	Esto nos dice que si el camino cerrado pasa por la arista $(\beta C, \beta D)$ necesariamente debe volver a pasar por la arista $(\beta C, \beta D)$ por lo tanto no es un ciclo. 
	Concluimos que el grafo $T$ es acíclico y por lo tanto como es conexo también resulta que $T$ es un árbol.
	
	Para ver que es una descomposición de árboles debemos ver que cumple las tres condiciones \ref{desc-arbol} de la definición. 
	\begin{enumerate}
		\item La primera condición la cumple por como lo definimos porque cualquier vértice del grafo $g \in V(\Gamma)$ 
		es tal que existe $n \in \NN$ de manera que $d(1,g)=n$, por lo que está en alguna componente conexa $C \subseteq V_{n-1}$. 
		En particular como la distancia es exactamente $n$ tiene que existir una arista $gg' \in E(\Gamma)$ con un vértice $g' \in V_{n-1}$ y por lo tanto $g \in \beta C$.
		
		\item La segunda condición partimos de una arista $gh \in E(\Gamma)$ luego miramos las distancias que hay al $1$ de ambos vértices para conseguirnos el bolsón adecuado. 
		Supongamos que ambas están a la misma distancia del $1$. En tal caso sea $n$ tal que $d(g,1)=d(h,1)=n$ luego si miramos $V_{n-1}$ notemos que tienen que estar en la misma componente conexa porque existe una arista entre ambos vértices. Sea esta componente $C$ luego como están a distancia exactamente $n$ ambas están en el borde, esto es que $g,h \in \beta C$ tal como queríamos ver. 
		El otro caso es que $d(g,1)=n < d(h,1)=n+1$ y en este caso como están conectadas resulta que están en $\beta C$ si $C$ es la componente conexa que contiene a $h$ en $V_n$ por definición del borde de un conjunto de vértices de un grafo.
		
		\item Para la tercera condición supongamos que hay $g \in V(\Gamma)$ tal que está en la intersección de dos bolsones $\beta C \cap \beta D$. 
		Queremos ver que está en todos los bolsones que aparecen en la geodésica de $\beta C$ a $\beta D$ en el árbol T. 
		Si $d(g,1) = n$ luego solo puede estar en la frontera de alguna componente conexa $C$ tal que esté en alguna de estas opciones  $V_{n-1}, V_{n},  V_{n+1}$. 
		Supongamos que $D \subseteq V_{n}$, en tal caso vale que $D \nsubseteq V_{n}$ porque sino tendríamos que resulta ser la misma componente conexa. 
		Sin pérdida de generalidad supongamos que $C \subset V_n$ mientras que $D \subset V_{n+1}$. 
		Como ambas son componentes conexas luego si hay una intersección tiene que haber una contención, esto es que $D \subseteq C$. 
		De esta manera vemos que $(\beta C, \beta D) \in E(T)$ por lo tanto como están unidos por una arista la geodésica es justamente esta arista.
		
	\end{enumerate}
\end{ej}

\begin{obs}\label{palabras-wp}
Si tenemos un grupo $G$ tal que es independiente de contexto consideremos $\cal G$ gramática que genera al lenguaje del problema de la palabra, $\WP = L(\cal G)$.
Si $A$ es una de las variables de esta gramática consideremos el lenguaje $L_A$ de palabras generadas a partir de esta variable, donde
\[
L_A = \{ w \in \Sigma^*  \ | \ A \deriva w  \}.
\]
Veamos que si $v,v' \in L_A$ entonces $v =_G v'$, es decir son el mismo elemento vistos en el grupo $G$. 
Para eso si tenemos una derivación que en algún momento llega a $S \deriva \beta A \gamma \deriva uvw$ también tenemos otra derivación que deriva en $S \deriva \beta A \gamma  \deriva uv'w$. 
Es decir que $uvw, u'v'w' \in \WP$ por lo tanto 
\begin{equation*}
	uvw =_G 1 =_G uv'w \implies v =_G v'
\end{equation*}
tal como queríamos ver.
\end{obs}



\begin{teo}
	Todo grupo independiente de contexto es tal que su grafo de Cayley tiene treewidth finito.
\end{teo}
\begin{proof}

La descomposición que hicimos en \ref{desc-grafo-cayley} es válida para todo grafo de Cayley. 
Veamos que esta descomposición para un grupo independiente de contexto tiene treewidth finito. 
Buscamos $k \in \NN$ tal que nos permita acotar $|\beta C| \le k$ para todo $\beta C \in V(T)$. 
Alcanza con ver que el diámetro de cada bolsón $\beta C$ está acotado uniformemente, esto es que exista $M \in \NN$ tal que 
\[
\text{diam}(\beta C) =  \sup_{g,h \in \beta C} d(g,h) \le M
\] 
porque al ser el grupo finitamente generado por $\Sigma$ entonces $|\beta C| \le |\Sigma|^{M} < \infty$. 


Dado que $G$ es un grupo independiente de contexto entonces el lenguaje del problema de la palabra para estos generadores $\WP$ tiene una gramática $\cal G$ independiente de contexto que lo genera. 
Consideremos que está en la forma normal de Chomsky.

Para cada variable $A$ de nuestra gramática podemos considerar el siguiente lenguaje
\[
L_A = \{ w \in \Sigma^* : A \deriva w  \}.
\]
Para este lenguaje introduzcamos un número natural $k_A \in \NN$ definido por $k_A = \min_{w \in L_A} |w|$. 
Como tenemos finitas variables en nuestra gramática $\cal G$ podemos considerar $k = \max_{A \in V} k_A$. 
Veamos que $\text{diam}(\beta C) \le 3k$ para todo $\beta C \in V(T)$.

Sean $g,h \in \beta C$ para cierta $C$ componente conexa de $V_n$, acotemos $d(g,h)$. 
Para eso consideremos una geodésica $\alpha$ que una $1$ con $g$ y análogamente otra $\gamma$ que una $1$ con $h$. 
Como $C \cup \beta C$ es conexo podemos tomar un arco $\tau$ que una $g$ con  $h$ dentro de $C \cup \beta C$. 
De esta manera tenemos un triángulo tal que si leemos las letras que están en la etiqueta del arco empezando desde $1$ y moviéndonos por $\alpha$ leemos la etiqueta $u$. 
Cuando nos movemos por $\tau$ leemos la etiqueta $v$. Consideremos que esta etiqueta $v$ es tal que $|v|>1$ caso contrario ya tenemos la cota probada. Finalmente leemos la etiqueta $w$ cuando regresamos al $1$ por medio de $\gamma$.
Como $uvw$ está en un ciclo en el grafo de Cayley entonces $uvw \in  \WP$ y por lo tanto tenemos alguna derivación $S \deriva uvw$.

Ya que tenemos esta derivación $S \deriva uvw$ miremos la primer variable que deriva a $v$ como subpalabra. 
Esto es que para la subpalabra $v$ sabemos que existe alguna variable $A$ tal que $A \deriva v'v''$ donde $v$ es a su vez una subpalabra de $v'v''$. 
Tomamos la última variable que aparece en la derivación.
%Esto es que para la subpalabra $v$ sabemos que debe existir alguna variable $A$ tal que $A \deriva u''vw''$ para $u''$ algún posfijo de $u$ y $w''$ algún prefijo de $w$ y aparece último en esta derivación. 
Ésta debe existir porque en particular $S$ cumple lo pedido de ser una variable que deriva a una palabra que contiene a $v$ como subpalabra.

Como está en la forma normal de Chomsky sabemos que al ser $|v| \ge 2$ entonces tenemos que la derivación tiene la siguiente pinta
\begin{equation*}
	S \deriva u'Aw' \Rightarrow_{\cal G} u'BC w' \deriva u'v'v''w'
\end{equation*}
donde $B,C$ son otras variables. En particular notemos que $A \deriva v'v''$, $B \deriva v'$ y $C \deriva v''$.


Si miramos la geodésica $\alpha$ sabemos que cuando leímos $u'$ habremos llegado a un vértice del grafo $x$, y al estar sobre la geodésica misma tenemos la siguiente igualdad,
%y que si tomamos el camino que leemos la palabra de menor longitud tenemos que habremos llegado al vértice $y$ que corresponde al haber leído $u'v'$.
\begin{equation*}
d(x,g) = d(1,g) - d(1,x).
\end{equation*}
Análogamente cuando miramos la geodésica $\gamma$ en la instancia que ya leímos $w'$ saliendo desde $h$ llegamos a cierto vértice $z$ y por la misma razón que en el caso anterior obtenemos
\begin{equation*}
	d(z,h) = d(1,h) - d(1,z).
\end{equation*}
Por otro lado si consideramos el vértice $y$ al que llegamos después de leer $u'v'$ que sabemos que está en el arco $\tau$ dado que $v$ es subpalabra de $v'v''$.
Usando que $y \in \tau \subseteq C \cup \beta C$ tenemos que $d(1,y) \le n+1 = d(1,g)$ por ser $C$ una componente conexa de $V_n$, entonces vale la siguiente desigualdad
\begin{equation*}
d(x,g) = d(1,g) - d(1,x) \le d(1,y) - d(1,x) = d(x,y)
\end{equation*}
y análogamente tenemos que $d(z,h) \le d(z,y)$.


Por la observación \ref{palabras-wp} notemos que si reemplazamos $v'$ por la palabra de menor tamaño del lenguaje $L_B$ seguimos teniendo un ciclo pero de longitud idéntica o más chica. 
La palabra $v'$ la leemos justamente cuando vamos del vértice $x$ al vértice $y$, así la distancia  $d(x,y)$ está acotada por la mayor de todas las palabras que puedan derivarse de $B$. 
Idénticamente hacemos esto para las variables $A$ y $C$.
Por como definimos a $k$ tenemos las siguientes cotas $d(x,y), d(y,z), d(x,z) \le k$.
%agregar dibujito, creo que es la manera más clara de explicar esto


Ahora estamos listos para ver que $d(g,h) \le 3k$. Usamos la desigualdad triangular tres veces,
\begin{align*}
	d(g,h) & \le d(g,x) + d(x,z) + d(h,z) \\
	& \le d(x,y) + d(x,z) + d(y,z) \le 3k
\end{align*}
tal como queríamos ver.
\end{proof}


\subsection{Cuasisometrías.}
%Mover esto a la sección anterior dado que uso que es un espacio métrico antes.
A todo grafo lo podemos pensar como un espacio métrico dónde las aristas son isométricas al intervalo real $[0,1]$. 


\begin{deff}
	Sean $X,Y$ espacios métricos. Una cuasisometría es una función $f:X \to Y$ tal que:
	\begin{enumerate}
	\item Para todo par de puntos $x_1,x_2 \in X$ existen constantes $A,B \le 0$ tales que
	\[
	\frac{1}{A} d_X(x_1,x_2) - B \le d_Y(f(x_1),f(x_2)) \le A d_X(x_1,x_2) + B
	\]
	\item Existe una constante real $C \le 0$ tal que para todo punto $y \in Y$ existe $x \in X$ tal que 
	\[
	d(y,f(x)) \le C
	\]
	\end{enumerate}
 	Dos espacios métricos que se dicen cuasisométricos si existe una cuasisometría entre ellos.
\end{deff}



\red{Propiedades de las cuasisometrías y un poco de la intuición geométrica detrás.}
Si tenemos una cuasisometría $f:X \to Y$ a partir de ésta nos podemos armar otra cuasisometría $g:Y \to X$. De esta manera podemos que la relación de ser cuasisométricos es una relación de equivalencia porque la reflexividad y la transitividad se deducen inmediatamente y la simetría a partir de lo visto anteriormente.


Intuitivamente una cuasisometría entre espacios métricos nos dice que estos resultan ser bastante similares al menos desde cierta distancia. El ejemplo clásico es el de la grilla y el plano.

Dado que todo grupo lo podemos pensar como un espacio métrico a partir de la distancia dada por la cantidad de palabras... está bien hablar de cuasisometrías entre grupos si pudieramos ver que esto no depende del conjunto de generadores que hayamos elegido.



Así otra manera de pensar que un grafo de un grupo virtualmente libre es casi un árbol es pedirle que sea cuasisométrico con un árbol. Veamos que estas categorización es equivalente a pedirle que el treewidth sea finito que era la otra caracterización que habíamos obtenido anteriormente.

\begin{lema}
	El treewidth finito es un invariante por cuasisometría.
\end{lema}
\begin{proof}
Si tenemos una cuasisometría $f:\Gamma_1 \to \Gamma_2$ tal que $\Gamma_1$ tiene treewidth finito, nos gustaría ver que $\Gamma_2$ también tiene treewidth finito...
\end{proof}

A partir de este resultado podemos ver que las dos maneras distintas que teníamos de pensar a los grafos que se parecen a árboles resultan ser equivalentes.

\begin{prop}
	Un grafo $X$ tiene treewidth finito si y solo si es cuasisométrico con un árbol.
\end{prop}
\begin{proof}
%La manera más inmediata para la ida es usar el resultado que un subgrupo de índice finito es cuasisométrico con el grupo original.	
	
Para la ida veamos de armarnos la cuasisometría a partir de la descomposición en árbol del grafo $X$. Definamos entonces la cuasisometría $q: T \to X$ a partir de mandar $t \to x_t$ donde $x_t \in X_t$ es algún elemento del bolsón correspondiente a $t \in V(T)$ que sabemos que no es vacío. Esta función es una cuasisometría con constante $C=1$ y $A = bs(T) + 1$.

Hay que ver la distancia dentro de un bolsón esté controlada...


Para la vuelta dado que el grafo $X$ es cuasisométrico a un árbol $T$ y este tiene treewidth exactamente 1 luego usando la prop anterior vemos que $X$ debe tener treewidth finito tal como queríamos ver.
\end{proof}

\begin{coro}
	Todo grupo independiente de contexto es tal que su grafo de Cayley es cuasisométrico a un árbol.
\end{coro}

\section{Teoría de Bass Serre.}



	
	
	
	
\end{document}