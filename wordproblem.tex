\documentclass[tesis.tex]{subfiles}

\newcommand{\ic}{independiente de contexto }
\newcommand{\APND}{automáta de pila no determinístico }
\newcommand{\APD}{automáta de pila determinístico }
\newcommand{\fg}{grupo finitamente generado }
\newcommand{\fp}{grupo finitamente presentado }
\newcommand{\WP}{\text{WP}(G, \Sigma)}
\newcommand{\deriva}{\overset{*}{\Rightarrow_{\cal G}}}

\begin{document}
	
\chapter{Grupos virtualmente libres.}
\begin{deff}
Un grupo $G$ \fg es \blue{virtualmente libre} si existe un subgrupo $F$ libre tal que su índice en $G$ es finito.
\end{deff}

\begin{obs}
	Al subgrupo libre siempre lo podemos tomar normal...?
\end{obs}

\begin{ej}
	El grupo $\ZZ \times \ZZ$ no es virtualmente libre.
	Como es un grupo conmutativo no puede tener a ningún $F_n$ con $n \ge 2$ como subgrupo. 
	Para que sea virtualmente libre no queda otra que el libre sea isomorfo a $\ZZ$. 
	Veamos que esto es imposible.
	Sea $H$ este subgrupo y sea $K \simeq G/H$ el cociente finito que necesariamente tiene que ser abeliano.
	Como el subgrupo $H$ tiene índice finito tenemos bien definido el morfismo del transfer $\phi$.
	Para definirlo necesitamos tomar $\{ x_i \}_{i=1 \dots n}$ representantes de $G/H$ a izquierda en $\ZZ \times \ZZ$ que sabemos son finitos porque $[\ZZ \times \ZZ : H] < \infty$.
	Luego todo elemento $x \in \ZZ \times \ZZ$ lo podemos escribir como 
	\[
	x = \prod_{i=1}^{n} h_i x_i
	\]
	donde $h_i \in H$.
	El transfer es el siguiente morfismo $\phi: \ZZ \times \ZZ \to \ZZ$ dado por $\phi(g) = \prod_{i=1}^{n} h_i$.
	En particular notemos que es un epimorfismo.
	Como $\ZZ$ es libre todo epimorfismo se parte. 
	Esto es que $\ZZ \times \ZZ  \simeq \ZZ \times K$ donde $K$ ya sabemos que es un grupo finito abeliano.
	Por el teorema de la clasificación de los grupos abelianos llegamos a una contradicción porque el grupo $\ZZ \times K$ sin importar qué grupo finito tomemos tiene torsión mientras que $\ZZ \times \ZZ$ no tiene.	
\end{ej}






\section{Grupos independientes de contexto.}
 
Como corolario de la proposición \ref{prop-cono-wp} y de saber que los lenguajes \ic forman un cono \ref{ic-cono} podemos dar la siguiente definición.
\medskip
\begin{deff}
	Si $G$ es un grupo \fg tal que para ciertos generadores $\Sigma$ resulta que $WP(G, \Sigma)$ es independiente de contexto entonces diremos que $G$ es un \blue{grupo \ic }.
\end{deff}

\begin{ej}
	$\ZZ \times \ZZ$ no es un grupo independiente de contexto.
	Si tomamos los siguientes generadores $\Sigma = \{ a,b,c \}$ tal que tenemos un morfismo de monoides $\pi: \Sigma^* \to \ZZ \times \ZZ$ dado por $\pi(a)=(1,0), \pi(b)=(0,1), \pi(c)=(-1,-1)$.
	Bajo esta presentación 
	\[
	WP(\ZZ \times \ZZ, \Sigma) = \{ w \in \Sigma^*  : \ \exists n \in \NN, \ w = a^nb^nc^n  \}.
	\]
	Este lenguaje no es independiente de contexto.
	Para eso usemos el lema del pumping \ref{pumping} para probarlo por contradicción.
	Si fuera \ic debería existir una constante $n \ge 0$ tal que hace valer las hipotesis del lema.
	Consideremos la palabra $w = a^n b^n c^n \in WP(G, \Sigma)$.
	Si tenemos una factorización $uvwxy = a^nb^nc^n$, que $|vwx| \le n$ implica que no todas las letras aparecen en $vwx$.
	Supongamos que la letra que no aparece es $c$.
	Por otro lado como $|vx| \le 0$ esto nos dice que al menos una letra aparece en la subpalabra $vx$.
	Si tomamos $i=0$ notemos que la palabra $uwy \in WP(G,\Sigma)$ pero esto es una contradicción porque la cantidad de $c$ en esta palabra es mayor que de $a$ o $b$.
\end{ej}

Una pregunta natural es intentar entender la relación entre la clasificación del lenguaje del problema de la palabra de un grupo dado y las distintas familias de grupos que le corresponden. 

%Dado que tenemos una equivalencia con ser aceptado por un automáta de pila no determinístico veamos qué clase de grupos son independientes de contexto.

\begin{ej}[Automáta para grupos libres.]
	Dado un grupo libre $F_\Sigma$ veamos cómo construir un automáta $\cal M$ tal que acepta su problema de la palabra. 
	Pensemos un \APND que tenga dos estados. Uno inicial que también va a ser final para poder aceptar la palabra vacía que corresponde al elemento 1 de nuestro grupo y otro estado para las palabras que no están en el problema de la palabra.
	Para eso la idea es tener en la pila lo que fuimos leyendo de nuestra palabra hasta el momento visto como un elemento en el grupo. 
	Esto es, cada vez que leemos una letra de la palabra ver de multiplicarla como un elemento en el grupo con lo que tenemos en el tope de la pila. 
	Eventualmente cuando hayamos recorrido la palabra entera debería quedarnos una palabra en la pila que queremos que sea exactamente $1$ y esto es lo mismo que pedir que sea aceptada por pila vacía. 
	Entonces este automáta lo podemos representar de la siguiente manera:	
	
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4.5cm,
	scale = 1.15,transform shape]
	
	\node[state,accepting,initial] (1') {$1'$};
	\node[state] (1) [right of=1'] {$1$};
	
	\path (1') edge[bend left]              node {} (1)
	(1) edge[bend left]              node {} (1');
	\end{tikzpicture}
	
	Donde las transiciones del estado 1' a 1 son todas las transiciones en las cuales la letra que estamos por leer no es la inversa de lo que esté al tope de la pila. Por otro lado las transiciones del estado 1 al estado 1' son todas las que lo que leemos es justamente el inverso de lo que está al tope de la pila.
	
	% No sé bien si anotar todas las representaciones o no! Creo que al ser un ejemplo es un poco excesivo y así se entiende mejor pero no me queda claro.
\end{ej}

Esta idea que usamos para los grupos libres se puede extender más en general para grupos virtualmente libres con algunas modificaciones. Esta es la primera de las equivalencias que vamos a ver.

\begin{teo}
	Todo grupo virtualmente libre es tal que su problema de la palabra es aceptado por un automáta determinístico especial de pila finito.
\end{teo}

\begin{proof}
	Para demostrar este teorema necesitamos construirnos al automáta para una presentación fijada de un grupo virtualmente libre.
	
	Fijemos entonces el subgrupo libre de índice finito $F_\Sigma$. 
	Sea $R$ representantes de coclases a derecha de $G/F_\Sigma$ que sabemos son finitos. 
	De esta manera podemos considerar al conjunto  $\Delta = \Sigma \cup \Sigma^{-1} \cup R$ de generadores de nuestro grupo tal que nos da una presentación.
	
	Recordemos por \ref{} que para todo grupo virtualmente libre tenemos un sistema de reescritura convergente dado por 
	\[
	S = \{ ab \to w(a,b)r  \}
	\] 
	donde $w(a,b) \in F_\Sigma$ es una palabra reducida y $r \in R$ tal que $ab = w(a,b)r$. Vamos a usar este sistema para construirnos la función de transición de nuestro automáta. 
	
	Nuestro automáta lo definimos así 
	\[
	{\cal M }= (Q,\Delta, Z, \delta, q_0, F)
	\]
	donde los estados $Q$ se corresponden a $R \cup R'$ siendo $R'$ una copia de $R$. 
	Para el alfabeto de la pila consideramos solamente el alfabeto del subgrupo libre y otra vez agregamos otras copias de manera que nuestro alfabeto para la pila es $Z = \Sigma \cup \Sigma^{-1} \cup (\Sigma \cup \Sigma^{-1})^{'}$. 
	Nuestro estado inicial es $q_0 = 1' \in R'$ es decir el $1$ de la copia. Nuestro conjunto de estados finales contiene solamente al estado inicial $F=q_0$. 
	Notemos a su vez a $m = \max {|w(r,a)|}$ para $r \in R, a \in \Delta$ que es finito porque es el máximo de longitudes de finitas palabras. 
	Cuando tengamos una ecuación en término de las copias la vamos a considerar como el elemento que representa en el grupo. 
	La utilidad radica en poder tener un automáta más declarativo en cuanto a los nombres de los estados. 
	Nuestra función de transición entonces funciona de la siguiente manera si no tenemos nada en la pila
	
	\begin{align*}
		(r'a,w(r'a)s) \in \delta  \ \ \ \text{para} \ \  s \in R \ \ \text{tal que} \ r'a=w(r',a)s \ \ \text{y} \ \ w(r',a) \neq 1  \\
		(r'a,s') \in \delta  \ \ \text{para} \ \  s \in R \ \ \text{tal que} \ r'a=s.  \\ 
	\end{align*}
	
Si la palabra reducida $w(r',a)$ es distinta de la identidad entonces pasamos a los estados que le corresponden a $R$ mientras que en el otro caso nos quedamos en los estados de la copia $R'$. 
En particular como el estado inicial es $1' \in R'$ luego siempre que tengamos la pila no vacía vamos a estar en algún estado $r \in R$. 
Repliquemos esta idea también para el caso que que tengamos algo en la pila,
	
	\begin{align*}
	(xra,ys) \in \delta \ \ \text{para} \ \  s \in R, x,y \in (\Sigma \cup \Sigma^{-1})^m & \ \  \text{tal que} \ ra=w(r,a)s  \\ & \ \ \text{e} \ \ y \ \text{es la forma reducida de} \ \ xw(r,a)  \\
	(xra,s') \in \delta\ \ \text{para} \ \  s' \in R', x,y \in (\Sigma \cup \Sigma^{-1})^m & \ \  \text{tal que} \ ra=w(r,a)s'  \\ & \ \ \text{e}  \ \ xw(r,a)  \ \text{se reduce a 1}. \ \  \\ 
	\end{align*}
	En este caso la función de transición cuando tenemos algo en la pila lo que va haciendo es lo mismo que antes y solo pasa a los estados que corresponden a $R'$ cuando la palabra que nos queda la pila vacía. 
	
	De esta manera notemos que en particular es un automáta especial determinístico considerando que la transición es determinística porque el sistema de reescritura es convergente por lo que hay una única palabra reducida. 
	Por otro lado como el único estado que acepta es el estado inicial y la única manera de llegar a cualquier estado en $R'$ es con la pila vacía luego el automáta acepta por pila vacía y estado final a la vez.
\end{proof}

\begin{obs}
	En particular esto nos dice que todo grupo virtualmente libre es tal que su problema de la palabra es un lenguaje independiente de contexto determinístico. 
	Como tal tiene las siguientes buenas propiedades algorítmicas \ref{}...
\end{obs}


\section{Grafos de Cayley.}

\begin{deff}
	Sea $G$ un \fg y $\Sigma$ un conjunto de generadores como grupo. 
	Supongamos que $1 \notin \Sigma$.
	Definimos el \blue{grafo de Cayley} $\Gamma = \text{Cay}(G,\Sigma)$ como el grafo que tiene como vértices $V(\Gamma) = G$ y aristas $(g,h) \in E(\Gamma)$ sii $h=ga$ para ciertos $g,h \in G$ y $a \in \Sigma \cup \Sigma^{-1}$. 
\end{deff}

Para una arista $(g,ga)$ llamaremos la \emph{etiqueta} al generador $a$.
Extendemos esta definición a caminos sobre el grafo para obtener una palabra en el monoide $\Sigma^*$.
Este grafo por como lo definimos no tiene aristas múltiples ni tampoco tiene bucles.
Dado que $\Sigma$ genera tenemos que el grafo $\Gamma$ es conexo.

El grafo de Cayley lo podemos ver como un espacio métrico justamente si hacemos que todas las aristas sean isométricas a $[0,1]$. 
Esto es que $d(g,ga) = 1$ para todo $g \in G, a \in \Sigma \cup \Sigma^{-1}$. 
Un camino $\alpha = g_0 \dots g_n$ es una \emph{geodésica} si $d(g_i,g_j) = j-i$ para todo $i,j \in [0,n]$.

\begin{ej}
	Sea $\Bbb F_2$ el grupo libre en dos generadores $a,b$. Su grafo de Cayley para estos generadores tiene la siguiente pinta,
	\bigskip
	
	\begin{tikzpicture}
	\draw l-system [l-system={cayley, axiom=[A] [+A] [-A] [++A], step=2.35cm, order=3}];
	\end{tikzpicture}
	
	 Notemos que este grafo resulta ser un árbol y esto es algo que vale en general para todos los grupos libres cuando miramos respecto a sus generadores canónicos.
\end{ej}

Como todo grupo libre es tal que sus grafos de Cayley resultan ser árboles por un resultado clásico de Serre, ver \cite{}.
Es razonable pensar que todo grupo virtualmente libre es tal que su grafo de Cayley se parezca a un árbol. 
La primera noción que podemos tomar para modelizar esto es el de tener un treewidth finito.

\begin{deff}\label{desc-arbol}
	 Una \blue{descomposición en un árbol} de un grafo $X$ es un árbol $T$ y un mapa $q:t \in V(T) \mapsto X_t \in {\cal P}(V(X))$ que cumple las siguientes condiciones:
	\begin{enumerate}
		\item Dado cualquier vértice $v \in V(X)$ existe $t \in V(T)$ tal que $x \in X_t$. 
		\item Si hay una arista $e$ entre dos vértices $v,w \in V(X)$ luego existe $t \in V(T)$ tal que $v,w \in X_t$.
		\item Si $v \in V(X)$ es tal que $v \in X_t \cap X_s$ luego $v \in X_r$ para todo $r$ en la geodésica que va desde $s$ a $t$ dentro de $T$. En otras palabras esto es que $\{ t \in V(T) :  v \in X_t \}$ forma un subárbol. 
	\end{enumerate} 
\end{deff}
\smallskip

La idea de la descomposición es que los \emph{bolsones} $X_t \in {\cal P}(V(T))$ no tengan muchos vértices si es que queremos modelizar que el grafo se parezca a un árbol. Esto nos conduce a la siguiente definición.

\begin{deff}
El \blue{bagsize} de una descomposición en un árbol $T$ de un grafo $X$ es el siguiente valor:
	\begin{equation*}
		bs(X,T) = \{ \sup |X_t|, \ t \in V(T) : T \ \text{descomposición de} \ X  \} - 1
	\end{equation*}
Un grafo $X$ tiene \blue{treewidth finito} si existe una descomposición en un árbol de bagsize finito.	
\end{deff}
\begin{obs}\label{desc-arbol-arbol}
 En particular si el grafo $X$ es un árbol notemos que tiene treewidth exactamente igual a 1.
 Una manera de probarlo es tomar $T$ la subdivisión baricéntrica de $X$. 
 Este es el siguiente árbol que tiene como vértices a 
 \[
 V(T) = \{ \{ x \} \ | \ x \in V(X)  \} \cup \{ \{ x,y \} \ | \ xy \in E(X) \}.
 \]
 Tomamos todos los vértices de $x$ y los agregamos a los de $T$ y agregamos un vértice por cada arista del grafo $X$.
 Finalmente las aristas están formadas por 
 \[
 E(T) = \{  ts \ | \ t \subset s \ \lor s \subset t \}
 \]
 agregamos una arista entre cada vértice de $T$ que se corresponde con un vértice de $X$ con los que se corresponden con una arista que lo contiene en $X$. 
%Por cada arista del grafo $e \in E(X)$ donde $e=xy$ con $x,y \in V(X)$ agregamos un vértice $v_e \in V(T)$ tal que definimos para que $xv_e, v_ey \in E(T)$.
 
 
 La descomposición que tomamos entonces es la siguiente. 
 Por cada $t \in V(T)$ tenemos ya armados los bolsones por la construcción que hicimos. 
 Esto es que:
 \begin{itemize}
 	\item Si $t$ es un vértice que ya estaba en $V(X)$ entonces $X_t = \{ t \}$. 
 	\item Si $t$ lo agregamos por una arista $xy \in E(X)$ entonces $X_t = \{ x,y  \}$.
 \end{itemize}
Por como los definimos es evidente que $|X_t| \le 2$ para todo $t \in V(T)$.
De esta manera si vemos que se trata de una descomposición en un árbol tendremos probado que $bs(X,T) = 1$ tal como queríamos ver.

Finalmente veamos que se trata de una descomposición. Corroboremos que cumple las tres condiciones necesarias.
\begin{enumerate}
	\item Todo vértice $v \in V(X)$ lo podemos ver como uno en $T$. Su bolsón asociado $X_v$ lo tiene como único elemento por la construcción de esta descomposición.
	\item Si $xy \in E(X)$ entonces tenemos un vértice $t\in V(T)$ tal que $X_{t} = \{ x,y \}$. 
	\item Sea $x \in X_t \cap X_s$. 
	Por como armamos los bolsones, si estos son distintos no queda más que al menos uno de los dos, por ejemplo $X_t$ tenga esta pinta, $X_t = \{ x,y\}$ para cierto vértice $y \in V(X)$ tal que junto con $x$ forman una arista $xy \in E(X)$.
	
	El primer caso es que $X_s = \{ x \}$.
	La geodésica que podemos tomar entonces es $st$ puesto que $s$ se corresponde con el vértice $x$ y sabemos que existe una arista $st \in E(T)$ porque justamente $t$ se corresponde con una arista en $X$ que contiene a $x$.
	
	En el caso que $s \in V(T)$ sea tal que el bolsón $X_s$ se corresponda con los vértices que aparecen en una arista debería ser del tipo $X_s = \{x,z\}$ para cierto $z \in V(X)$. 
	Es decir que la arista debe incluir a $x$ necesariamente y como vimos los bolsones solo tienen a lo sumo dos elementos.
	Si miramos la geodésica sobre $T$ entre ambos vértices no es más que el siguiente camino $tvs$ donde $v \in V(T)$ es el vértice que está tanto en el árbol original $X$ como en la subdivisión baricéntrica $T$.
	Esto es que $X_v = \{ x \}$.
	De esta manera $x$ está en todos los bolsones correspondientes a la geodésica sobre $T$ tal como queríamos ver.	
\end{enumerate}
\end{obs}


% [Creo que está bastante mal esto. Si lo tengo que usar más en adelante repensarlo bien.]
%	\begin{obs}
%	Si un grafo $\Gamma$ tiene treewidth finito podemos tomarnos otra descomposición tal que siga siendo de treewidth finito pero los bolsones de la descomposición sean conexos. 
%	Si algún bolsón no es conexo agregamos todos los vértices del grafo que estén en la geodésica que une las componentes conexas. 
%	Haciendo esto la descomposición sigue siendo finita aunque el tamaño de los bolsones puede aumentar considerablemente.
%	\end{obs}

\begin{prop}\label{prop-camino-desc}
	Sea $\Gamma$ grafo tal que tiene una descomposición en un árbol $T$.
	Sean $X,Y,Z$ bolsones tales que el vértice correspondiente a $Z$ en el árbol $T$ está en la geodésica que va de $X$ a $Y$. 
	Sean $x \in X, y \in Y$ tales que $x = x_0 \dots x_n=y$ es algún camino en $\Gamma$ conectándolos.
	Entonces debe existir algún $ 0 \le i \le n$ tal que $x_i \in Z$. 
\end{prop}

\begin{proof}
	Vamos a demostrarlo haciendo inducción en la longitud $n$ del camino. 
	El caso base es que $n = 0$ por lo tanto $x=y$. 
	En este caso por ser una descomposición en un árbol tenemos que usando la tercer propiedad que $x \in Z$ también.
	
	Para el paso inductivo tomemos $X'$ bolsón que contiene tanto a $x$ como a $x_1$ que sabemos existe por ser una de las propiedades de las descomposiciones en árboles.
	Si este bolsón $X'$ es $Z$ ya está porque nos alcanza con tomar $i=1$ de manera que $x_1 \in Z$.
	En el caso que esto no ocurra miramos el camino de longitud $n-1$ dado por $x_1 x_2 \dots x_n = y$ y usando la hipótesis inductiva llegamos al resultado.	
\end{proof}


\begin{deff}
	Sea $\Gamma$ un grafo y $C \in V(\Gamma)$ un conjunto de vértices entonces definimos los \blue{vecinos de $C$} por medio de 
	\[
	N(C) = \{ v \in V(\Gamma) : \exists w \in C, \ vw \in E(\Gamma) \}.
	\]
	De esta manera podemos definir recursivamente los l-ésimos vecinos por medio de $N^l(C) = N(N^{l-1}(C))$.
\end{deff}

\begin{obs}
	Esta definición la podemos escribir de manera más concisa como $N^l (C) = \{ v \in V(\Gamma) : \ \exists w \in C, \  d(v,w) \le l  \}$.
\end{obs}

\begin{prop}\label{prop-vecinos-desc}
	Si $(X_t)_{t \in V(T)}$ es una descomposición en un árbol $T$ para un grafo $\Gamma$ entonces si tomamos como bolsones a $N^l(X_t)$ también tenemos una descomposición en un árbol.
\end{prop}
\begin{proof}
	
	Veamos este resultado para $l=1$ y por inducción lo podemos extender para un $l$ genérico.
	En este caso notemos que las dos primeras condiciones de la descomposición en un árbol se siquen cumpliendo porque no hicimos más que agrandar los bolsones. 
	Esto es que si $X_t$ era un bolsón luego $X_t \subseteq N(X_t)$.
	Debemos ver que cumple la tercer condición.
	Partamos de un vértice $x \in V(X)$ tal que $x \in N(X_s) \cap N(X_t)$ y veamos que si $r \in V(T)$ está en la geodésica de $t$ a $s$ entonces $x \in N(X_r)$.
	Notemos que en este caso debe existir algún $y \in N(X_s)$ tal que $xy \in E(X)$.
	Análogamente existe $z \in N(X_t)$ tal que $xz \in E(X)$.
	Si no fuera así tendríamos que $x \in X_s \cap X_t$ y esta condición ya se cumpliría por ser los bolsones de una descomposición.
	Entonces si usamos la proposición \ref{prop-camino-desc} tomando el camino $yxz$ tenemos que alguno de estos tres vértices debe estar en $X_r$.
	De esta manera $x \in N(X_r)$ tal como queríamos ver.
\end{proof}
\medskip

\begin{deff}
	Dado un grafo $X$, el \blue{borde} de un conjunto de vértices $C \subseteq V(X)$ se define como
	\[
	\beta C = \{ u \in V(X) : \exists v \in V(X), \ uv \in E(X), \  \ \ (u \in C \wedge v \in \overline C) \ \ \lor  (u \in \overline C \wedge v \in  C)   \}.
	\] 
\end{deff}

\begin{ej}\label{desc-grafo-cayley}%[Descomposición válida para todo grupo finitamente generado].
	
	Construyamos una descomposición en un árbol que podemos hacer en general para todos los grafos de Cayley de grupos finitamente generados. 
	Consideremos el grafo $\Gamma = Cay(G,\Sigma)$ para cierto conjunto de generadores $\Sigma$ finito.
	
	Sea $V_n = \Gamma \setminus B_n(1) $ tal que $V_0 = \Gamma \setminus \{1\}$. 
	El árbol que vamos a considerar va a tener como vértices a conjuntos de vértices del grafo $\Gamma$ de manera que resultará evidente los bolsones que vamos a tomar para la descomposición. 
	Los vértices del árbol $T$ van a estar dados por los siguientes conjuntos,
	\[
	V(T) = \{  \beta C : C \subseteq V_n \ \text{componente conexa}   \}
	\]
	esto es todas las fronteras de las componentes conexas que nos quedan cuando consideramos algún $V_n$. 
	Las aristas entonces van a estar dadas por lo siguiente,
	\[
	E(T) = \{ \beta C \beta D : C \subseteq D \subseteq V_n, \ C \subset V_{n+1}   \}
	\]
	esto es que $C$ es una componente conexa del grafo que queda de sacarla la bola de radio un número mayor que el que está $D$.
	
	Notemos en particular que por como definimos este grafo $T$ resulta que si $C$ es una componente conexa de $V_n$ entonces solo existe una única arista $(\beta C, \beta D)$ tal que $D \subseteq V_{n-1}$. 
	Esto se debe a que al ser $C$ conexo entonces como $V_{n-1} \subseteq V_{n}$ en particular $C \subseteq V_{n}$ y debe estar contenida en una sola componente conexa $D \subseteq V_{n-1}.$
	
	%Quizá estaría bueno poner algún dibujito acá.
	
	Podemos ver que así como lo construimos tenemos que el grafo $T$ resulta ser un árbol tal que su raíz es $B_1(\Gamma)$. 
	
	Para ver que es un árbol veamos primero que es conexo. Dado un vértice $\beta C \in V(T)$ vamos a armar un camino que lo conecte con la raíz del árbol $B_1(\Gamma)$. 
	Usemos inducción en el $n$ tal que $C$ es una componente conexa de $V_n$. 
	El caso base es algún $C$ tal que es una componente conexa de $V_2$ y queremos armarnos un camino que lo una con $B_1(\Gamma)$. 
	Dado que $V_2 \subseteq V_1$ en particular tenemos que $C \subseteq V_1$. De esta manera por la definición tenemos que existe una arista $\beta CB_1(0)$ tal como queríamos ver.
	
	Para el paso inductivo supongamos para cualquier borde de una componente conexa de $V_{n-1}$ tenemos un camino que lo une con la raíz $B_1(\Gamma)$ y veamos de construirnos un camino con cualquier borde de una componente conexa $C \subseteq V_n$.
	De esta manera debe existir $D$ componente conexa de $V_{n-1}$ tal que $C \subseteq D$. Esto es porque $V_{n-1} \subseteq V_{n}$ y al ser $C$ un conexo si interseca alguna de las componentes conexas de $V_{n-1}$ debe estar contenida en ella. 
	Necesariamente debe intersecar a alguna de estas componentes conexas porque particionan al espacio.
	Así vimos que existe una arista $(\beta C, \beta D)$ y ahora usando la hipótesis inductiva obtenemos un camino de $B_1(\Gamma)$ con $\beta C$.
	Concluimos que el grafo $T$ es conexo.   
	
	% Otra manera que se me ocurrió es tomar un ciclo de longitud mínimo y llegar a un absurdo achicandolo. Creo que es más corto pero no me convence.
	Para terminar de ver que es un árbol veamos que es acíclico. 
	Dado un camino cerrado $\sigma$ en $T$ probemos que necesariamente tiene que repetirse algún vértice por lo tanto ningún camino cerrado puede ser un ciclo. Vamos a probarlo usando inducción en el máximo $n \in \NN$ tal que $C \in V_n$ y $\beta C$ es uno de los vértices en el camino. 
	%Notemos que está bien definido porque los caminos cerrados son compactos.
	Para el caso base notemos que si $\sigma$ es un camino cerrado tal que el máximo $n$ que aparece es $n=1$ entonces necesariamente $\sigma$ es idéntico al camino constante fijo en $B_1(0)$.
	%reescribir esto!
	Para el paso inductivo supongamos que para todo camino cerrado con máximo $m \in \NN$ tal que algún vértice que aparece en este camino es una componente conexa de $V_m$ resulta ser $n-1$ entonces este camino no es un ciclo. Veamos que si $m=n$ entonces este camino cerrado también resulta ser un ciclo.
	
	Partamos de un camino tal que pasa por $\beta C$ con $C \subseteq V_n$. 
	Como no existe $\beta C, \beta C' \in E(T)$ tal que $C,C'$ sean componentes conexas de un mismo $V_n$ por la definición que dimos de las aristas. 
	Necesariamente tiene que haber una arista con alguna componente conexa $D \in V_{n-1}$ dado que $n$ es máximo en este camino cerrado.   
	Como vimos anteriormente solamente hay una única arista que una a $\beta C$ con alguna $\beta D$ con $D \subseteq V_{n-1}$. 
	Esto nos dice que si el camino cerrado pasa por la arista $(\beta C, \beta D)$ necesariamente debe volver a pasar por la arista $(\beta C, \beta D)$ por lo tanto no es un ciclo. 
	Concluimos que el grafo $T$ es acíclico y por lo tanto como es conexo también resulta que $T$ es un árbol.
	
	Para ver que es una descomposición de árboles debemos ver que cumple las tres condiciones \ref{desc-arbol} de la definición. 
	\begin{enumerate}
		\item La primera condición la cumple por como lo definimos porque cualquier vértice del grafo $g \in V(\Gamma)$ 
		es tal que existe $n \in \NN$ de manera que $d(1,g)=n$, por lo que está en alguna componente conexa $C \subseteq V_{n-1}$. 
		En particular como la distancia es exactamente $n$ tiene que existir una arista $gg' \in E(\Gamma)$ con un vértice $g' \in V_{n-1}$ y por lo tanto $g \in \beta C$.
		
		\item La segunda condición partimos de una arista $gh \in E(\Gamma)$ luego miramos las distancias que hay al $1$ de ambos vértices para conseguirnos el bolsón adecuado. 
		Supongamos que ambas están a la misma distancia del $1$. En tal caso sea $n$ tal que $d(g,1)=d(h,1)=n$ luego si miramos $V_{n-1}$ notemos que tienen que estar en la misma componente conexa porque existe una arista entre ambos vértices. Sea esta componente $C$ luego como están a distancia exactamente $n$ ambas están en el borde, esto es que $g,h \in \beta C$ tal como queríamos ver. 
		El otro caso es que $d(g,1)=n < d(h,1)=n+1$ y en este caso como están conectadas resulta que están en $\beta C$ si $C$ es la componente conexa que contiene a $h$ en $V_n$ por definición del borde de un conjunto de vértices de un grafo.
		
		\item Para la tercera condición supongamos que hay $g \in V(\Gamma)$ tal que está en la intersección de dos bolsones $\beta C \cap \beta D$. 
		Queremos ver que está en todos los bolsones que aparecen en la geodésica de $\beta C$ a $\beta D$ en el árbol T. 
		Si $d(g,1) = n$ luego solo puede estar en la frontera de alguna componente conexa $C$ tal que esté en alguna de estas opciones  $V_{n-1}, V_{n},  V_{n+1}$. 
		Supongamos que $D \subseteq V_{n}$, en tal caso vale que $D \nsubseteq V_{n}$ porque sino tendríamos que resulta ser la misma componente conexa. 
		Sin pérdida de generalidad supongamos que $C \subset V_n$ mientras que $D \subset V_{n+1}$. 
		Como ambas son componentes conexas luego si hay una intersección tiene que haber una contención, esto es que $D \subseteq C$. 
		De esta manera vemos que $\beta C, \beta D \in E(T)$ por lo tanto como están unidos por una arista la geodésica es justamente esta arista.
		
	\end{enumerate}
\end{ej}

\begin{obs}\label{palabras-wp}
Si tenemos un grupo $G$ tal que es independiente de contexto consideremos $\cal G$ gramática que genera al lenguaje del problema de la palabra, $\WP = L(\cal G)$.
Si $A$ es una de las variables de esta gramática podemos obtener el lenguaje $L_A$ de palabras generadas a partir de esta variable, donde
\[
L_A = \{ w \in \Sigma^*  \ | \ A \deriva w  \}.
\]
Veamos que si $v,v' \in L_A$ entonces $v =_G v'$, es decir son el mismo elemento vistos en el grupo $G$. 
Para eso si tenemos una derivación que en algún momento llega a $S \deriva \beta A \gamma \deriva uvw$ también tenemos otra derivación que deriva en $S \deriva \beta A \gamma  \deriva uv'w$. 
Es decir que $uvw, u'v'w' \in \WP$ por lo tanto 
\begin{equation*}
	uvw =_G 1 =_G uv'w \implies v =_G v'
\end{equation*}
tal como queríamos ver.
\end{obs}


El siguiente resultado es un teorema de Muller-Schupp demostrado en \cite{muller1985theory}.
La demostración sigue la exposición del paper \cite{diekert_contextfree_2017}.
\medskip
\begin{teo} [Muller - Schupp 1985] \label{teo_schupp_muller_ic_desc}
	Todo grupo independiente de contexto es tal que su grafo de Cayley tiene treewidth finito.
\end{teo}
\begin{proof}

La descomposición que hicimos en \ref{desc-grafo-cayley} es válida para todo grafo de Cayley. 
Veamos que esta descomposición para un grupo independiente de contexto tiene treewidth finito. 
Buscamos $k \in \NN$ tal que nos permita acotar $|\beta C| \le k$ para todo $\beta C \in V(T)$. 
Alcanza con ver que los diámetros de los bolsones $\beta C$ están acotados uniformemente, esto es que exista $M \in \NN$ tal que 
\[
\text{diam}(\beta C) =  \sup_{g,h \in \beta C} d(g,h) \le M
\] 
para todo $\beta C$ de la descomposición de árboles.
Si esto sucede, al ser el grupo finitamente generado por $\Sigma$ entonces $|\beta C| \le |\Sigma|^{M} < \infty$.


Dado que $G$ es un grupo independiente de contexto entonces el lenguaje del problema de la palabra para estos generadores $\WP$ tiene una gramática $\cal G$ independiente de contexto que lo genera. 
Consideremos que está en la forma normal de Chomsky.

Para cada variable $A$ de nuestra gramática podemos considerar el siguiente lenguaje
\[
L_A = \{ w \in \Sigma^* : A \deriva w  \}.
\]
Para este lenguaje introduzcamos un número natural $k_A \in \NN$ definido por $k_A = \min_{w \in L_A} |w|$. 
Como tenemos finitas variables en nuestra gramática $\cal G$ podemos considerar $k = \max_{A \in V} k_A$. 
Veamos que $\text{diam}(\beta C) \le 3k$ para todo $\beta C \in V(T)$.

Sean $g,h \in \beta C$ para cierta $C$ componente conexa de $V_n$, acotemos $d(g,h)$. 
Para eso consideremos una geodésica $\alpha$ que una $1$ con $g$ y análogamente otra $\gamma$ que una $1$ con $h$. 
Como $C \cup \beta C$ es conexo podemos tomar un arco $\tau$ que una $g$ con  $h$ dentro de $C \cup \beta C$. 
De esta manera tenemos un triángulo tal que si leemos las letras que están en la etiqueta del arco empezando desde $1$ y moviéndonos por $\alpha$ leemos la etiqueta $u$. 
Cuando nos movemos por $\tau$ leemos la etiqueta $v$. Consideremos que esta etiqueta $v$ es tal que $|v|>1$ caso contrario ya tenemos la cota probada. Finalmente leemos la etiqueta $w$ cuando regresamos al $1$ por medio de $\gamma$.
Como $uvw$ está en un ciclo en el grafo de Cayley entonces $uvw \in  \WP$ y por lo tanto tenemos alguna derivación $S \deriva uvw$.

Ya que tenemos esta derivación $S \deriva uvw$ miremos la primer variable que deriva a $v$ como subpalabra. 
Esto es que para la subpalabra $v$ sabemos que existe alguna variable $A$ tal que $A \deriva v'v''$ donde $v$ es a su vez una subpalabra de $v'v''$. 
Tomamos la última variable que aparece en la derivación.
%Esto es que para la subpalabra $v$ sabemos que debe existir alguna variable $A$ tal que $A \deriva u''vw''$ para $u''$ algún posfijo de $u$ y $w''$ algún prefijo de $w$ y aparece último en esta derivación. 
Ésta debe existir porque en particular $S$ cumple lo pedido de ser una variable que deriva a una palabra que contiene a $v$ como subpalabra.

Como está en la forma normal de Chomsky sabemos que al ser $|v| \ge 2$ entonces tenemos que la derivación tiene la siguiente pinta
\begin{equation*}
	S \deriva u'Aw' \Rightarrow_{\cal G} u'BC w' \deriva u'v'v''w'
\end{equation*}
donde $B,C$ son otras variables. En particular notemos que $A \deriva v'v''$, $B \deriva v'$ y $C \deriva v''$.


Si miramos la geodésica $\alpha$ sabemos que cuando leímos $u'$ habremos llegado a un vértice del grafo $x$, y al estar sobre la geodésica misma tenemos la siguiente igualdad,
%y que si tomamos el camino que leemos la palabra de menor longitud tenemos que habremos llegado al vértice $y$ que corresponde al haber leído $u'v'$.
\begin{equation*}
d(x,g) = d(1,g) - d(1,x).
\end{equation*}
Análogamente cuando miramos la geodésica $\gamma$ en la instancia que ya leímos $w'$ saliendo desde $h$ llegamos a cierto vértice $z$ y por la misma razón que en el caso anterior obtenemos
\begin{equation*}
	d(z,h) = d(1,h) - d(1,z).
\end{equation*}
Por otro lado si consideramos el vértice $y$ al que llegamos después de leer $u'v'$ que sabemos que está en el arco $\tau$ dado que $v$ es subpalabra de $v'v''$.
Usando que $y \in \tau \subseteq C \cup \beta C$ tenemos que $d(1,y) \le n+1 = d(1,g)$ por ser $C$ una componente conexa de $V_n$, entonces vale la siguiente desigualdad
\begin{equation*}
d(x,g) = d(1,g) - d(1,x) \le d(1,y) - d(1,x) = d(x,y)
\end{equation*}
y análogamente tenemos que $d(z,h) \le d(z,y)$.


Por la observación \ref{palabras-wp} notemos que si reemplazamos $v'$ por la palabra de menor tamaño del lenguaje $L_B$ seguimos teniendo un ciclo pero de longitud idéntica o más chica. 
La palabra $v'$ la leemos justamente cuando vamos del vértice $x$ al vértice $y$, así la distancia  $d(x,y)$ está acotada por la mayor de todas las palabras que puedan derivarse de $B$. 
Idénticamente hacemos esto para las variables $A$ y $C$.
Por como definimos a $k$ tenemos las siguientes cotas $d(x,y), d(y,z), d(x,z) \le k$.
%agregar dibujito, creo que es la manera más clara de explicar esto


Ahora estamos listos para ver que $d(g,h) \le 3k$. Usamos la desigualdad triangular tres veces,
\begin{align*}
	d(g,h) & \le d(g,x) + d(x,z) + d(h,z) \\
	& \le d(x,y) + d(x,z) + d(y,z) \le 3k
\end{align*}
tal como queríamos ver.
\end{proof}

\begin{ej}
	Ejemplo de $PSL(2,\ZZ)$ o de algún otro grupo que sea un producto libre de grupos finitos.
\end{ej}


\subsection{Cuasisometrías.}


\begin{deff}
	Sean $X,Y$ espacios métricos. Una \blue{cuasisometría} es una función $f:X \to Y$ tal que:
	\begin{itemize}
	\item Para todo par de puntos $x_1,x_2 \in X$ existe constante $A > 0$ tales que
	\[
	\frac{1}{A} d_X(x_1,x_2) - A \le d_Y(f(x_1),f(x_2)) \le A d_X(x_1,x_2) + A
	\]
	\item Existe una constante real $C \ge 0$ tal que para todo punto $y \in Y$ existe $x \in X$ tal que 
	\[
	d(y,f(x)) \le C
	\]
	\end{itemize}
 	Dos espacios métricos que se dicen \emph{cuasisométricos} si existe una cuasisometría entre ellos.
\end{deff}

\begin{obs}
	Si nos restringimos a que los espacios métricos sean grafos podemos redefinir una cuasisometría para que sea una función de los vértices de un grafo a los del otro.
	Esto es si tenemos dos grafos $\Gamma_1$ y $\Gamma_2$ entonces son cuasisométricos como espacios métricos si y solo si existe $f:V(\Gamma_1) \to V(\Gamma_2)$ tal que 
	\begin{itemize}
		\item Para todo $v,w \in V(\Gamma_1)$ existe constante $A > 0$ tal que 
		\[
		\frac{1}{A} d_X(v,w) - A \le d_Y(f(v),f(w)) \le A d_X(v,w) + A
		\]
		\item Existe una constante real $C \ge 0$ tal que para todo vértice $y \in V(\Gamma_2)$ existe $v \in V(\Gamma_1)$ tal que 
		\[
		d(y,f(v)) \le C
		\]
	\end{itemize}
	
	Para esto si tenemos una cuasisometría $g$ como espacios métrices definamos una sobre los vértices $f$ de la siguiente manera.
	Por cada vértice $v \in V(\Gamma_1)$ consideremos $g(v) \in \Gamma_2$. 
	Si $g(v) \in V(\Gamma_2)$ tomamos $f(v)=g(v)$.
	El otro caso es que $g(v)$ cae en el medio de alguna arista $xy \in E(\Gamma_2)$. 
	Supongamos que $d(g(v),x) \le \frac{1}{2}$ porque la distancia máxima con alguno de los vértices debe ser no más de $\frac{1}{2}$ porque justamente las aristas son isométricas con el intervalo $[0,1]$. 
	En este caso definamos $f(v) = x$.
	Notemos ahora que la distancia entre dos vértices por medio de $f$ a lo sumo aumenta. 
	Tenemos que $d(f(v),f(w) \le d (g(v),g(w)) + 1$ para $v,w \in V(\Gamma_1)$ porque a lo sumo las imágenes por $g$ están a distancia $\frac{1}{2}$ de alguno de los vértices.
	De esta manera notemos que si tomamos la constante $C+1$ nos sirve.
	Para ver que la imagen es cuasidensa idénticamente tomando $C+1$ nos sirve.
	En definitiva $f$ definida de esta manera es una cuasisometría con constante $C+1$.	
\end{obs}

\begin{prop}
	Si existe $f:X \to Y$ cuasisometría entonces también debe haber $g:Y \to X$ cuasisometría.
\end{prop}
\begin{proof}
	Resultado estándar. Ver \cite{bridson2013metric}.
\end{proof}

Todo espacio métrico es cuasisométrico consigo mismo por medio de la identidad.
La composición de cuasisometrías también sigue siendo una cuasisometría.
Con esta proposición vemos que ser cuasisométricos es una relación de equivalencia entre los espacios métricos. 


Intuitivamente una cuasisometría entre espacios métricos nos dice que estos resultan ser bastante similares al menos desde cierta distancia. 
\medskip

\begin{ej}
Ejemplo de $\ZZ \times \ZZ$ para ver que no es cuasisométrico con un árbol o bien podría rehacer el ejemplo de la parte anterior.
\end{ej}

Todo grafo de Cayley lo podemos pensar como un espacio métrico.  
Veamos que esto no depende de los generadores que hayamos elegido.

\begin{prop}
	Sea $\Sigma$ y $\Delta$ conjuntos finitos de generadores para $G$ grupo entonces $\text{Cay}(G,\Sigma)$ es cuasisométrico con $\text{Cay}(G, \Delta).$
\end{prop}

\begin{proof}
	Resultado estándar. Ver \cite{bridson2013metric}.
\end{proof}



Así otra manera de pensar que un grafo de un grupo virtualmente libre es casi un árbol es pedirle que sea cuasisométrico con un árbol. 
Veamos que estas categorización es equivalente a pedirle que el treewidth sea finito que era la otra caracterización que habíamos obtenido anteriormente.

\begin{prop} \label{treewidth-inv}
	\marginnote{\tiny La otra manera no vale. Hay contraejemplo.}
	El treewidth finito es un invariante por cuasisometría para grafos con grado acotado uniformemente.
\end{prop}
%\begin{proof}[Intento de demo distinta. No salió]
%Si tenemos una cuasisometría $f:\Gamma_1 \to \Gamma_2$ tal que $\Gamma_1$ tiene treewidth finito $k \in \NN$, nos gustaría ver que $\Gamma_2$ también tiene treewidth finito.
%Dada la cuasisometría $f$ consideremos $C \ge A + B$.
%
%Partamos de una descomposición en un árbol $T$ para $\Gamma_1$.
%La idea es usar la cuasisometría para empujar esta descomposición a una (con bolsones posiblemente más grandes) en $\Gamma_2$.
%Por cada bolsón $X_t \subset V(\Gamma_1)$ vamos a considerar un bolsón en el otro grafo,
%\[
%Y_t = B(f(X_t),Ck) \cap V(\Gamma_2).
%\] 
%Esto es todos los vértices de $\Gamma_2$ que estén a distancia igual o menor que $Ck$ de la imagen del bolsón $X_t$ por medio de $f$. 
%Donde $k$ es la constante del treewidth del grafo $\Gamma_1$ y $C$ la constante de la cuasisometría anteriormente definida.
%
%Como ya sabemos que $T$ el grafo subyacente de la descomposición es un árbol basta ver que cumple las tres propiedades que debe cumplir toda descomposición \ref{desc-arbol}.
%
%\begin{enumerate}
%	\item Queremos ver que dado $v \in V(\Gamma_2)$ existe $t \in V(T)$ tal que $v \in Y_t$.
%	Por ser un embedding cuasisométrico debe existir $y \in \Gamma_1$ (no necesariamente algún vértice) tal que $d(f(y),v) \le C$. 
%	Tomemos $x \in V(\Gamma_1)$ de manera que $d(x,y) < 1$. 
%	Usando desigualdad triangular notemos que 
%	\[
%	d(f(x),v) \le d(f(x),f(y)) + d(v,f(y)) \le 2C
%	\]
%	donde $d(f(x),f(y)) \le C$ porque $f$ es una cuasisometría.
%	Mientras que la otra cota vale porque justamente así tomamos a $f(y)$. 
%	Como $k \le 2$ tenemos que $2C \le Ck$ y así vemos que $v \in Y_t$ tal como queríamos ver.
%	\item Dado una arista $vw \in E(\Gamma_2)$ veamos que $v, w \in Y_t$ para algún mismo bolsón $Y_t$.
%	Por la cuenta anterior sabemos que todo $v \in V(\Gamma_2)$ es tal que existe algún $x \in V(\Gamma_1)$ de manera que $d(f(x),v) \le C + 1$.
%	Si tomamos este mismo $x$ notemos que como $d(v,w) = 1$ entonces $d(w,x) \le C+2$. 
%	Esto nos dice que $v,w \in Y_t$ donde $Y_t$ es la bolsa correspondiente a $f(x)$. 
%	\item Sea $v \in Y_t \cap Y_s$ queremos ver que $v \in Y_r$ para todo $r$ en la geodésica que une $t$ con $s$ en el árbol $T$.
%	Alcanza con tomarnos $Y_t$ tal que exista $x \in V(\Gamma_1)$ con $x \in X_t$ de manera que $d(f(x),v) \le 2C$.	
%	Esto lo podemos hacer porque $f$ es una cuasisometría. 
%	Fijemos uno de los bolsones y veamos que para toda geodésicas que parten del vértice del árbol $t$ y terminan en $s$ son tales que todos los vértices $r \in V(T)$ que aparecen cumplen que $v \in Y_r$. 
%	Si no pudiéramos hacer esto tendríamos que nuestro grafo $T$ tiene un ciclo pero esto es absurdo puesto que es un árbol.
%	Supongamos que $sr$ es una arista de $T$ y $rt$ es otra arista.
%%	Los casos de una geodésica en general se reducen a este usando inducción en la longitud del camino.
%%	Sabemos que existe $z \in X_r \cap X_t$ por la proposición \ref{}. 
%%	De esta manera como $|X_t| \le k$ tenemos que $d(x,z) \le k$. 
%%	Usando que $f$ es una cuasisometría tenemos que $d(f(x),f(z) \le Ck$.
%%	
%%	Entonces veamos de acotar $d(f(z),v)$ y así concluir que $x \in Y_r$ tal como queríamos ver.
%%	Usando la desigualdad triangular,
%%	\[
%%	d(f(z),v) \le d(f(z),f()) + d(v,f(x)) \le Ck + C + 2
%%	\]
%%	y esto termina la demostración porque inductivamente lo podemos ver para cualquier $r$ en la geodésica.
%
%\red{Ahora creo que esto no es cierto. La tercera condición se rompa incluso en un ejemplo finito.}
%\end{enumerate}
%
%\end{proof}

\begin{proof}
	Si tenemos una cuasisometría $f:\Gamma_1 \to \Gamma_2$ tal que $\Gamma_2$ tiene treewidth finito $k \in \NN$, nos gustaría ver que $\Gamma_1$ también tiene esta propiedad.
	Consideremos $l$ tal que $d(f(v),f(w) \le l$ para vértices $v,w \in V(\Gamma_1)$ que estén conectados por una arista.
	Esto lo podemos tomar porque al ser una cuasisometría 
	\[
	d(f(v),f(w)) \le C d(v,w) + C  \le 2C
	\]
	entonces basta con tomar $l \ge C+1$.
	
	Veamos de armarnos la descomposición en un árbol $T$ para $\Gamma_1$.	
	Tomaremos como árbol para descomposición al mismo $T$ que usamos para $\Gamma_2$.
	Sean $X_t$ los bolsones de esta descomposición. 
	Recordemos que por \ref{prop-vecinos-desc} si tomamos $N^l(X_t)$ los vecinos del bolsón $X_t$ que están a distancia no mayor a $l$ seguimos teniendo una descomposición.  
	Consideraremos los bolsones $Y_t = f^{-1}(N^l(X_t))$ de vértices en $\Gamma_1$. 
	
	Debemos ver que cumplen las tres propiedades.
	
	\begin{enumerate}
		\item La primera se cumple puesto que los bolsones $X_t$ cubren $V(\Gamma_2)$. 
		De esta manera $\cup_{t \in T} N^l(X_t) = V(\Gamma_2)$ y por lo tanto tomando preimagen tenemos que
		\[
		\bigcup_{t \in V(T)} f^{-1} (N^l (X_t)) = \bigcup_{t \in V(T)} Y_t = f^{-1} (V(\Gamma_2)) = V(\Gamma_1)
		\] 
		donde usamos que la preimagen de la unión es la unión de las preimágenes.
		\item La segunda condición usamos que si hay una arista $xy \in E(\Gamma_2)$ luego debe ser que $d(f(x),f(y)) \le l$ por como tomamos a $l$.
		De esta manera como $f(x) \in X_t$ para algún $t \in V(T)$, notemos que $f(y) \in N^l(X_t)$ también. 
		Tomando preimagen tenemos que $x,y \in f^{-1}(N^l(X_t))$ y esto es que justamente $x,y \in Y_t$ para un mismo $t \in V(T)$ tal como queríamos ver.		
		\item Para la tercera condición si $x \in Y_t \cap Y_s$ queremos ver que $x \in Y_r$ para todo $r \in V(T)$ que aparezca en la geodésica de $s$ a $t$.
		Como la preimagen de una intersección es lo mismo que la intersección de las preimágenes entonces 
		\[
		x \in f^{-1}(N^l(X_t)) \cap f^{-1}(N^l(X_s)) = f^{-1}(N^l(X_t) \cap N^l (X_s)
		\]
		de esta manera debe existir $v \in V(\Gamma_2)$ tal que $v \in N^l(X_s) \cap N^l(X_t)$.
		Ahora usamos que esta es una descomposición sobre $\Gamma_2$ para notar que $v \in N^l(X_r)$.
		Tomando preimagen tenemos que $x \in Y_r$ tal como queríamos ver.
	\end{enumerate}
	
	Finalmente debemos ver que el tamaño de los bolsones está acotado uniformemente.
	Esto es que exista $k \in \NN$ tal que $|Y_t| \le k$ para todo $t \in V(T)$.
	Como $\Gamma_2$ tiene treewidth finito tenemos que $|X_t| \le M$ uniformemente para todo $y \in V(T)$ para cierta $M$. 
	Como el grado de los grafos está acotado uniformemente por alguna constante $d$ tenemos que 
	\[
	|N^l(X_t)| \le d^l |X_t| \le d^l M.
	\]
	Finalmente notemos que al ser $f$ una cuasisometría tenemos que $|f^{-1}(v)| \le k$ para todo $v \in V(\Gamma_2)$.
	Esto lo podemos ver porque si $f(x) = v = f(y)$ entonces
	\[
	\frac{1}{C}d(x,y) - C \le d( f(x), f(y) ) = 0 \implies d(x,y) \le C^2 < \infty
	\]
	y esta cota es uniforme para todo $v \in \Gamma_2$. 
	Así vemos que,
	\[
	|Y_t| = |f^{-1}(N^l(X_t))| \le C^2 d^l M < \infty
	\]
	y tomamos $k$ suficientemente grande para que haga valer esto.
	Concluímos así que la descomposición que nos armamos para $\Gamma_1$ tiene treewidth finito.
\end{proof}

A partir de este resultado podemos ver que la otra manera que teníamos de pensar a los grafos que se parecen a árboles resulta ser más débil. 
El siguiente resultado lo demostramos en el caso general de un grafo tal que los grados de sus vértices están acotados uniformemente. 
Como caso particular tenemos los grafos de Cayley de grupos finitamente generados.

\begin{prop} \marginnote{\tiny Estuve pensando la vuelta. }
	Un grafo $X$ de grado acotado uniformemente cuasisométrico con un árbol tiene treewidth finito.
\end{prop}
\begin{proof}	
%Para la ida veamos de armarnos la cuasisometría a partir de la descomposición en árbol del grafo $X$. 
%Definamos entonces la cuasisometría $q: T \to X$ a partir de mandar $t \to x_t$ donde $x_t \in X_t$ es algún elemento del bolsón correspondiente a $t \in V(T)$ que sabemos que no es vacío. 
%Esta función es una cuasisometría con constante $C=1$ y $A = bs(T) + 1$.
%
%Hay que ver la distancia dentro de un bolsón esté controlada.
%Si los bolsones los tomamos conexos \ref{} entonces notemos que la mayor distancia posible es...


Dado que el grafo $X$ es cuasisométrico a un árbol $T$, por la observación \ref{desc-arbol-arbol} este tiene treewidth exactamente 1.
Por la proposición anterior \ref{treewidth-inv} como es un invariante por cuasisometría vemos que $X$ debe tener treewidth finito tal como queríamos ver.
\end{proof}

\begin{coro}
	Todo grupo independiente de contexto es tal que su grafo de Cayley es cuasisométrico a un árbol.
\end{coro}
\begin{proof}
	Por \ref{teo_schupp_muller_ic_desc} todo grupo independiente de contexto tiene treewidth finito y usando la proposición recién demostrada concluímos que su grafo de Cayley es cuasisométrico a un árbol.
\end{proof}
\medskip

\begin{prop}\label{cuasisometria-subgrupo-ind-finito}
	Sea $G$ grupo \fg entonces si $H$ es un subgrupo de índice finito resulta que son cuasisométricos.
\end{prop}
\begin{proof}
	Resultado estándar pero no tan elemental de demostrar. Ver \cite{loh2017geometric}.
\end{proof}

Esto nos dice que todo grupo es cuasisométrico con los subgrupos de índice finito. 
De esta manera obtenemos el siguiente resultado,

\begin{prop}
	Todo grafo de Cayley de un grupo virtualmente libre es cuasisométrico a un árbol.
\end{prop}

\begin{proof}
	Si $G$ es virtualmente libre entonces existe $F \le G$ grupo libre de índice finito.
	Por la prop anterior \ref{cuasisometria-subgrupo-ind-finito} tenemos que el grafo de Cayley de $G$ es cuasisométrico con el de $H$.
	Por el resultado \ref{} sabemos que los grafos de grupos libres son árboles y así queda demostrada la proposición.
\end{proof}

\section{Teoría de Bass Serre.}

\section{Ends de grupos.}
	
	
	
\end{document}